{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TV Script Generation\n",
    "\n",
    "In this project, you'll generate your own [Seinfeld](https://en.wikipedia.org/wiki/Seinfeld) TV scripts using RNNs.  You'll be using part of the [Seinfeld dataset](https://www.kaggle.com/thec03u5/seinfeld-chronicles#scripts.csv) of scripts from 9 seasons.  The Neural Network you'll build will generate a new ,\"fake\" TV script, based on patterns it recognizes in this training data.\n",
    "\n",
    "## Get the Data\n",
    "\n",
    "The data is already provided for you in `./data/Seinfeld_Scripts.txt` and you're encouraged to open that file and look at the text. \n",
    ">* As a first step, we'll load in this data and look at some samples. \n",
    "* Then, you'll be tasked with defining and training an RNN to generate a new script!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# load in data\n",
    "import helper\n",
    "data_dir = './data/Seinfeld_Scripts.txt'\n",
    "text = helper.load_data(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "Play around with `view_line_range` to view different parts of the data. This will give you a sense of the data you'll be working with. You can see, for example, that it is all lowercase text, and each new line of dialogue is separated by a newline character `\\n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Stats\n",
      "Roughly the number of unique words: 46367\n",
      "Number of lines: 109233\n",
      "Average number of words in each line: 5.544240293684143\n",
      "\n",
      "The lines 0 to 10:\n",
      "jerry: do you know what this is all about? do you know, why were here? to be out, this is out...and out is one of the single most enjoyable experiences of life. people...did you ever hear people talking about we should go out? this is what theyre talking about...this whole thing, were all out now, no one is home. not one person here is home, were all out! there are people trying to find us, they dont know where we are. (on an imaginary phone) did you ring?, i cant find him. where did he go? he didnt tell me where he was going. he must have gone out. you wanna go out you get ready, you pick out the clothes, right? you take the shower, you get all ready, get the cash, get your friends, the car, the spot, the reservation...then youre standing around, what do you do? you go we gotta be getting back. once youre out, you wanna get back! you wanna go to sleep, you wanna get up, you wanna go out again tomorrow, right? where ever you are in life, its my feeling, youve gotta go. \n",
      "\n",
      "jerry: (pointing at georges shirt) see, to me, that button is in the worst possible spot. the second button literally makes or breaks the shirt, look at it. its too high! its in no-mans-land. you look like you live with your mother. \n",
      "\n",
      "george: are you through? \n",
      "\n",
      "jerry: you do of course try on, when you buy? \n",
      "\n",
      "george: yes, it was purple, i liked it, i dont actually recall considering the buttons. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "view_line_range = (0, 10)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "print('Dataset Stats')\n",
    "print('Roughly the number of unique words: {}'.format(len({word: None for word in text.split()})))\n",
    "\n",
    "lines = text.split('\\n')\n",
    "print('Number of lines: {}'.format(len(lines)))\n",
    "word_count_line = [len(line.split()) for line in lines]\n",
    "print('Average number of words in each line: {}'.format(np.average(word_count_line)))\n",
    "\n",
    "print()\n",
    "print('The lines {} to {}:'.format(*view_line_range))\n",
    "print('\\n'.join(text.split('\\n')[view_line_range[0]:view_line_range[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Implement Pre-processing Functions\n",
    "The first thing to do to any dataset is pre-processing.  Implement the following pre-processing functions below:\n",
    "- Lookup Table\n",
    "- Tokenize Punctuation\n",
    "\n",
    "### Lookup Table\n",
    "To create a word embedding, you first need to transform the words to ids.  In this function, create two dictionaries:\n",
    "- Dictionary to go from the words to an id, we'll call `vocab_to_int`\n",
    "- Dictionary to go from the id to word, we'll call `int_to_vocab`\n",
    "\n",
    "Return these dictionaries in the following **tuple** `(vocab_to_int, int_to_vocab)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import problem_unittests as tests\n",
    "import re\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "def create_lookup_tables(text):\n",
    "    \"\"\"\n",
    "    Create lookup tables for vocabulary\n",
    "    :param text: The text of tv scripts split into words\n",
    "    :return: A tuple of dicts (vocab_to_int, int_to_vocab)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    vocabulary = Counter(text)\n",
    "    int_to_vocab = {i : word for i, word in enumerate(sorted(vocabulary, key=vocabulary.get, reverse=True))}\n",
    "    vocab_to_int = {word : i for i, word in int_to_vocab.items()}\n",
    "    \n",
    "    # return tuple\n",
    "    return (vocab_to_int, int_to_vocab)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_create_lookup_tables(create_lookup_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Punctuation\n",
    "We'll be splitting the script into a word array using spaces as delimiters.  However, punctuations like periods and exclamation marks can create multiple ids for the same word. For example, \"bye\" and \"bye!\" would generate two different word ids.\n",
    "\n",
    "Implement the function `token_lookup` to return a dict that will be used to tokenize symbols like \"!\" into \"||Exclamation_Mark||\".  Create a dictionary for the following symbols where the symbol is the key and value is the token:\n",
    "- Period ( **.** )\n",
    "- Comma ( **,** )\n",
    "- Quotation Mark ( **\"** )\n",
    "- Semicolon ( **;** )\n",
    "- Exclamation mark ( **!** )\n",
    "- Question mark ( **?** )\n",
    "- Left Parentheses ( **(** )\n",
    "- Right Parentheses ( **)** )\n",
    "- Dash ( **-** )\n",
    "- Return ( **\\n** )\n",
    "\n",
    "This dictionary will be used to tokenize the symbols and add the delimiter (space) around it.  This separates each symbols as its own word, making it easier for the neural network to predict the next word. Make sure you don't use a value that could be confused as a word; for example, instead of using the value \"dash\", try using something like \"||dash||\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def token_lookup():\n",
    "    \"\"\"\n",
    "    Generate a dict to turn punctuation into a token.\n",
    "    :return: Tokenized dictionary where the key is the punctuation and the value is the token\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function    \n",
    "    return {\n",
    "        '.': '||period||',\n",
    "        ',': '||comma||',\n",
    "        '\"': '||quotation||',\n",
    "        ';': '||semicolon||',\n",
    "        '!': '||exclamation||',\n",
    "        '?': '||question||',\n",
    "        '(': '||left_parenthesis||',\n",
    "        ')': '||right_parenthesis||',\n",
    "        '-': '||dash||',\n",
    "        '\\n': '||newline||'\n",
    "    }\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_tokenize(token_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process all the data and save it\n",
    "\n",
    "Running the code cell below will pre-process all the data and save it to file. You're encouraged to lok at the code for `preprocess_and_save_data` in the `helpers.py` file to see what it's doing in detail, but you do not need to change this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# pre-process training data\n",
    "helper.preprocess_and_save_data(data_dir, token_lookup, create_lookup_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint. If you ever decide to come back to this notebook or have to restart the notebook, you can start from here. The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import helper\n",
    "import problem_unittests as tests\n",
    "\n",
    "int_text, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Neural Network\n",
    "In this section, you'll build the components necessary to build an RNN by implementing the RNN Module and forward and backpropagation functions.\n",
    "\n",
    "### Check Access to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import torch\n",
    "\n",
    "# Check for a GPU\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if not train_on_gpu:\n",
    "    print('No GPU found. Please use a GPU to train your neural network.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input\n",
    "Let's start with the preprocessed input data. We'll use [TensorDataset](http://pytorch.org/docs/master/data.html#torch.utils.data.TensorDataset) to provide a known format to our dataset; in combination with [DataLoader](http://pytorch.org/docs/master/data.html#torch.utils.data.DataLoader), it will handle batching, shuffling, and other dataset iteration functions.\n",
    "\n",
    "You can create data with TensorDataset by passing in feature and target tensors. Then create a DataLoader as usual.\n",
    "```\n",
    "data = TensorDataset(feature_tensors, target_tensors)\n",
    "data_loader = torch.utils.data.DataLoader(data, \n",
    "                                          batch_size=batch_size)\n",
    "```\n",
    "\n",
    "### Batching\n",
    "Implement the `batch_data` function to batch `words` data into chunks of size `batch_size` using the `TensorDataset` and `DataLoader` classes.\n",
    "\n",
    ">You can batch words using the DataLoader, but it will be up to you to create `feature_tensors` and `target_tensors` of the correct size and content for a given `sequence_length`.\n",
    "\n",
    "For example, say we have these as input:\n",
    "```\n",
    "words = [1, 2, 3, 4, 5, 6, 7]\n",
    "sequence_length = 4\n",
    "```\n",
    "\n",
    "Your first `feature_tensor` should contain the values:\n",
    "```\n",
    "[1, 2, 3, 4]\n",
    "```\n",
    "And the corresponding `target_tensor` should just be the next \"word\"/tokenized word value:\n",
    "```\n",
    "5\n",
    "```\n",
    "This should continue with the second `feature_tensor`, `target_tensor` being:\n",
    "```\n",
    "[2, 3, 4, 5]  # features\n",
    "6             # target\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "[tensor([[0, 1, 2],\n",
      "        [1, 2, 3],\n",
      "        [2, 3, 4],\n",
      "        [3, 4, 5]]), tensor([3, 4, 5, 6])]\n",
      "[tensor([[4, 5, 6],\n",
      "        [5, 6, 7],\n",
      "        [6, 7, 8],\n",
      "        [7, 8, 9]]), tensor([ 7,  8,  9, 10])]\n",
      "[tensor([[ 8,  9, 10],\n",
      "        [ 9, 10, 11],\n",
      "        [10, 11, 12],\n",
      "        [11, 12, 13]]), tensor([11, 12, 13, 14])]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def batch_data(words, sequence_length, batch_size):\n",
    "    \"\"\"\n",
    "    Batch the neural network data using DataLoader\n",
    "    :param words: The word ids of the TV scripts\n",
    "    :param sequence_length: The sequence length of each batch\n",
    "    :param batch_size: The size of each batch; the number of sequences in a batch\n",
    "    :return: DataLoader with batched data\n",
    "    \"\"\"\n",
    "    # TODO: Implement function\n",
    "    num_batches = (len(words) - sequence_length) // batch_size    \n",
    "    \n",
    "    features = []\n",
    "    targets = []\n",
    "    for i in range(num_batches * batch_size):\n",
    "        features.append(words[i:i+sequence_length])\n",
    "        targets.append(words[i+sequence_length])\n",
    "        \n",
    "    dataset = TensorDataset(torch.LongTensor(features), torch.LongTensor(targets))\n",
    "    # return a dataloader\n",
    "    return DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# there is no test for this function, but you are encouraged to create\n",
    "# print statements and tests of your own\n",
    "print([word for word in range(15)])\n",
    "for data in batch_data(range(15), 3, 4):\n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your dataloader \n",
    "\n",
    "You'll have to modify this code to test a batching function, but it should look fairly similar.\n",
    "\n",
    "Below, we're generating some test text data and defining a dataloader using the function you defined, above. Then, we are getting some sample batch of inputs `sample_x` and targets `sample_y` from our dataloader.\n",
    "\n",
    "Your code should return something like the following (likely in a different order, if you shuffled your data):\n",
    "\n",
    "```\n",
    "torch.Size([10, 5])\n",
    "tensor([[ 28,  29,  30,  31,  32],\n",
    "        [ 21,  22,  23,  24,  25],\n",
    "        [ 17,  18,  19,  20,  21],\n",
    "        [ 34,  35,  36,  37,  38],\n",
    "        [ 11,  12,  13,  14,  15],\n",
    "        [ 23,  24,  25,  26,  27],\n",
    "        [  6,   7,   8,   9,  10],\n",
    "        [ 38,  39,  40,  41,  42],\n",
    "        [ 25,  26,  27,  28,  29],\n",
    "        [  7,   8,   9,  10,  11]])\n",
    "\n",
    "torch.Size([10])\n",
    "tensor([ 33,  26,  22,  39,  16,  28,  11,  43,  30,  12])\n",
    "```\n",
    "\n",
    "### Sizes\n",
    "Your sample_x should be of size `(batch_size, sequence_length)` or (10, 5) in this case and sample_y should just have one dimension: batch_size (10). \n",
    "\n",
    "### Values\n",
    "\n",
    "You should also notice that the targets, sample_y, are the *next* value in the ordered test_text data. So, for an input sequence `[ 28,  29,  30,  31,  32]` that ends with the value `32`, the corresponding output should be `33`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5])\n",
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 1,  2,  3,  4,  5],\n",
      "        [ 2,  3,  4,  5,  6],\n",
      "        [ 3,  4,  5,  6,  7],\n",
      "        [ 4,  5,  6,  7,  8],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [ 6,  7,  8,  9, 10],\n",
      "        [ 7,  8,  9, 10, 11],\n",
      "        [ 8,  9, 10, 11, 12],\n",
      "        [ 9, 10, 11, 12, 13]])\n",
      "\n",
      "torch.Size([10])\n",
      "tensor([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14])\n"
     ]
    }
   ],
   "source": [
    "# test dataloader\n",
    "\n",
    "test_text = range(50)\n",
    "t_loader = batch_data(test_text, sequence_length=5, batch_size=10)\n",
    "\n",
    "data_iter = iter(t_loader)\n",
    "sample_x, sample_y = data_iter.next()\n",
    "\n",
    "print(sample_x.shape)\n",
    "print(sample_x)\n",
    "print()\n",
    "print(sample_y.shape)\n",
    "print(sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Build the Neural Network\n",
    "Implement an RNN using PyTorch's [Module class](http://pytorch.org/docs/master/nn.html#torch.nn.Module). You may choose to use a GRU or an LSTM. To complete the RNN, you'll have to implement the following functions for the class:\n",
    " - `__init__` - The initialize function. \n",
    " - `init_hidden` - The initialization function for an LSTM/GRU hidden state\n",
    " - `forward` - Forward propagation function.\n",
    " \n",
    "The initialize function should create the layers of the neural network and save them to the class. The forward propagation function will use these layers to run forward propagation and generate an output and a hidden state.\n",
    "\n",
    "**The output of this model should be the *last* batch of word scores** after a complete sequence has been processed. That is, for each input sequence of words, we only want to output the word scores for a single, most likely, next word.\n",
    "\n",
    "### Hints\n",
    "\n",
    "1. Make sure to stack the outputs of the lstm to pass to your fully-connected layer, you can do this with `lstm_output = lstm_output.contiguous().view(-1, self.hidden_dim)`\n",
    "2. You can get the last batch of word scores by shaping the output of the final, fully-connected layer like so:\n",
    "\n",
    "```\n",
    "# reshape into (batch_size, seq_length, output_size)\n",
    "output = output.view(batch_size, -1, self.output_size)\n",
    "# get last batch\n",
    "out = output[:, -1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the PyTorch RNN Module\n",
    "        :param vocab_size: The number of input dimensions of the neural network (the size of the vocabulary)\n",
    "        :param output_size: The number of output dimensions of the neural network\n",
    "        :param embedding_dim: The size of embeddings, should you choose to use them        \n",
    "        :param hidden_dim: The size of the hidden layer outputs\n",
    "        :param dropout: dropout to add in between LSTM/GRU layers\n",
    "        \"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "        # TODO: Implement function\n",
    "        # set class variables\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = n_layers\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # define model layers\n",
    "        self.embed_input = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, nn_input, hidden):\n",
    "        \"\"\"\n",
    "        Forward propagation of the neural network\n",
    "        :param nn_input: The input to the neural network\n",
    "        :param hidden: The hidden state        \n",
    "        :return: Two Tensors, the output of the neural network and the latest hidden state\n",
    "        \"\"\"\n",
    "        # TODO: Implement function\n",
    "        batch_size = nn_input.shape[0]\n",
    "        x = self.embed_input(nn_input)\n",
    "        x, hidden = self.lstm(x, hidden)\n",
    "        x = x.contiguous().view(-1, self.hidden_dim)\n",
    "#         x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(batch_size, -1, self.output_size)\n",
    "\n",
    "        # return one batch of output word scores and the hidden state\n",
    "        return x[:, -1], hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        '''\n",
    "        Initialize the hidden state of an LSTM/GRU\n",
    "        :param batch_size: The batch_size of the hidden state\n",
    "        :return: hidden state of dims (n_layers, batch_size, hidden_dim)\n",
    "        '''\n",
    "        \n",
    "        new_weights = []\n",
    "        # Implement function\n",
    "        for name, parameter in self.named_parameters():\n",
    "            if name.startswith('lstm.weight_ih'):\n",
    "                new_weight = parameter.data.new(self.num_layers, batch_size, self.hidden_dim).zero_()\n",
    "                if train_on_gpu:\n",
    "                    new_weight = new_weight.cuda()\n",
    "                new_weights += [new_weight]\n",
    "        \n",
    "        # initialize hidden state with zero weights, and move to GPU if available\n",
    "        return tuple(new_weights)\n",
    "\n",
    "   \n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_rnn(RNN, train_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define forward and backpropagation\n",
    "\n",
    "Use the RNN class you implemented to apply forward and back propagation. This function will be called, iteratively, in the training loop as follows:\n",
    "```\n",
    "loss = forward_back_prop(decoder, decoder_optimizer, criterion, inp, target)\n",
    "```\n",
    "\n",
    "And it should return the average loss over a batch and the hidden state returned by a call to `RNN(inp, hidden)`. Recall that you can get this loss by computing it, as usual, and calling `loss.item()`.\n",
    "\n",
    "**If a GPU is available, you should move your data to that GPU device, here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def forward_back_prop(rnn, optimizer, criterion, inp, target, hidden):\n",
    "    \"\"\"\n",
    "    Forward and backward propagation on the neural network\n",
    "    :param decoder: The PyTorch Module that holds the neural network\n",
    "    :param decoder_optimizer: The PyTorch optimizer for the neural network\n",
    "    :param criterion: The PyTorch loss function\n",
    "    :param inp: A batch of input to the neural network\n",
    "    :param target: The target output for the batch of input\n",
    "    :return: The loss and the latest hidden state Tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Implement Function\n",
    "\n",
    "    # move data to GPU, if available\n",
    "    if train_on_gpu:\n",
    "        inp, target = inp.cuda(), target.cuda()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "    hidden = tuple([each.data for each in hidden])\n",
    "    output, hidden_out = rnn(inp, hidden)\n",
    "    # perform backpropagation and optimization\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "\n",
    "#     nn.utils.clip_grad_norm_(rnn.parameters(), 1)\n",
    "    optimizer.step()\n",
    "    \n",
    "    # return the loss over a batch and the hidden state produced by our model\n",
    "    return loss.item(), hidden_out\n",
    "\n",
    "# Note that these tests aren't completely extensive.\n",
    "# they are here to act as general checks on the expected outputs of your functions\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_forward_back_prop(RNN, forward_back_prop, train_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Training\n",
    "\n",
    "With the structure of the network complete and data ready to be fed in the neural network, it's time to train it.\n",
    "\n",
    "### Train Loop\n",
    "\n",
    "The training loop is implemented for you in the `train_decoder` function. This function will train the network over all the batches for the number of epochs given. The model progress will be shown every number of batches. This number is set with the `show_every_n_batches` parameter. You'll set this parameter along with other parameters in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "\n",
    "def train_rnn(rnn, batch_size, optimizer, criterion, n_epochs, show_every_n_batches=100):\n",
    "    batch_losses = []\n",
    "    \n",
    "    rnn.train()\n",
    "\n",
    "    print(\"Training for %d epoch(s)...\" % n_epochs)\n",
    "    for epoch_i in range(1, n_epochs + 1):\n",
    "        \n",
    "        # initialize hidden state\n",
    "        hidden = rnn.init_hidden(batch_size)\n",
    "        \n",
    "        for batch_i, (inputs, labels) in enumerate(train_loader, 1):\n",
    "            \n",
    "            # make sure you iterate over completely full batches, only\n",
    "            n_batches = len(train_loader.dataset)//batch_size\n",
    "            if(batch_i > n_batches):\n",
    "                break\n",
    "            \n",
    "            # forward, back prop\n",
    "            loss, hidden = forward_back_prop(rnn, optimizer, criterion, inputs, labels, hidden)          \n",
    "            # record loss\n",
    "            batch_losses.append(loss)\n",
    "\n",
    "            # printing loss stats\n",
    "            if batch_i % show_every_n_batches == 0:\n",
    "                print('Epoch: {:>4}/{:<4}  Loss: {}\\n'.format(\n",
    "                    epoch_i, n_epochs, np.average(batch_losses)))\n",
    "                batch_losses = []\n",
    "\n",
    "    # returns a trained rnn\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Set and train the neural network with the following parameters:\n",
    "- Set `sequence_length` to the length of a sequence.\n",
    "- Set `batch_size` to the batch size.\n",
    "- Set `num_epochs` to the number of epochs to train for.\n",
    "- Set `learning_rate` to the learning rate for an Adam optimizer.\n",
    "- Set `vocab_size` to the number of unique tokens in our vocabulary.\n",
    "- Set `output_size` to the desired size of the output.\n",
    "- Set `embedding_dim` to the embedding dimension; smaller than the vocab_size.\n",
    "- Set `hidden_dim` to the hidden dimension of your RNN.\n",
    "- Set `n_layers` to the number of layers/cells in your RNN.\n",
    "- Set `show_every_n_batches` to the number of batches at which the neural network should print progress.\n",
    "\n",
    "If the network isn't getting the desired results, tweak these parameters and/or the layers in the `RNN` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data params\n",
    "# Sequence Length\n",
    "sequence_length = 15  # of words in a sequence\n",
    "# Batch Size\n",
    "batch_size = 30\n",
    "\n",
    "# data loader - do not change\n",
    "train_loader = batch_data(int_text, sequence_length, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "# Number of Epochs\n",
    "num_epochs = 60\n",
    "# Learning Rate\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Model parameters\n",
    "# Vocab size\n",
    "vocab_size = len(vocab_to_int)\n",
    "# Output size\n",
    "output_size = len(vocab_to_int)\n",
    "# Embedding Dimension\n",
    "embedding_dim = 300\n",
    "# Hidden Dimension\n",
    "hidden_dim = 256\n",
    "# Number of RNN Layers\n",
    "n_layers = 2\n",
    "\n",
    "# Show stats for every n number of batches\n",
    "show_every_n_batches = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "In the next cell, you'll train the neural network on the pre-processed data.  If you have a hard time getting a good loss, you may consider changing your hyperparameters. In general, you may get better results with larger hidden and n_layer dimensions, but larger models take a longer time to train. \n",
    "> **You should aim for a loss less than 3.5.** \n",
    "\n",
    "You should also experiment with different sequence lengths, which determine the size of the long range dependencies that a model can learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 60 epoch(s)...\n",
      "Epoch:    1/60    Loss: 5.584539404392243\n",
      "\n",
      "Epoch:    1/60    Loss: 4.978618786811829\n",
      "\n",
      "Epoch:    1/60    Loss: 4.743197936058045\n",
      "\n",
      "Epoch:    1/60    Loss: 4.7408830742836\n",
      "\n",
      "Epoch:    1/60    Loss: 4.796560604572296\n",
      "\n",
      "Epoch:    1/60    Loss: 4.691383345127106\n",
      "\n",
      "Epoch:    1/60    Loss: 4.620989734649658\n",
      "\n",
      "Epoch:    1/60    Loss: 4.5035069065094\n",
      "\n",
      "Epoch:    1/60    Loss: 4.2975137164592745\n",
      "\n",
      "Epoch:    1/60    Loss: 4.580089133262634\n",
      "\n",
      "Epoch:    1/60    Loss: 4.363871543884278\n",
      "\n",
      "Epoch:    1/60    Loss: 4.470418291568756\n",
      "\n",
      "Epoch:    1/60    Loss: 4.186340519428253\n",
      "\n",
      "Epoch:    1/60    Loss: 4.282206547737122\n",
      "\n",
      "Epoch:    1/60    Loss: 4.192819122314453\n",
      "\n",
      "Epoch:    1/60    Loss: 4.33475363445282\n",
      "\n",
      "Epoch:    1/60    Loss: 4.294622162818909\n",
      "\n",
      "Epoch:    1/60    Loss: 4.451160747051239\n",
      "\n",
      "Epoch:    1/60    Loss: 4.440550621509552\n",
      "\n",
      "Epoch:    1/60    Loss: 4.313336195468903\n",
      "\n",
      "Epoch:    1/60    Loss: 4.309487774848938\n",
      "\n",
      "Epoch:    1/60    Loss: 4.205012201547623\n",
      "\n",
      "Epoch:    1/60    Loss: 4.502835605621338\n",
      "\n",
      "Epoch:    1/60    Loss: 4.315154174804688\n",
      "\n",
      "Epoch:    1/60    Loss: 4.477178359031678\n",
      "\n",
      "Epoch:    1/60    Loss: 4.474082582473755\n",
      "\n",
      "Epoch:    1/60    Loss: 4.332868708610535\n",
      "\n",
      "Epoch:    1/60    Loss: 4.454158801078797\n",
      "\n",
      "Epoch:    1/60    Loss: 4.333987774848938\n",
      "\n",
      "Epoch:    1/60    Loss: 4.245570753097534\n",
      "\n",
      "Epoch:    1/60    Loss: 4.191190000057221\n",
      "\n",
      "Epoch:    1/60    Loss: 4.500000421524048\n",
      "\n",
      "Epoch:    1/60    Loss: 4.312783335208893\n",
      "\n",
      "Epoch:    1/60    Loss: 4.0926206276416774\n",
      "\n",
      "Epoch:    1/60    Loss: 4.1326706950664525\n",
      "\n",
      "Epoch:    1/60    Loss: 4.312404307842255\n",
      "\n",
      "Epoch:    1/60    Loss: 4.12882629776001\n",
      "\n",
      "Epoch:    1/60    Loss: 4.399092391729355\n",
      "\n",
      "Epoch:    1/60    Loss: 4.264918925523758\n",
      "\n",
      "Epoch:    1/60    Loss: 4.217979504585266\n",
      "\n",
      "Epoch:    1/60    Loss: 4.194918124675751\n",
      "\n",
      "Epoch:    1/60    Loss: 4.245503536701202\n",
      "\n",
      "Epoch:    1/60    Loss: 4.207558061599731\n",
      "\n",
      "Epoch:    1/60    Loss: 4.386960781574249\n",
      "\n",
      "Epoch:    1/60    Loss: 4.240934824943542\n",
      "\n",
      "Epoch:    1/60    Loss: 4.349321382522583\n",
      "\n",
      "Epoch:    1/60    Loss: 4.556552526950836\n",
      "\n",
      "Epoch:    1/60    Loss: 4.565672998428345\n",
      "\n",
      "Epoch:    1/60    Loss: 4.419836859226227\n",
      "\n",
      "Epoch:    1/60    Loss: 4.430744566679001\n",
      "\n",
      "Epoch:    1/60    Loss: 4.491157646656037\n",
      "\n",
      "Epoch:    1/60    Loss: 4.461477841854095\n",
      "\n",
      "Epoch:    1/60    Loss: 4.483451738595963\n",
      "\n",
      "Epoch:    1/60    Loss: 4.417303246498108\n",
      "\n",
      "Epoch:    1/60    Loss: 4.428138305187225\n",
      "\n",
      "Epoch:    1/60    Loss: 4.4382841343879695\n",
      "\n",
      "Epoch:    1/60    Loss: 4.290555070877075\n",
      "\n",
      "Epoch:    1/60    Loss: 4.510940369129181\n",
      "\n",
      "Epoch:    1/60    Loss: 4.262174345254898\n",
      "\n",
      "Epoch:    2/60    Loss: 4.429508287945519\n",
      "\n",
      "Epoch:    2/60    Loss: 4.0317278101444245\n",
      "\n",
      "Epoch:    2/60    Loss: 4.030819558143616\n",
      "\n",
      "Epoch:    2/60    Loss: 4.06558516073227\n",
      "\n",
      "Epoch:    2/60    Loss: 4.132909673452377\n",
      "\n",
      "Epoch:    2/60    Loss: 4.153683086156845\n",
      "\n",
      "Epoch:    2/60    Loss: 4.111942491531372\n",
      "\n",
      "Epoch:    2/60    Loss: 4.052715909957886\n",
      "\n",
      "Epoch:    2/60    Loss: 3.874140060424805\n",
      "\n",
      "Epoch:    2/60    Loss: 4.1939811913967135\n",
      "\n",
      "Epoch:    2/60    Loss: 3.990584184885025\n",
      "\n",
      "Epoch:    2/60    Loss: 4.126995318889618\n",
      "\n",
      "Epoch:    2/60    Loss: 3.840491840362549\n",
      "\n",
      "Epoch:    2/60    Loss: 3.9559146318435667\n",
      "\n",
      "Epoch:    2/60    Loss: 3.8551442093849184\n",
      "\n",
      "Epoch:    2/60    Loss: 4.006331790208817\n",
      "\n",
      "Epoch:    2/60    Loss: 4.020254987716675\n",
      "\n",
      "Epoch:    2/60    Loss: 4.228961871147156\n",
      "\n",
      "Epoch:    2/60    Loss: 4.141343107700348\n",
      "\n",
      "Epoch:    2/60    Loss: 4.0554907076358795\n",
      "\n",
      "Epoch:    2/60    Loss: 4.055373066902161\n",
      "\n",
      "Epoch:    2/60    Loss: 3.97321329498291\n",
      "\n",
      "Epoch:    2/60    Loss: 4.298759968757629\n",
      "\n",
      "Epoch:    2/60    Loss: 4.109160690307617\n",
      "\n",
      "Epoch:    2/60    Loss: 4.242182459831238\n",
      "\n",
      "Epoch:    2/60    Loss: 4.264491364717483\n",
      "\n",
      "Epoch:    2/60    Loss: 4.132045463562012\n",
      "\n",
      "Epoch:    2/60    Loss: 4.248043483734131\n",
      "\n",
      "Epoch:    2/60    Loss: 4.1306860065460205\n",
      "\n",
      "Epoch:    2/60    Loss: 4.060737189769745\n",
      "\n",
      "Epoch:    2/60    Loss: 3.9417130317687987\n",
      "\n",
      "Epoch:    2/60    Loss: 4.29304283285141\n",
      "\n",
      "Epoch:    2/60    Loss: 4.137231809854508\n",
      "\n",
      "Epoch:    2/60    Loss: 3.9067204978466035\n",
      "\n",
      "Epoch:    2/60    Loss: 3.956833998441696\n",
      "\n",
      "Epoch:    2/60    Loss: 4.113496272802353\n",
      "\n",
      "Epoch:    2/60    Loss: 3.972088612794876\n",
      "\n",
      "Epoch:    2/60    Loss: 4.238672315597534\n",
      "\n",
      "Epoch:    2/60    Loss: 4.08638326048851\n",
      "\n",
      "Epoch:    2/60    Loss: 4.041441945791244\n",
      "\n",
      "Epoch:    2/60    Loss: 4.041833787918091\n",
      "\n",
      "Epoch:    2/60    Loss: 4.058106949567795\n",
      "\n",
      "Epoch:    2/60    Loss: 4.092928634643554\n",
      "\n",
      "Epoch:    2/60    Loss: 4.200017159461975\n",
      "\n",
      "Epoch:    2/60    Loss: 4.119115034103394\n",
      "\n",
      "Epoch:    2/60    Loss: 4.187801851272583\n",
      "\n",
      "Epoch:    2/60    Loss: 4.41037546133995\n",
      "\n",
      "Epoch:    2/60    Loss: 4.3907617893219\n",
      "\n",
      "Epoch:    2/60    Loss: 4.24628427362442\n",
      "\n",
      "Epoch:    2/60    Loss: 4.246769404649735\n",
      "\n",
      "Epoch:    2/60    Loss: 4.2671496539115905\n",
      "\n",
      "Epoch:    2/60    Loss: 4.289663331031799\n",
      "\n",
      "Epoch:    2/60    Loss: 4.297907082319259\n",
      "\n",
      "Epoch:    2/60    Loss: 4.276141669273376\n",
      "\n",
      "Epoch:    2/60    Loss: 4.198048438787461\n",
      "\n",
      "Epoch:    2/60    Loss: 4.266749669075012\n",
      "\n",
      "Epoch:    2/60    Loss: 4.121604875087738\n",
      "\n",
      "Epoch:    2/60    Loss: 4.362252393245697\n",
      "\n",
      "Epoch:    2/60    Loss: 4.079461237668991\n",
      "\n",
      "Epoch:    3/60    Loss: 4.250750797922197\n",
      "\n",
      "Epoch:    3/60    Loss: 3.9251162407398223\n",
      "\n",
      "Epoch:    3/60    Loss: 3.914248083591461\n",
      "\n",
      "Epoch:    3/60    Loss: 3.94316263628006\n",
      "\n",
      "Epoch:    3/60    Loss: 4.029306303739547\n",
      "\n",
      "Epoch:    3/60    Loss: 4.083336960792542\n",
      "\n",
      "Epoch:    3/60    Loss: 4.0299128365516665\n",
      "\n",
      "Epoch:    3/60    Loss: 4.042876502275467\n",
      "\n",
      "Epoch:    3/60    Loss: 3.7869373910427093\n",
      "\n",
      "Epoch:    3/60    Loss: 4.123842885255813\n",
      "\n",
      "Epoch:    3/60    Loss: 3.9306966569423674\n",
      "\n",
      "Epoch:    3/60    Loss: 4.0140827729702\n",
      "\n",
      "Epoch:    3/60    Loss: 3.746992486476898\n",
      "\n",
      "Epoch:    3/60    Loss: 3.8321164903640748\n",
      "\n",
      "Epoch:    3/60    Loss: 3.746077346324921\n",
      "\n",
      "Epoch:    3/60    Loss: 3.8679626944065095\n",
      "\n",
      "Epoch:    3/60    Loss: 3.910302846431732\n",
      "\n",
      "Epoch:    3/60    Loss: 4.1163127307891845\n",
      "\n",
      "Epoch:    3/60    Loss: 4.018224453449249\n",
      "\n",
      "Epoch:    3/60    Loss: 3.9532341599464416\n",
      "\n",
      "Epoch:    3/60    Loss: 3.909925265073776\n",
      "\n",
      "Epoch:    3/60    Loss: 3.8639591455459597\n",
      "\n",
      "Epoch:    3/60    Loss: 4.18081232213974\n",
      "\n",
      "Epoch:    3/60    Loss: 3.945679934024811\n",
      "\n",
      "Epoch:    3/60    Loss: 4.076323775529861\n",
      "\n",
      "Epoch:    3/60    Loss: 4.16047481584549\n",
      "\n",
      "Epoch:    3/60    Loss: 4.019626809597016\n",
      "\n",
      "Epoch:    3/60    Loss: 4.157767161846161\n",
      "\n",
      "Epoch:    3/60    Loss: 4.025215100288391\n",
      "\n",
      "Epoch:    3/60    Loss: 3.989033597946167\n",
      "\n",
      "Epoch:    3/60    Loss: 3.8601762781143187\n",
      "\n",
      "Epoch:    3/60    Loss: 4.183839636325836\n",
      "\n",
      "Epoch:    3/60    Loss: 4.022508750200272\n",
      "\n",
      "Epoch:    3/60    Loss: 3.8207516753673554\n",
      "\n",
      "Epoch:    3/60    Loss: 3.8664631218910217\n",
      "\n",
      "Epoch:    3/60    Loss: 3.992371515750885\n",
      "\n",
      "Epoch:    3/60    Loss: 3.8129169692993163\n",
      "\n",
      "Epoch:    3/60    Loss: 4.052038418769836\n",
      "\n",
      "Epoch:    3/60    Loss: 3.994664577484131\n",
      "\n",
      "Epoch:    3/60    Loss: 3.8779393215179443\n",
      "\n",
      "Epoch:    3/60    Loss: 3.9145858850479125\n",
      "\n",
      "Epoch:    3/60    Loss: 3.9229103367328646\n",
      "\n",
      "Epoch:    3/60    Loss: 3.955868262529373\n",
      "\n",
      "Epoch:    3/60    Loss: 4.128921581983566\n",
      "\n",
      "Epoch:    3/60    Loss: 4.026408871173858\n",
      "\n",
      "Epoch:    3/60    Loss: 4.058253768444061\n",
      "\n",
      "Epoch:    3/60    Loss: 4.234986638069153\n",
      "\n",
      "Epoch:    3/60    Loss: 4.196707132339477\n",
      "\n",
      "Epoch:    3/60    Loss: 4.074207115650177\n",
      "\n",
      "Epoch:    3/60    Loss: 4.104648168563843\n",
      "\n",
      "Epoch:    3/60    Loss: 4.12827761554718\n",
      "\n",
      "Epoch:    3/60    Loss: 4.132703597545624\n",
      "\n",
      "Epoch:    3/60    Loss: 4.090524292230606\n",
      "\n",
      "Epoch:    3/60    Loss: 4.1452890601158146\n",
      "\n",
      "Epoch:    3/60    Loss: 4.129444852590561\n",
      "\n",
      "Epoch:    3/60    Loss: 4.151323220014572\n",
      "\n",
      "Epoch:    3/60    Loss: 3.975802195549011\n",
      "\n",
      "Epoch:    3/60    Loss: 4.234117865085602\n",
      "\n",
      "Epoch:    3/60    Loss: 3.9730878348350527\n",
      "\n",
      "Epoch:    4/60    Loss: 4.184733656923408\n",
      "\n",
      "Epoch:    4/60    Loss: 3.914286875963211\n",
      "\n",
      "Epoch:    4/60    Loss: 3.865648806810379\n",
      "\n",
      "Epoch:    4/60    Loss: 3.9025143425464632\n",
      "\n",
      "Epoch:    4/60    Loss: 3.9858370382785795\n",
      "\n",
      "Epoch:    4/60    Loss: 4.020926055908203\n",
      "\n",
      "Epoch:    4/60    Loss: 3.918301112651825\n",
      "\n",
      "Epoch:    4/60    Loss: 3.9387994062900544\n",
      "\n",
      "Epoch:    4/60    Loss: 3.6834995160102846\n",
      "\n",
      "Epoch:    4/60    Loss: 4.005870884895325\n",
      "\n",
      "Epoch:    4/60    Loss: 3.880285642147064\n",
      "\n",
      "Epoch:    4/60    Loss: 3.940782643079758\n",
      "\n",
      "Epoch:    4/60    Loss: 3.660971079349518\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    4/60    Loss: 3.729708338022232\n",
      "\n",
      "Epoch:    4/60    Loss: 3.6837831318378447\n",
      "\n",
      "Epoch:    4/60    Loss: 3.7861758847236633\n",
      "\n",
      "Epoch:    4/60    Loss: 3.851883688211441\n",
      "\n",
      "Epoch:    4/60    Loss: 4.0383371849060055\n",
      "\n",
      "Epoch:    4/60    Loss: 3.9950000686645506\n",
      "\n",
      "Epoch:    4/60    Loss: 3.900468761205673\n",
      "\n",
      "Epoch:    4/60    Loss: 3.837289304494858\n",
      "\n",
      "Epoch:    4/60    Loss: 3.780396887779236\n",
      "\n",
      "Epoch:    4/60    Loss: 4.057126965761185\n",
      "\n",
      "Epoch:    4/60    Loss: 3.9283308670520785\n",
      "\n",
      "Epoch:    4/60    Loss: 4.049860929012299\n",
      "\n",
      "Epoch:    4/60    Loss: 4.121878700256348\n",
      "\n",
      "Epoch:    4/60    Loss: 3.9498735902309416\n",
      "\n",
      "Epoch:    4/60    Loss: 4.0905147600173954\n",
      "\n",
      "Epoch:    4/60    Loss: 3.9671390261650084\n",
      "\n",
      "Epoch:    4/60    Loss: 3.9465711572170257\n",
      "\n",
      "Epoch:    4/60    Loss: 3.83036514043808\n",
      "\n",
      "Epoch:    4/60    Loss: 4.124916875839234\n",
      "\n",
      "Epoch:    4/60    Loss: 3.954480763912201\n",
      "\n",
      "Epoch:    4/60    Loss: 3.7412215039730072\n",
      "\n",
      "Epoch:    4/60    Loss: 3.723030748605728\n",
      "\n",
      "Epoch:    4/60    Loss: 3.905531548023224\n",
      "\n",
      "Epoch:    4/60    Loss: 3.7376203265190124\n",
      "\n",
      "Epoch:    4/60    Loss: 3.9991951546669005\n",
      "\n",
      "Epoch:    4/60    Loss: 3.917320873737335\n",
      "\n",
      "Epoch:    4/60    Loss: 3.7944553582668306\n",
      "\n",
      "Epoch:    4/60    Loss: 3.8629423995018004\n",
      "\n",
      "Epoch:    4/60    Loss: 3.8377852849960328\n",
      "\n",
      "Epoch:    4/60    Loss: 3.8805543835163117\n",
      "\n",
      "Epoch:    4/60    Loss: 4.047729310750961\n",
      "\n",
      "Epoch:    4/60    Loss: 3.916271938800812\n",
      "\n",
      "Epoch:    4/60    Loss: 3.999320381641388\n",
      "\n",
      "Epoch:    4/60    Loss: 4.154348774909973\n",
      "\n",
      "Epoch:    4/60    Loss: 4.1380528497695925\n",
      "\n",
      "Epoch:    4/60    Loss: 4.020527085781097\n",
      "\n",
      "Epoch:    4/60    Loss: 4.076804300069809\n",
      "\n",
      "Epoch:    4/60    Loss: 4.052146801948547\n",
      "\n",
      "Epoch:    4/60    Loss: 4.024033182382584\n",
      "\n",
      "Epoch:    4/60    Loss: 4.0529596912860875\n",
      "\n",
      "Epoch:    4/60    Loss: 4.10186659860611\n",
      "\n",
      "Epoch:    4/60    Loss: 4.068910949468613\n",
      "\n",
      "Epoch:    4/60    Loss: 4.104790388584137\n",
      "\n",
      "Epoch:    4/60    Loss: 3.9825770411491392\n",
      "\n",
      "Epoch:    4/60    Loss: 4.175799583911895\n",
      "\n",
      "Epoch:    4/60    Loss: 3.9753463881015776\n",
      "\n",
      "Epoch:    5/60    Loss: 4.097844849624064\n",
      "\n",
      "Epoch:    5/60    Loss: 3.828784527301788\n",
      "\n",
      "Epoch:    5/60    Loss: 3.7915471830368044\n",
      "\n",
      "Epoch:    5/60    Loss: 3.7971268219947816\n",
      "\n",
      "Epoch:    5/60    Loss: 3.9283235449790954\n",
      "\n",
      "Epoch:    5/60    Loss: 3.9659277534484865\n",
      "\n",
      "Epoch:    5/60    Loss: 3.84574959564209\n",
      "\n",
      "Epoch:    5/60    Loss: 3.843651285648346\n",
      "\n",
      "Epoch:    5/60    Loss: 3.6083807713985445\n",
      "\n",
      "Epoch:    5/60    Loss: 3.9355651507377623\n",
      "\n",
      "Epoch:    5/60    Loss: 3.7863817760944367\n",
      "\n",
      "Epoch:    5/60    Loss: 3.87999902009964\n",
      "\n",
      "Epoch:    5/60    Loss: 3.574395511388779\n",
      "\n",
      "Epoch:    5/60    Loss: 3.638563306570053\n",
      "\n",
      "Epoch:    5/60    Loss: 3.6250097687244414\n",
      "\n",
      "Epoch:    5/60    Loss: 3.6929680082798004\n",
      "\n",
      "Epoch:    5/60    Loss: 3.757768502235413\n",
      "\n",
      "Epoch:    5/60    Loss: 3.93716251206398\n",
      "\n",
      "Epoch:    5/60    Loss: 3.880793387413025\n",
      "\n",
      "Epoch:    5/60    Loss: 3.805861238241196\n",
      "\n",
      "Epoch:    5/60    Loss: 3.7415810153484346\n",
      "\n",
      "Epoch:    5/60    Loss: 3.7039615325927735\n",
      "\n",
      "Epoch:    5/60    Loss: 3.9595858035087583\n",
      "\n",
      "Epoch:    5/60    Loss: 3.8195024592876434\n",
      "\n",
      "Epoch:    5/60    Loss: 3.931761650323868\n",
      "\n",
      "Epoch:    5/60    Loss: 4.014524369955063\n",
      "\n",
      "Epoch:    5/60    Loss: 3.8668178052902222\n",
      "\n",
      "Epoch:    5/60    Loss: 4.016498373031617\n",
      "\n",
      "Epoch:    5/60    Loss: 3.860679790973663\n",
      "\n",
      "Epoch:    5/60    Loss: 3.810183493614197\n",
      "\n",
      "Epoch:    5/60    Loss: 3.695480749607086\n",
      "\n",
      "Epoch:    5/60    Loss: 3.984098320007324\n",
      "\n",
      "Epoch:    5/60    Loss: 3.849516926765442\n",
      "\n",
      "Epoch:    5/60    Loss: 3.6499430229663847\n",
      "\n",
      "Epoch:    5/60    Loss: 3.6218911139965058\n",
      "\n",
      "Epoch:    5/60    Loss: 3.833564812898636\n",
      "\n",
      "Epoch:    5/60    Loss: 3.661193711042404\n",
      "\n",
      "Epoch:    5/60    Loss: 3.9078928472995758\n",
      "\n",
      "Epoch:    5/60    Loss: 3.821103435993195\n",
      "\n",
      "Epoch:    5/60    Loss: 3.697388453722\n",
      "\n",
      "Epoch:    5/60    Loss: 3.8136048891544343\n",
      "\n",
      "Epoch:    5/60    Loss: 3.7856540055274963\n",
      "\n",
      "Epoch:    5/60    Loss: 3.8030316157341004\n",
      "\n",
      "Epoch:    5/60    Loss: 3.955633511543274\n",
      "\n",
      "Epoch:    5/60    Loss: 3.818228059053421\n",
      "\n",
      "Epoch:    5/60    Loss: 3.903260181903839\n",
      "\n",
      "Epoch:    5/60    Loss: 4.096767734050751\n",
      "\n",
      "Epoch:    5/60    Loss: 4.07127855348587\n",
      "\n",
      "Epoch:    5/60    Loss: 3.988435635566711\n",
      "\n",
      "Epoch:    5/60    Loss: 4.029611707448959\n",
      "\n",
      "Epoch:    5/60    Loss: 3.9816808195114137\n",
      "\n",
      "Epoch:    5/60    Loss: 4.012894055128098\n",
      "\n",
      "Epoch:    5/60    Loss: 3.9835224540233614\n",
      "\n",
      "Epoch:    5/60    Loss: 4.049765089035034\n",
      "\n",
      "Epoch:    5/60    Loss: 3.9708551032543182\n",
      "\n",
      "Epoch:    5/60    Loss: 4.0643724403381345\n",
      "\n",
      "Epoch:    5/60    Loss: 3.9051042773723603\n",
      "\n",
      "Epoch:    5/60    Loss: 4.117882941961288\n",
      "\n",
      "Epoch:    5/60    Loss: 3.9175322914123534\n",
      "\n",
      "Epoch:    6/60    Loss: 4.04913871055064\n",
      "\n",
      "Epoch:    6/60    Loss: 3.8106752781867983\n",
      "\n",
      "Epoch:    6/60    Loss: 3.7331402907371523\n",
      "\n",
      "Epoch:    6/60    Loss: 3.736544463634491\n",
      "\n",
      "Epoch:    6/60    Loss: 3.864188212633133\n",
      "\n",
      "Epoch:    6/60    Loss: 3.888409194469452\n",
      "\n",
      "Epoch:    6/60    Loss: 3.799902782201767\n",
      "\n",
      "Epoch:    6/60    Loss: 3.7798652896881104\n",
      "\n",
      "Epoch:    6/60    Loss: 3.5515146079063418\n",
      "\n",
      "Epoch:    6/60    Loss: 3.874164961576462\n",
      "\n",
      "Epoch:    6/60    Loss: 3.73828484082222\n",
      "\n",
      "Epoch:    6/60    Loss: 3.840934360027313\n",
      "\n",
      "Epoch:    6/60    Loss: 3.573694751024246\n",
      "\n",
      "Epoch:    6/60    Loss: 3.633674203634262\n",
      "\n",
      "Epoch:    6/60    Loss: 3.571234460115433\n",
      "\n",
      "Epoch:    6/60    Loss: 3.651729145050049\n",
      "\n",
      "Epoch:    6/60    Loss: 3.6977679817676545\n",
      "\n",
      "Epoch:    6/60    Loss: 3.8667835631370546\n",
      "\n",
      "Epoch:    6/60    Loss: 3.830215758562088\n",
      "\n",
      "Epoch:    6/60    Loss: 3.7869247341156007\n",
      "\n",
      "Epoch:    6/60    Loss: 3.6622869288921356\n",
      "\n",
      "Epoch:    6/60    Loss: 3.614857929468155\n",
      "\n",
      "Epoch:    6/60    Loss: 3.8655201897621154\n",
      "\n",
      "Epoch:    6/60    Loss: 3.7307353348731995\n",
      "\n",
      "Epoch:    6/60    Loss: 3.8623774743080137\n",
      "\n",
      "Epoch:    6/60    Loss: 3.9321649601459505\n",
      "\n",
      "Epoch:    6/60    Loss: 3.8124815175533295\n",
      "\n",
      "Epoch:    6/60    Loss: 3.894720826625824\n",
      "\n",
      "Epoch:    6/60    Loss: 3.7567529780864715\n",
      "\n",
      "Epoch:    6/60    Loss: 3.7267847936153413\n",
      "\n",
      "Epoch:    6/60    Loss: 3.5973722019195558\n",
      "\n",
      "Epoch:    6/60    Loss: 3.9082692403793335\n",
      "\n",
      "Epoch:    6/60    Loss: 3.799652024269104\n",
      "\n",
      "Epoch:    6/60    Loss: 3.60671950006485\n",
      "\n",
      "Epoch:    6/60    Loss: 3.5833284051418306\n",
      "\n",
      "Epoch:    6/60    Loss: 3.7489094302654267\n",
      "\n",
      "Epoch:    6/60    Loss: 3.594226236343384\n",
      "\n",
      "Epoch:    6/60    Loss: 3.837468341588974\n",
      "\n",
      "Epoch:    6/60    Loss: 3.746499710083008\n",
      "\n",
      "Epoch:    6/60    Loss: 3.642067765712738\n",
      "\n",
      "Epoch:    6/60    Loss: 3.736544775724411\n",
      "\n",
      "Epoch:    6/60    Loss: 3.7118086080551147\n",
      "\n",
      "Epoch:    6/60    Loss: 3.7266146104335784\n",
      "\n",
      "Epoch:    6/60    Loss: 3.8228844656944276\n",
      "\n",
      "Epoch:    6/60    Loss: 3.7350820441246033\n",
      "\n",
      "Epoch:    6/60    Loss: 3.845863143444061\n",
      "\n",
      "Epoch:    6/60    Loss: 4.009049328804016\n",
      "\n",
      "Epoch:    6/60    Loss: 3.99966006565094\n",
      "\n",
      "Epoch:    6/60    Loss: 3.9011569049358368\n",
      "\n",
      "Epoch:    6/60    Loss: 3.9519304883480073\n",
      "\n",
      "Epoch:    6/60    Loss: 3.938504410266876\n",
      "\n",
      "Epoch:    6/60    Loss: 3.9310884656906127\n",
      "\n",
      "Epoch:    6/60    Loss: 3.930112681865692\n",
      "\n",
      "Epoch:    6/60    Loss: 4.030239832401276\n",
      "\n",
      "Epoch:    6/60    Loss: 3.941018092870712\n",
      "\n",
      "Epoch:    6/60    Loss: 3.9544375257492064\n",
      "\n",
      "Epoch:    6/60    Loss: 3.7697881858348845\n",
      "\n",
      "Epoch:    6/60    Loss: 4.005310119390487\n",
      "\n",
      "Epoch:    6/60    Loss: 3.816432174682617\n",
      "\n",
      "Epoch:    7/60    Loss: 3.9897882389309616\n",
      "\n",
      "Epoch:    7/60    Loss: 3.778581902503967\n",
      "\n",
      "Epoch:    7/60    Loss: 3.686000163078308\n",
      "\n",
      "Epoch:    7/60    Loss: 3.701802495479584\n",
      "\n",
      "Epoch:    7/60    Loss: 3.765045377969742\n",
      "\n",
      "Epoch:    7/60    Loss: 3.808631047010422\n",
      "\n",
      "Epoch:    7/60    Loss: 3.742760512828827\n",
      "\n",
      "Epoch:    7/60    Loss: 3.7091941986083983\n",
      "\n",
      "Epoch:    7/60    Loss: 3.473218906402588\n",
      "\n",
      "Epoch:    7/60    Loss: 3.7973140218257906\n",
      "\n",
      "Epoch:    7/60    Loss: 3.638468101739883\n",
      "\n",
      "Epoch:    7/60    Loss: 3.751542142868042\n",
      "\n",
      "Epoch:    7/60    Loss: 3.508015439748764\n",
      "\n",
      "Epoch:    7/60    Loss: 3.563832541227341\n",
      "\n",
      "Epoch:    7/60    Loss: 3.517354857683182\n",
      "\n",
      "Epoch:    7/60    Loss: 3.597262838602066\n",
      "\n",
      "Epoch:    7/60    Loss: 3.6181649644374847\n",
      "\n",
      "Epoch:    7/60    Loss: 3.7884272160530092\n",
      "\n",
      "Epoch:    7/60    Loss: 3.7610038650035857\n",
      "\n",
      "Epoch:    7/60    Loss: 3.6764439175128936\n",
      "\n",
      "Epoch:    7/60    Loss: 3.6012875263690947\n",
      "\n",
      "Epoch:    7/60    Loss: 3.567130274772644\n",
      "\n",
      "Epoch:    7/60    Loss: 3.825834000825882\n",
      "\n",
      "Epoch:    7/60    Loss: 3.675629364013672\n",
      "\n",
      "Epoch:    7/60    Loss: 3.808701804637909\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    7/60    Loss: 3.8757731997966767\n",
      "\n",
      "Epoch:    7/60    Loss: 3.7476639981269835\n",
      "\n",
      "Epoch:    7/60    Loss: 3.8593687086105346\n",
      "\n",
      "Epoch:    7/60    Loss: 3.7231946861743928\n",
      "\n",
      "Epoch:    7/60    Loss: 3.6708181862831117\n",
      "\n",
      "Epoch:    7/60    Loss: 3.5521518626213076\n",
      "\n",
      "Epoch:    7/60    Loss: 3.874047056674957\n",
      "\n",
      "Epoch:    7/60    Loss: 3.734549289226532\n",
      "\n",
      "Epoch:    7/60    Loss: 3.5545007317066193\n",
      "\n",
      "Epoch:    7/60    Loss: 3.5176464920043946\n",
      "\n",
      "Epoch:    7/60    Loss: 3.667836847305298\n",
      "\n",
      "Epoch:    7/60    Loss: 3.5436180019378662\n",
      "\n",
      "Epoch:    7/60    Loss: 3.745401458263397\n",
      "\n",
      "Epoch:    7/60    Loss: 3.7001532146930693\n",
      "\n",
      "Epoch:    7/60    Loss: 3.5840956127643584\n",
      "\n",
      "Epoch:    7/60    Loss: 3.6670471658706667\n",
      "\n",
      "Epoch:    7/60    Loss: 3.6500742745399477\n",
      "\n",
      "Epoch:    7/60    Loss: 3.679114816904068\n",
      "\n",
      "Epoch:    7/60    Loss: 3.7834524478912352\n",
      "\n",
      "Epoch:    7/60    Loss: 3.675047170639038\n",
      "\n",
      "Epoch:    7/60    Loss: 3.7911734120845795\n",
      "\n",
      "Epoch:    7/60    Loss: 3.932958755016327\n",
      "\n",
      "Epoch:    7/60    Loss: 3.9293767795562746\n",
      "\n",
      "Epoch:    7/60    Loss: 3.8518361163139345\n",
      "\n",
      "Epoch:    7/60    Loss: 3.904269580364227\n",
      "\n",
      "Epoch:    7/60    Loss: 3.8785188517570495\n",
      "\n",
      "Epoch:    7/60    Loss: 3.850238511323929\n",
      "\n",
      "Epoch:    7/60    Loss: 3.870778109550476\n",
      "\n",
      "Epoch:    7/60    Loss: 3.9839150035381317\n",
      "\n",
      "Epoch:    7/60    Loss: 3.872526345729828\n",
      "\n",
      "Epoch:    7/60    Loss: 3.888511035203934\n",
      "\n",
      "Epoch:    7/60    Loss: 3.7889062201976778\n",
      "\n",
      "Epoch:    7/60    Loss: 3.975102250576019\n",
      "\n",
      "Epoch:    7/60    Loss: 3.7703021459579467\n",
      "\n",
      "Epoch:    8/60    Loss: 3.9288163611098477\n",
      "\n",
      "Epoch:    8/60    Loss: 3.725694377422333\n",
      "\n",
      "Epoch:    8/60    Loss: 3.600246710062027\n",
      "\n",
      "Epoch:    8/60    Loss: 3.621817303419113\n",
      "\n",
      "Epoch:    8/60    Loss: 3.707548088788986\n",
      "\n",
      "Epoch:    8/60    Loss: 3.737004664182663\n",
      "\n",
      "Epoch:    8/60    Loss: 3.671135634660721\n",
      "\n",
      "Epoch:    8/60    Loss: 3.640261929512024\n",
      "\n",
      "Epoch:    8/60    Loss: 3.4046792914867403\n",
      "\n",
      "Epoch:    8/60    Loss: 3.7023404791355135\n",
      "\n",
      "Epoch:    8/60    Loss: 3.5890075125694274\n",
      "\n",
      "Epoch:    8/60    Loss: 3.682610872268677\n",
      "\n",
      "Epoch:    8/60    Loss: 3.453173261165619\n",
      "\n",
      "Epoch:    8/60    Loss: 3.492424210071564\n",
      "\n",
      "Epoch:    8/60    Loss: 3.463555696964264\n",
      "\n",
      "Epoch:    8/60    Loss: 3.512752742290497\n",
      "\n",
      "Epoch:    8/60    Loss: 3.5436580097675323\n",
      "\n",
      "Epoch:    8/60    Loss: 3.6830229918956756\n",
      "\n",
      "Epoch:    8/60    Loss: 3.668008337497711\n",
      "\n",
      "Epoch:    8/60    Loss: 3.5667754971981047\n",
      "\n",
      "Epoch:    8/60    Loss: 3.5671004915237425\n",
      "\n",
      "Epoch:    8/60    Loss: 3.5346662466526033\n",
      "\n",
      "Epoch:    8/60    Loss: 3.795267871379852\n",
      "\n",
      "Epoch:    8/60    Loss: 3.6163527352809908\n",
      "\n",
      "Epoch:    8/60    Loss: 3.7290788989067076\n",
      "\n",
      "Epoch:    8/60    Loss: 3.8055024130344393\n",
      "\n",
      "Epoch:    8/60    Loss: 3.658055276632309\n",
      "\n",
      "Epoch:    8/60    Loss: 3.7649919054508207\n",
      "\n",
      "Epoch:    8/60    Loss: 3.609391571044922\n",
      "\n",
      "Epoch:    8/60    Loss: 3.5772050626277925\n",
      "\n",
      "Epoch:    8/60    Loss: 3.4774184222221374\n",
      "\n",
      "Epoch:    8/60    Loss: 3.831024895429611\n",
      "\n",
      "Epoch:    8/60    Loss: 3.6811555156707763\n",
      "\n",
      "Epoch:    8/60    Loss: 3.508899646282196\n",
      "\n",
      "Epoch:    8/60    Loss: 3.4739223161935806\n",
      "\n",
      "Epoch:    8/60    Loss: 3.618792956352234\n",
      "\n",
      "Epoch:    8/60    Loss: 3.489440856218338\n",
      "\n",
      "Epoch:    8/60    Loss: 3.6561764039993285\n",
      "\n",
      "Epoch:    8/60    Loss: 3.617253879070282\n",
      "\n",
      "Epoch:    8/60    Loss: 3.530184979915619\n",
      "\n",
      "Epoch:    8/60    Loss: 3.594269181251526\n",
      "\n",
      "Epoch:    8/60    Loss: 3.574828743457794\n",
      "\n",
      "Epoch:    8/60    Loss: 3.620969788789749\n",
      "\n",
      "Epoch:    8/60    Loss: 3.7073093342781065\n",
      "\n",
      "Epoch:    8/60    Loss: 3.6110213897228243\n",
      "\n",
      "Epoch:    8/60    Loss: 3.724043968677521\n",
      "\n",
      "Epoch:    8/60    Loss: 3.8554792103767395\n",
      "\n",
      "Epoch:    8/60    Loss: 3.8675808320045473\n",
      "\n",
      "Epoch:    8/60    Loss: 3.789744598865509\n",
      "\n",
      "Epoch:    8/60    Loss: 3.815082355976105\n",
      "\n",
      "Epoch:    8/60    Loss: 3.7897395873069764\n",
      "\n",
      "Epoch:    8/60    Loss: 3.810154887676239\n",
      "\n",
      "Epoch:    8/60    Loss: 3.838450210809708\n",
      "\n",
      "Epoch:    8/60    Loss: 3.927894937515259\n",
      "\n",
      "Epoch:    8/60    Loss: 3.7934266760349273\n",
      "\n",
      "Epoch:    8/60    Loss: 3.864465275526047\n",
      "\n",
      "Epoch:    8/60    Loss: 3.713022535085678\n",
      "\n",
      "Epoch:    8/60    Loss: 3.91150870013237\n",
      "\n",
      "Epoch:    8/60    Loss: 3.6868603880405426\n",
      "\n",
      "Epoch:    9/60    Loss: 3.8674727153518926\n",
      "\n",
      "Epoch:    9/60    Loss: 3.6749047703742983\n",
      "\n",
      "Epoch:    9/60    Loss: 3.5415132715702056\n",
      "\n",
      "Epoch:    9/60    Loss: 3.57811181640625\n",
      "\n",
      "Epoch:    9/60    Loss: 3.635637539386749\n",
      "\n",
      "Epoch:    9/60    Loss: 3.6814722259044648\n",
      "\n",
      "Epoch:    9/60    Loss: 3.616035396337509\n",
      "\n",
      "Epoch:    9/60    Loss: 3.586923178434372\n",
      "\n",
      "Epoch:    9/60    Loss: 3.3702004249095916\n",
      "\n",
      "Epoch:    9/60    Loss: 3.6537012503147124\n",
      "\n",
      "Epoch:    9/60    Loss: 3.5491888966560365\n",
      "\n",
      "Epoch:    9/60    Loss: 3.6332018735408784\n",
      "\n",
      "Epoch:    9/60    Loss: 3.4165285243988035\n",
      "\n",
      "Epoch:    9/60    Loss: 3.4704237897396086\n",
      "\n",
      "Epoch:    9/60    Loss: 3.4306859278678896\n",
      "\n",
      "Epoch:    9/60    Loss: 3.4894718856811524\n",
      "\n",
      "Epoch:    9/60    Loss: 3.5137692317962648\n",
      "\n",
      "Epoch:    9/60    Loss: 3.6418300313949583\n",
      "\n",
      "Epoch:    9/60    Loss: 3.6147139329910276\n",
      "\n",
      "Epoch:    9/60    Loss: 3.5125934655666353\n",
      "\n",
      "Epoch:    9/60    Loss: 3.533508552312851\n",
      "\n",
      "Epoch:    9/60    Loss: 3.5179746882915497\n",
      "\n",
      "Epoch:    9/60    Loss: 3.7500924179553987\n",
      "\n",
      "Epoch:    9/60    Loss: 3.5749093902111055\n",
      "\n",
      "Epoch:    9/60    Loss: 3.6834502825737\n",
      "\n",
      "Epoch:    9/60    Loss: 3.7641498599052428\n",
      "\n",
      "Epoch:    9/60    Loss: 3.6205097131729125\n",
      "\n",
      "Epoch:    9/60    Loss: 3.6914693839550017\n",
      "\n",
      "Epoch:    9/60    Loss: 3.5589679641723633\n",
      "\n",
      "Epoch:    9/60    Loss: 3.5537779562473295\n",
      "\n",
      "Epoch:    9/60    Loss: 3.4364824957847597\n",
      "\n",
      "Epoch:    9/60    Loss: 3.7584059171676634\n",
      "\n",
      "Epoch:    9/60    Loss: 3.643512302160263\n",
      "\n",
      "Epoch:    9/60    Loss: 3.4688806002140047\n",
      "\n",
      "Epoch:    9/60    Loss: 3.4369710812568663\n",
      "\n",
      "Epoch:    9/60    Loss: 3.5699786858558653\n",
      "\n",
      "Epoch:    9/60    Loss: 3.4497231612205503\n",
      "\n",
      "Epoch:    9/60    Loss: 3.61539053106308\n",
      "\n",
      "Epoch:    9/60    Loss: 3.5719607849121093\n",
      "\n",
      "Epoch:    9/60    Loss: 3.490773800611496\n",
      "\n",
      "Epoch:    9/60    Loss: 3.53324223279953\n",
      "\n",
      "Epoch:    9/60    Loss: 3.5380627074241637\n",
      "\n",
      "Epoch:    9/60    Loss: 3.587788015842438\n",
      "\n",
      "Epoch:    9/60    Loss: 3.6637820842266082\n",
      "\n",
      "Epoch:    9/60    Loss: 3.5827491250038146\n",
      "\n",
      "Epoch:    9/60    Loss: 3.714970386505127\n",
      "\n",
      "Epoch:    9/60    Loss: 3.8154319381713866\n",
      "\n",
      "Epoch:    9/60    Loss: 3.78645583486557\n",
      "\n",
      "Epoch:    9/60    Loss: 3.728056159734726\n",
      "\n",
      "Epoch:    9/60    Loss: 3.7769299249649047\n",
      "\n",
      "Epoch:    9/60    Loss: 3.74681187915802\n",
      "\n",
      "Epoch:    9/60    Loss: 3.7833212683200834\n",
      "\n",
      "Epoch:    9/60    Loss: 3.8019082539081572\n",
      "\n",
      "Epoch:    9/60    Loss: 3.8938212351799013\n",
      "\n",
      "Epoch:    9/60    Loss: 3.8006691815853118\n",
      "\n",
      "Epoch:    9/60    Loss: 3.7803919401168824\n",
      "\n",
      "Epoch:    9/60    Loss: 3.658997056722641\n",
      "\n",
      "Epoch:    9/60    Loss: 3.865464338541031\n",
      "\n",
      "Epoch:    9/60    Loss: 3.64456339764595\n",
      "\n",
      "Epoch:   10/60    Loss: 3.7916903244736404\n",
      "\n",
      "Epoch:   10/60    Loss: 3.6200971689224244\n",
      "\n",
      "Epoch:   10/60    Loss: 3.4918792915344237\n",
      "\n",
      "Epoch:   10/60    Loss: 3.5388222699165346\n",
      "\n",
      "Epoch:   10/60    Loss: 3.5898152887821198\n",
      "\n",
      "Epoch:   10/60    Loss: 3.6339627029895785\n",
      "\n",
      "Epoch:   10/60    Loss: 3.5824939963817597\n",
      "\n",
      "Epoch:   10/60    Loss: 3.550046229124069\n",
      "\n",
      "Epoch:   10/60    Loss: 3.345297247886658\n",
      "\n",
      "Epoch:   10/60    Loss: 3.6202656383514404\n",
      "\n",
      "Epoch:   10/60    Loss: 3.513807405948639\n",
      "\n",
      "Epoch:   10/60    Loss: 3.5648553109169008\n",
      "\n",
      "Epoch:   10/60    Loss: 3.3616503007411955\n",
      "\n",
      "Epoch:   10/60    Loss: 3.425822139263153\n",
      "\n",
      "Epoch:   10/60    Loss: 3.4019061806201933\n",
      "\n",
      "Epoch:   10/60    Loss: 3.4350856640338896\n",
      "\n",
      "Epoch:   10/60    Loss: 3.4428398308753967\n",
      "\n",
      "Epoch:   10/60    Loss: 3.580134294271469\n",
      "\n",
      "Epoch:   10/60    Loss: 3.5586517100334167\n",
      "\n",
      "Epoch:   10/60    Loss: 3.4409358966350556\n",
      "\n",
      "Epoch:   10/60    Loss: 3.4837193727493285\n",
      "\n",
      "Epoch:   10/60    Loss: 3.446145947933197\n",
      "\n",
      "Epoch:   10/60    Loss: 3.683572547197342\n",
      "\n",
      "Epoch:   10/60    Loss: 3.5316928112506867\n",
      "\n",
      "Epoch:   10/60    Loss: 3.623553609609604\n",
      "\n",
      "Epoch:   10/60    Loss: 3.6879937267303466\n",
      "\n",
      "Epoch:   10/60    Loss: 3.5404200282096863\n",
      "\n",
      "Epoch:   10/60    Loss: 3.618318155050278\n",
      "\n",
      "Epoch:   10/60    Loss: 3.5089039578437804\n",
      "\n",
      "Epoch:   10/60    Loss: 3.4897194488048555\n",
      "\n",
      "Epoch:   10/60    Loss: 3.370453464269638\n",
      "\n",
      "Epoch:   10/60    Loss: 3.6795973234176635\n",
      "\n",
      "Epoch:   10/60    Loss: 3.5879672803878786\n",
      "\n",
      "Epoch:   10/60    Loss: 3.409100648164749\n",
      "\n",
      "Epoch:   10/60    Loss: 3.3936631331443787\n",
      "\n",
      "Epoch:   10/60    Loss: 3.510334067106247\n",
      "\n",
      "Epoch:   10/60    Loss: 3.4008598058223725\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   10/60    Loss: 3.5584982147216797\n",
      "\n",
      "Epoch:   10/60    Loss: 3.5097120525836947\n",
      "\n",
      "Epoch:   10/60    Loss: 3.4547658886909485\n",
      "\n",
      "Epoch:   10/60    Loss: 3.4657480516433714\n",
      "\n",
      "Epoch:   10/60    Loss: 3.4924599905014038\n",
      "\n",
      "Epoch:   10/60    Loss: 3.5465559515953062\n",
      "\n",
      "Epoch:   10/60    Loss: 3.6250047516822814\n",
      "\n",
      "Epoch:   10/60    Loss: 3.558868219137192\n",
      "\n",
      "Epoch:   10/60    Loss: 3.6529250473976136\n",
      "\n",
      "Epoch:   10/60    Loss: 3.7863014068603515\n",
      "\n",
      "Epoch:   10/60    Loss: 3.7193010082244875\n",
      "\n",
      "Epoch:   10/60    Loss: 3.673429448366165\n",
      "\n",
      "Epoch:   10/60    Loss: 3.712593658924103\n",
      "\n",
      "Epoch:   10/60    Loss: 3.69113086271286\n",
      "\n",
      "Epoch:   10/60    Loss: 3.727460372686386\n",
      "\n",
      "Epoch:   10/60    Loss: 3.7415526093244553\n",
      "\n",
      "Epoch:   10/60    Loss: 3.795404575109482\n",
      "\n",
      "Epoch:   10/60    Loss: 3.713820204734802\n",
      "\n",
      "Epoch:   10/60    Loss: 3.6860624089241028\n",
      "\n",
      "Epoch:   10/60    Loss: 3.5882261383533476\n",
      "\n",
      "Epoch:   10/60    Loss: 3.7736968326568605\n",
      "\n",
      "Epoch:   10/60    Loss: 3.592023967504501\n",
      "\n",
      "Epoch:   11/60    Loss: 3.762373757751092\n",
      "\n",
      "Epoch:   11/60    Loss: 3.605390557765961\n",
      "\n",
      "Epoch:   11/60    Loss: 3.4750542118549346\n",
      "\n",
      "Epoch:   11/60    Loss: 3.536714929819107\n",
      "\n",
      "Epoch:   11/60    Loss: 3.5823006427288053\n",
      "\n",
      "Epoch:   11/60    Loss: 3.6050270714759827\n",
      "\n",
      "Epoch:   11/60    Loss: 3.5505755183696746\n",
      "\n",
      "Epoch:   11/60    Loss: 3.5023224608898165\n",
      "\n",
      "Epoch:   11/60    Loss: 3.3136247324943544\n",
      "\n",
      "Epoch:   11/60    Loss: 3.579969510555267\n",
      "\n",
      "Epoch:   11/60    Loss: 3.4812975516319273\n",
      "\n",
      "Epoch:   11/60    Loss: 3.531459974050522\n",
      "\n",
      "Epoch:   11/60    Loss: 3.333946119070053\n",
      "\n",
      "Epoch:   11/60    Loss: 3.3904587903022767\n",
      "\n",
      "Epoch:   11/60    Loss: 3.3600435338020325\n",
      "\n",
      "Epoch:   11/60    Loss: 3.3978937523365023\n",
      "\n",
      "Epoch:   11/60    Loss: 3.395810935497284\n",
      "\n",
      "Epoch:   11/60    Loss: 3.5464040360450744\n",
      "\n",
      "Epoch:   11/60    Loss: 3.5209201378822326\n",
      "\n",
      "Epoch:   11/60    Loss: 3.4239779448509218\n",
      "\n",
      "Epoch:   11/60    Loss: 3.4494804124832155\n",
      "\n",
      "Epoch:   11/60    Loss: 3.4147557990550994\n",
      "\n",
      "Epoch:   11/60    Loss: 3.6435554578304292\n",
      "\n",
      "Epoch:   11/60    Loss: 3.480894809484482\n",
      "\n",
      "Epoch:   11/60    Loss: 3.5749907920360564\n",
      "\n",
      "Epoch:   11/60    Loss: 3.6355729875564573\n",
      "\n",
      "Epoch:   11/60    Loss: 3.4996128878593447\n",
      "\n",
      "Epoch:   11/60    Loss: 3.581681033849716\n",
      "\n",
      "Epoch:   11/60    Loss: 3.503224030256271\n",
      "\n",
      "Epoch:   11/60    Loss: 3.461798913478851\n",
      "\n",
      "Epoch:   11/60    Loss: 3.3247987124919893\n",
      "\n",
      "Epoch:   11/60    Loss: 3.630829516887665\n",
      "\n",
      "Epoch:   11/60    Loss: 3.5614179203510283\n",
      "\n",
      "Epoch:   11/60    Loss: 3.3818553814888\n",
      "\n",
      "Epoch:   11/60    Loss: 3.349005355358124\n",
      "\n",
      "Epoch:   11/60    Loss: 3.4894536139965058\n",
      "\n",
      "Epoch:   11/60    Loss: 3.3905297176837923\n",
      "\n",
      "Epoch:   11/60    Loss: 3.526557269334793\n",
      "\n",
      "Epoch:   11/60    Loss: 3.5017120003700257\n",
      "\n",
      "Epoch:   11/60    Loss: 3.4326830575466154\n",
      "\n",
      "Epoch:   11/60    Loss: 3.455827918291092\n",
      "\n",
      "Epoch:   11/60    Loss: 3.448095640659332\n",
      "\n",
      "Epoch:   11/60    Loss: 3.5406017334461213\n",
      "\n",
      "Epoch:   11/60    Loss: 3.6441096906661987\n",
      "\n",
      "Epoch:   11/60    Loss: 3.6104516475200654\n",
      "\n",
      "Epoch:   11/60    Loss: 3.627206099033356\n",
      "\n",
      "Epoch:   11/60    Loss: 3.728110293626785\n",
      "\n",
      "Epoch:   11/60    Loss: 3.663515791416168\n",
      "\n",
      "Epoch:   11/60    Loss: 3.641201601266861\n",
      "\n",
      "Epoch:   11/60    Loss: 3.692295907974243\n",
      "\n",
      "Epoch:   11/60    Loss: 3.6510821900367736\n",
      "\n",
      "Epoch:   11/60    Loss: 3.6898596770763397\n",
      "\n",
      "Epoch:   11/60    Loss: 3.7123113532066343\n",
      "\n",
      "Epoch:   11/60    Loss: 3.7464305720329283\n",
      "\n",
      "Epoch:   11/60    Loss: 3.6756236519813537\n",
      "\n",
      "Epoch:   11/60    Loss: 3.6677811672687533\n",
      "\n",
      "Epoch:   11/60    Loss: 3.568403673410416\n",
      "\n",
      "Epoch:   11/60    Loss: 3.716959187269211\n",
      "\n",
      "Epoch:   11/60    Loss: 3.533947014570236\n",
      "\n",
      "Epoch:   12/60    Loss: 3.722932328672513\n",
      "\n",
      "Epoch:   12/60    Loss: 3.5986595990657806\n",
      "\n",
      "Epoch:   12/60    Loss: 3.457977991819382\n",
      "\n",
      "Epoch:   12/60    Loss: 3.5109978659152983\n",
      "\n",
      "Epoch:   12/60    Loss: 3.5520497162342073\n",
      "\n",
      "Epoch:   12/60    Loss: 3.5855153365135193\n",
      "\n",
      "Epoch:   12/60    Loss: 3.5298806276321413\n",
      "\n",
      "Epoch:   12/60    Loss: 3.469061761379242\n",
      "\n",
      "Epoch:   12/60    Loss: 3.3100754446983336\n",
      "\n",
      "Epoch:   12/60    Loss: 3.556035200834274\n",
      "\n",
      "Epoch:   12/60    Loss: 3.452882736682892\n",
      "\n",
      "Epoch:   12/60    Loss: 3.49192986702919\n",
      "\n",
      "Epoch:   12/60    Loss: 3.2953031046390535\n",
      "\n",
      "Epoch:   12/60    Loss: 3.3394475333690643\n",
      "\n",
      "Epoch:   12/60    Loss: 3.3482992713451387\n",
      "\n",
      "Epoch:   12/60    Loss: 3.3689435324668886\n",
      "\n",
      "Epoch:   12/60    Loss: 3.393075595855713\n",
      "\n",
      "Epoch:   12/60    Loss: 3.522240922451019\n",
      "\n",
      "Epoch:   12/60    Loss: 3.475549899339676\n",
      "\n",
      "Epoch:   12/60    Loss: 3.3864578609466554\n",
      "\n",
      "Epoch:   12/60    Loss: 3.4164824833869933\n",
      "\n",
      "Epoch:   12/60    Loss: 3.416160554647446\n",
      "\n",
      "Epoch:   12/60    Loss: 3.577465455532074\n",
      "\n",
      "Epoch:   12/60    Loss: 3.451311095237732\n",
      "\n",
      "Epoch:   12/60    Loss: 3.5386988213062285\n",
      "\n",
      "Epoch:   12/60    Loss: 3.5954009222984316\n",
      "\n",
      "Epoch:   12/60    Loss: 3.459300685405731\n",
      "\n",
      "Epoch:   12/60    Loss: 3.550304529428482\n",
      "\n",
      "Epoch:   12/60    Loss: 3.4809310131072997\n",
      "\n",
      "Epoch:   12/60    Loss: 3.4384466779232024\n",
      "\n",
      "Epoch:   12/60    Loss: 3.288239565849304\n",
      "\n",
      "Epoch:   12/60    Loss: 3.603840918540955\n",
      "\n",
      "Epoch:   12/60    Loss: 3.511156045913696\n",
      "\n",
      "Epoch:   12/60    Loss: 3.3363916277885437\n",
      "\n",
      "Epoch:   12/60    Loss: 3.3285923931598664\n",
      "\n",
      "Epoch:   12/60    Loss: 3.4682236449718475\n",
      "\n",
      "Epoch:   12/60    Loss: 3.3543639905452727\n",
      "\n",
      "Epoch:   12/60    Loss: 3.468362466096878\n",
      "\n",
      "Epoch:   12/60    Loss: 3.449130399465561\n",
      "\n",
      "Epoch:   12/60    Loss: 3.387033580780029\n",
      "\n",
      "Epoch:   12/60    Loss: 3.4077745056152344\n",
      "\n",
      "Epoch:   12/60    Loss: 3.3863085446357726\n",
      "\n",
      "Epoch:   12/60    Loss: 3.4775174956321715\n",
      "\n",
      "Epoch:   12/60    Loss: 3.5716629276275635\n",
      "\n",
      "Epoch:   12/60    Loss: 3.5267696352005005\n",
      "\n",
      "Epoch:   12/60    Loss: 3.554508596420288\n",
      "\n",
      "Epoch:   12/60    Loss: 3.638662242412567\n",
      "\n",
      "Epoch:   12/60    Loss: 3.543053324699402\n",
      "\n",
      "Epoch:   12/60    Loss: 3.5590641334056854\n",
      "\n",
      "Epoch:   12/60    Loss: 3.6146525695323946\n",
      "\n",
      "Epoch:   12/60    Loss: 3.5644933471679687\n",
      "\n",
      "Epoch:   12/60    Loss: 3.6006943662166595\n",
      "\n",
      "Epoch:   12/60    Loss: 3.6137799098491667\n",
      "\n",
      "Epoch:   12/60    Loss: 3.6409624662399294\n",
      "\n",
      "Epoch:   12/60    Loss: 3.62011626791954\n",
      "\n",
      "Epoch:   12/60    Loss: 3.6179453299045563\n",
      "\n",
      "Epoch:   12/60    Loss: 3.5239859890937804\n",
      "\n",
      "Epoch:   12/60    Loss: 3.652615890264511\n",
      "\n",
      "Epoch:   12/60    Loss: 3.4879220027923585\n",
      "\n",
      "Epoch:   13/60    Loss: 3.668476427864769\n",
      "\n",
      "Epoch:   13/60    Loss: 3.551484389781952\n",
      "\n",
      "Epoch:   13/60    Loss: 3.410887631177902\n",
      "\n",
      "Epoch:   13/60    Loss: 3.4455637443065643\n",
      "\n",
      "Epoch:   13/60    Loss: 3.4497782208919525\n",
      "\n",
      "Epoch:   13/60    Loss: 3.4943095734119414\n",
      "\n",
      "Epoch:   13/60    Loss: 3.497854811191559\n",
      "\n",
      "Epoch:   13/60    Loss: 3.4348411281108855\n",
      "\n",
      "Epoch:   13/60    Loss: 3.2534138102531434\n",
      "\n",
      "Epoch:   13/60    Loss: 3.513117794275284\n",
      "\n",
      "Epoch:   13/60    Loss: 3.4300424473285673\n",
      "\n",
      "Epoch:   13/60    Loss: 3.4403796095848085\n",
      "\n",
      "Epoch:   13/60    Loss: 3.2603962879180908\n",
      "\n",
      "Epoch:   13/60    Loss: 3.329005229234695\n",
      "\n",
      "Epoch:   13/60    Loss: 3.3282157955169676\n",
      "\n",
      "Epoch:   13/60    Loss: 3.333139503479004\n",
      "\n",
      "Epoch:   13/60    Loss: 3.3636950516700743\n",
      "\n",
      "Epoch:   13/60    Loss: 3.4703209958076475\n",
      "\n",
      "Epoch:   13/60    Loss: 3.4203539493083954\n",
      "\n",
      "Epoch:   13/60    Loss: 3.3402546861171722\n",
      "\n",
      "Epoch:   13/60    Loss: 3.3911341474056242\n",
      "\n",
      "Epoch:   13/60    Loss: 3.357407230377197\n",
      "\n",
      "Epoch:   13/60    Loss: 3.5085783858299253\n",
      "\n",
      "Epoch:   13/60    Loss: 3.411143491744995\n",
      "\n",
      "Epoch:   13/60    Loss: 3.491267461299896\n",
      "\n",
      "Epoch:   13/60    Loss: 3.543554400920868\n",
      "\n",
      "Epoch:   13/60    Loss: 3.4448009996414184\n",
      "\n",
      "Epoch:   13/60    Loss: 3.5093280799388884\n",
      "\n",
      "Epoch:   13/60    Loss: 3.4515255858898164\n",
      "\n",
      "Epoch:   13/60    Loss: 3.392246668100357\n",
      "\n",
      "Epoch:   13/60    Loss: 3.253947923183441\n",
      "\n",
      "Epoch:   13/60    Loss: 3.550262416601181\n",
      "\n",
      "Epoch:   13/60    Loss: 3.4800392460823057\n",
      "\n",
      "Epoch:   13/60    Loss: 3.313714222431183\n",
      "\n",
      "Epoch:   13/60    Loss: 3.3072771842479707\n",
      "\n",
      "Epoch:   13/60    Loss: 3.4458764114379883\n",
      "\n",
      "Epoch:   13/60    Loss: 3.306202966213226\n",
      "\n",
      "Epoch:   13/60    Loss: 3.389444536924362\n",
      "\n",
      "Epoch:   13/60    Loss: 3.409256075620651\n",
      "\n",
      "Epoch:   13/60    Loss: 3.3464845840930937\n",
      "\n",
      "Epoch:   13/60    Loss: 3.3766424124240877\n",
      "\n",
      "Epoch:   13/60    Loss: 3.349675814628601\n",
      "\n",
      "Epoch:   13/60    Loss: 3.4249412336349487\n",
      "\n",
      "Epoch:   13/60    Loss: 3.501241278409958\n",
      "\n",
      "Epoch:   13/60    Loss: 3.4614691202640535\n",
      "\n",
      "Epoch:   13/60    Loss: 3.517523584365845\n",
      "\n",
      "Epoch:   13/60    Loss: 3.594325399160385\n",
      "\n",
      "Epoch:   13/60    Loss: 3.4909558238983154\n",
      "\n",
      "Epoch:   13/60    Loss: 3.5139585726261138\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   13/60    Loss: 3.579603631258011\n",
      "\n",
      "Epoch:   13/60    Loss: 3.5262464666366578\n",
      "\n",
      "Epoch:   13/60    Loss: 3.543883153676987\n",
      "\n",
      "Epoch:   13/60    Loss: 3.564850581407547\n",
      "\n",
      "Epoch:   13/60    Loss: 3.6192431302070616\n",
      "\n",
      "Epoch:   13/60    Loss: 3.580011263370514\n",
      "\n",
      "Epoch:   13/60    Loss: 3.589677803993225\n",
      "\n",
      "Epoch:   13/60    Loss: 3.4980432991981507\n",
      "\n",
      "Epoch:   13/60    Loss: 3.6150482680797578\n",
      "\n",
      "Epoch:   13/60    Loss: 3.4706174697875976\n",
      "\n",
      "Epoch:   14/60    Loss: 3.6440658080189126\n",
      "\n",
      "Epoch:   14/60    Loss: 3.5505749077796938\n",
      "\n",
      "Epoch:   14/60    Loss: 3.4221648554801942\n",
      "\n",
      "Epoch:   14/60    Loss: 3.456373544692993\n",
      "\n",
      "Epoch:   14/60    Loss: 3.4427258191108705\n",
      "\n",
      "Epoch:   14/60    Loss: 3.475616331100464\n",
      "\n",
      "Epoch:   14/60    Loss: 3.5077902569770814\n",
      "\n",
      "Epoch:   14/60    Loss: 3.407384548187256\n",
      "\n",
      "Epoch:   14/60    Loss: 3.223609859228134\n",
      "\n",
      "Epoch:   14/60    Loss: 3.4691884999275207\n",
      "\n",
      "Epoch:   14/60    Loss: 3.3999497628211977\n",
      "\n",
      "Epoch:   14/60    Loss: 3.397182380914688\n",
      "\n",
      "Epoch:   14/60    Loss: 3.2375227584838866\n",
      "\n",
      "Epoch:   14/60    Loss: 3.2890483322143553\n",
      "\n",
      "Epoch:   14/60    Loss: 3.286317976951599\n",
      "\n",
      "Epoch:   14/60    Loss: 3.2803670251369477\n",
      "\n",
      "Epoch:   14/60    Loss: 3.3136286401748656\n",
      "\n",
      "Epoch:   14/60    Loss: 3.432775870323181\n",
      "\n",
      "Epoch:   14/60    Loss: 3.3674558906555174\n",
      "\n",
      "Epoch:   14/60    Loss: 3.287450428247452\n",
      "\n",
      "Epoch:   14/60    Loss: 3.342788825035095\n",
      "\n",
      "Epoch:   14/60    Loss: 3.297739010334015\n",
      "\n",
      "Epoch:   14/60    Loss: 3.488912986755371\n",
      "\n",
      "Epoch:   14/60    Loss: 3.3763635001182557\n",
      "\n",
      "Epoch:   14/60    Loss: 3.4753860340118408\n",
      "\n",
      "Epoch:   14/60    Loss: 3.5221248543262482\n",
      "\n",
      "Epoch:   14/60    Loss: 3.4051649730205535\n",
      "\n",
      "Epoch:   14/60    Loss: 3.50700021648407\n",
      "\n",
      "Epoch:   14/60    Loss: 3.422054708480835\n",
      "\n",
      "Epoch:   14/60    Loss: 3.3726066896915436\n",
      "\n",
      "Epoch:   14/60    Loss: 3.2287880296707154\n",
      "\n",
      "Epoch:   14/60    Loss: 3.5319434294700622\n",
      "\n",
      "Epoch:   14/60    Loss: 3.45263315987587\n",
      "\n",
      "Epoch:   14/60    Loss: 3.2880559384822847\n",
      "\n",
      "Epoch:   14/60    Loss: 3.2659445127248765\n",
      "\n",
      "Epoch:   14/60    Loss: 3.423380567073822\n",
      "\n",
      "Epoch:   14/60    Loss: 3.2767807881832125\n",
      "\n",
      "Epoch:   14/60    Loss: 3.3713716061115266\n",
      "\n",
      "Epoch:   14/60    Loss: 3.3815531961917875\n",
      "\n",
      "Epoch:   14/60    Loss: 3.3338660485744476\n",
      "\n",
      "Epoch:   14/60    Loss: 3.3340334005355836\n",
      "\n",
      "Epoch:   14/60    Loss: 3.31309898853302\n",
      "\n",
      "Epoch:   14/60    Loss: 3.3666598098278047\n",
      "\n",
      "Epoch:   14/60    Loss: 3.447463441848755\n",
      "\n",
      "Epoch:   14/60    Loss: 3.3931056327819826\n",
      "\n",
      "Epoch:   14/60    Loss: 3.472395007610321\n",
      "\n",
      "Epoch:   14/60    Loss: 3.543052148103714\n",
      "\n",
      "Epoch:   14/60    Loss: 3.419991268634796\n",
      "\n",
      "Epoch:   14/60    Loss: 3.4808440845012667\n",
      "\n",
      "Epoch:   14/60    Loss: 3.5363125522136687\n",
      "\n",
      "Epoch:   14/60    Loss: 3.489264604091644\n",
      "\n",
      "Epoch:   14/60    Loss: 3.5149637606143953\n",
      "\n",
      "Epoch:   14/60    Loss: 3.539115919828415\n",
      "\n",
      "Epoch:   14/60    Loss: 3.606447235584259\n",
      "\n",
      "Epoch:   14/60    Loss: 3.554535835504532\n",
      "\n",
      "Epoch:   14/60    Loss: 3.566235748052597\n",
      "\n",
      "Epoch:   14/60    Loss: 3.4646394033432006\n",
      "\n",
      "Epoch:   14/60    Loss: 3.572420719385147\n",
      "\n",
      "Epoch:   14/60    Loss: 3.413465657234192\n",
      "\n",
      "Epoch:   15/60    Loss: 3.5978007052579652\n",
      "\n",
      "Epoch:   15/60    Loss: 3.5011952493190766\n",
      "\n",
      "Epoch:   15/60    Loss: 3.3554293138980866\n",
      "\n",
      "Epoch:   15/60    Loss: 3.397196498632431\n",
      "\n",
      "Epoch:   15/60    Loss: 3.361057954788208\n",
      "\n",
      "Epoch:   15/60    Loss: 3.389194525718689\n",
      "\n",
      "Epoch:   15/60    Loss: 3.4363338837623596\n",
      "\n",
      "Epoch:   15/60    Loss: 3.366086834669113\n",
      "\n",
      "Epoch:   15/60    Loss: 3.1991918210983274\n",
      "\n",
      "Epoch:   15/60    Loss: 3.4605094521045685\n",
      "\n",
      "Epoch:   15/60    Loss: 3.378990444421768\n",
      "\n",
      "Epoch:   15/60    Loss: 3.3795575320720674\n",
      "\n",
      "Epoch:   15/60    Loss: 3.2349978141784668\n",
      "\n",
      "Epoch:   15/60    Loss: 3.288603487253189\n",
      "\n",
      "Epoch:   15/60    Loss: 3.2760678145885467\n",
      "\n",
      "Epoch:   15/60    Loss: 3.28762483215332\n",
      "\n",
      "Epoch:   15/60    Loss: 3.301560841560364\n",
      "\n",
      "Epoch:   15/60    Loss: 3.420902151107788\n",
      "\n",
      "Epoch:   15/60    Loss: 3.366080671072006\n",
      "\n",
      "Epoch:   15/60    Loss: 3.283931738853455\n",
      "\n",
      "Epoch:   15/60    Loss: 3.329003821372986\n",
      "\n",
      "Epoch:   15/60    Loss: 3.290248983621597\n",
      "\n",
      "Epoch:   15/60    Loss: 3.4870563502311707\n",
      "\n",
      "Epoch:   15/60    Loss: 3.372059406518936\n",
      "\n",
      "Epoch:   15/60    Loss: 3.445386960744858\n",
      "\n",
      "Epoch:   15/60    Loss: 3.518833995819092\n",
      "\n",
      "Epoch:   15/60    Loss: 3.3904691171646117\n",
      "\n",
      "Epoch:   15/60    Loss: 3.4991769862174986\n",
      "\n",
      "Epoch:   15/60    Loss: 3.3900370581150057\n",
      "\n",
      "Epoch:   15/60    Loss: 3.3443149697780608\n",
      "\n",
      "Epoch:   15/60    Loss: 3.206187175512314\n",
      "\n",
      "Epoch:   15/60    Loss: 3.5267063121795656\n",
      "\n",
      "Epoch:   15/60    Loss: 3.428943464279175\n",
      "\n",
      "Epoch:   15/60    Loss: 3.2694342992305754\n",
      "\n",
      "Epoch:   15/60    Loss: 3.244398521900177\n",
      "\n",
      "Epoch:   15/60    Loss: 3.368488088607788\n",
      "\n",
      "Epoch:   15/60    Loss: 3.2283637523651123\n",
      "\n",
      "Epoch:   15/60    Loss: 3.320254534959793\n",
      "\n",
      "Epoch:   15/60    Loss: 3.3536297919750213\n",
      "\n",
      "Epoch:   15/60    Loss: 3.2967400479316713\n",
      "\n",
      "Epoch:   15/60    Loss: 3.3157939219474795\n",
      "\n",
      "Epoch:   15/60    Loss: 3.2750966374874113\n",
      "\n",
      "Epoch:   15/60    Loss: 3.3442129786014556\n",
      "\n",
      "Epoch:   15/60    Loss: 3.3975198674201965\n",
      "\n",
      "Epoch:   15/60    Loss: 3.379279350757599\n",
      "\n",
      "Epoch:   15/60    Loss: 3.4479566042423246\n",
      "\n",
      "Epoch:   15/60    Loss: 3.524293622970581\n",
      "\n",
      "Epoch:   15/60    Loss: 3.405334379673004\n",
      "\n",
      "Epoch:   15/60    Loss: 3.452107650518417\n",
      "\n",
      "Epoch:   15/60    Loss: 3.5332250752449035\n",
      "\n",
      "Epoch:   15/60    Loss: 3.4846694133281706\n",
      "\n",
      "Epoch:   15/60    Loss: 3.5117354130744936\n",
      "\n",
      "Epoch:   15/60    Loss: 3.529239530324936\n",
      "\n",
      "Epoch:   15/60    Loss: 3.60353387260437\n",
      "\n",
      "Epoch:   15/60    Loss: 3.5332089989185334\n",
      "\n",
      "Epoch:   15/60    Loss: 3.5477080078125\n",
      "\n",
      "Epoch:   15/60    Loss: 3.4446413679122925\n",
      "\n",
      "Epoch:   15/60    Loss: 3.560871721506119\n",
      "\n",
      "Epoch:   15/60    Loss: 3.4297697234153746\n",
      "\n",
      "Epoch:   16/60    Loss: 3.5552016415673755\n",
      "\n",
      "Epoch:   16/60    Loss: 3.4850304188728334\n",
      "\n",
      "Epoch:   16/60    Loss: 3.32276788687706\n",
      "\n",
      "Epoch:   16/60    Loss: 3.343819099664688\n",
      "\n",
      "Epoch:   16/60    Loss: 3.3156618456840516\n",
      "\n",
      "Epoch:   16/60    Loss: 3.3549168450832365\n",
      "\n",
      "Epoch:   16/60    Loss: 3.4108371272087097\n",
      "\n",
      "Epoch:   16/60    Loss: 3.3434850280284882\n",
      "\n",
      "Epoch:   16/60    Loss: 3.1768969492912293\n",
      "\n",
      "Epoch:   16/60    Loss: 3.4110292937755586\n",
      "\n",
      "Epoch:   16/60    Loss: 3.3493848741054535\n",
      "\n",
      "Epoch:   16/60    Loss: 3.3631961233615875\n",
      "\n",
      "Epoch:   16/60    Loss: 3.2054788069725038\n",
      "\n",
      "Epoch:   16/60    Loss: 3.2568587579727173\n",
      "\n",
      "Epoch:   16/60    Loss: 3.246300941705704\n",
      "\n",
      "Epoch:   16/60    Loss: 3.264293571472168\n",
      "\n",
      "Epoch:   16/60    Loss: 3.2896481068134307\n",
      "\n",
      "Epoch:   16/60    Loss: 3.4036517677307128\n",
      "\n",
      "Epoch:   16/60    Loss: 3.343314752101898\n",
      "\n",
      "Epoch:   16/60    Loss: 3.2852506513595583\n",
      "\n",
      "Epoch:   16/60    Loss: 3.297949355840683\n",
      "\n",
      "Epoch:   16/60    Loss: 3.277534846782684\n",
      "\n",
      "Epoch:   16/60    Loss: 3.461104424715042\n",
      "\n",
      "Epoch:   16/60    Loss: 3.3360949013233183\n",
      "\n",
      "Epoch:   16/60    Loss: 3.4054131293296814\n",
      "\n",
      "Epoch:   16/60    Loss: 3.4818177108764647\n",
      "\n",
      "Epoch:   16/60    Loss: 3.3623150482177735\n",
      "\n",
      "Epoch:   16/60    Loss: 3.4547464017868044\n",
      "\n",
      "Epoch:   16/60    Loss: 3.3655280735492705\n",
      "\n",
      "Epoch:   16/60    Loss: 3.326203287124634\n",
      "\n",
      "Epoch:   16/60    Loss: 3.184393804550171\n",
      "\n",
      "Epoch:   16/60    Loss: 3.4161973829269408\n",
      "\n",
      "Epoch:   16/60    Loss: 3.368087757587433\n",
      "\n",
      "Epoch:   16/60    Loss: 3.2124102938175203\n",
      "\n",
      "Epoch:   16/60    Loss: 3.1800529844760894\n",
      "\n",
      "Epoch:   16/60    Loss: 3.34174204993248\n",
      "\n",
      "Epoch:   16/60    Loss: 3.207780462265015\n",
      "\n",
      "Epoch:   16/60    Loss: 3.2872151832580565\n",
      "\n",
      "Epoch:   16/60    Loss: 3.3365808897018434\n",
      "\n",
      "Epoch:   16/60    Loss: 3.2830717675685883\n",
      "\n",
      "Epoch:   16/60    Loss: 3.2771510825157164\n",
      "\n",
      "Epoch:   16/60    Loss: 3.2433772900104523\n",
      "\n",
      "Epoch:   16/60    Loss: 3.333143209695816\n",
      "\n",
      "Epoch:   16/60    Loss: 3.3903775753974914\n",
      "\n",
      "Epoch:   16/60    Loss: 3.3332857382297516\n",
      "\n",
      "Epoch:   16/60    Loss: 3.440404524087906\n",
      "\n",
      "Epoch:   16/60    Loss: 3.4992938935756683\n",
      "\n",
      "Epoch:   16/60    Loss: 3.391852882385254\n",
      "\n",
      "Epoch:   16/60    Loss: 3.4199561150074005\n",
      "\n",
      "Epoch:   16/60    Loss: 3.4959760100841524\n",
      "\n",
      "Epoch:   16/60    Loss: 3.4601605491638185\n",
      "\n",
      "Epoch:   16/60    Loss: 3.513487582921982\n",
      "\n",
      "Epoch:   16/60    Loss: 3.5158816049098967\n",
      "\n",
      "Epoch:   16/60    Loss: 3.587245527267456\n",
      "\n",
      "Epoch:   16/60    Loss: 3.4985825440883636\n",
      "\n",
      "Epoch:   16/60    Loss: 3.4736093354225157\n",
      "\n",
      "Epoch:   16/60    Loss: 3.394220042467117\n",
      "\n",
      "Epoch:   16/60    Loss: 3.464185659408569\n",
      "\n",
      "Epoch:   16/60    Loss: 3.3304287877082825\n",
      "\n",
      "Epoch:   17/60    Loss: 3.5152878539393777\n",
      "\n",
      "Epoch:   17/60    Loss: 3.4414569780826567\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   17/60    Loss: 3.277259191274643\n",
      "\n",
      "Epoch:   17/60    Loss: 3.302737434387207\n",
      "\n",
      "Epoch:   17/60    Loss: 3.3002242386341094\n",
      "\n",
      "Epoch:   17/60    Loss: 3.3366727983951567\n",
      "\n",
      "Epoch:   17/60    Loss: 3.3957268357276917\n",
      "\n",
      "Epoch:   17/60    Loss: 3.3206763558387755\n",
      "\n",
      "Epoch:   17/60    Loss: 3.136403620481491\n",
      "\n",
      "Epoch:   17/60    Loss: 3.3816332268714904\n",
      "\n",
      "Epoch:   17/60    Loss: 3.3256276853084565\n",
      "\n",
      "Epoch:   17/60    Loss: 3.3420629749298096\n",
      "\n",
      "Epoch:   17/60    Loss: 3.1878785796165467\n",
      "\n",
      "Epoch:   17/60    Loss: 3.233029477596283\n",
      "\n",
      "Epoch:   17/60    Loss: 3.2201851279735565\n",
      "\n",
      "Epoch:   17/60    Loss: 3.2364381322860716\n",
      "\n",
      "Epoch:   17/60    Loss: 3.245013053417206\n",
      "\n",
      "Epoch:   17/60    Loss: 3.350328604221344\n",
      "\n",
      "Epoch:   17/60    Loss: 3.3014356188774108\n",
      "\n",
      "Epoch:   17/60    Loss: 3.2275468764305115\n",
      "\n",
      "Epoch:   17/60    Loss: 3.2695296766757966\n",
      "\n",
      "Epoch:   17/60    Loss: 3.236613594055176\n",
      "\n",
      "Epoch:   17/60    Loss: 3.417028036355972\n",
      "\n",
      "Epoch:   17/60    Loss: 3.3160128190517426\n",
      "\n",
      "Epoch:   17/60    Loss: 3.3651394674777984\n",
      "\n",
      "Epoch:   17/60    Loss: 3.449082607984543\n",
      "\n",
      "Epoch:   17/60    Loss: 3.3351928489208222\n",
      "\n",
      "Epoch:   17/60    Loss: 3.4231724362373352\n",
      "\n",
      "Epoch:   17/60    Loss: 3.3346037473678587\n",
      "\n",
      "Epoch:   17/60    Loss: 3.2669774239063263\n",
      "\n",
      "Epoch:   17/60    Loss: 3.1389810490608214\n",
      "\n",
      "Epoch:   17/60    Loss: 3.3783677499294282\n",
      "\n",
      "Epoch:   17/60    Loss: 3.3297284862995147\n",
      "\n",
      "Epoch:   17/60    Loss: 3.1862420337200166\n",
      "\n",
      "Epoch:   17/60    Loss: 3.160702290058136\n",
      "\n",
      "Epoch:   17/60    Loss: 3.2705640594959258\n",
      "\n",
      "Epoch:   17/60    Loss: 3.181162782907486\n",
      "\n",
      "Epoch:   17/60    Loss: 3.2599922780990602\n",
      "\n",
      "Epoch:   17/60    Loss: 3.2767955267429354\n",
      "\n",
      "Epoch:   17/60    Loss: 3.2499254133701325\n",
      "\n",
      "Epoch:   17/60    Loss: 3.246207352399826\n",
      "\n",
      "Epoch:   17/60    Loss: 3.2270885441303254\n",
      "\n",
      "Epoch:   17/60    Loss: 3.3071152629852296\n",
      "\n",
      "Epoch:   17/60    Loss: 3.363324609518051\n",
      "\n",
      "Epoch:   17/60    Loss: 3.308753326177597\n",
      "\n",
      "Epoch:   17/60    Loss: 3.4097247757911684\n",
      "\n",
      "Epoch:   17/60    Loss: 3.4634741206169126\n",
      "\n",
      "Epoch:   17/60    Loss: 3.3609861345291137\n",
      "\n",
      "Epoch:   17/60    Loss: 3.404297626256943\n",
      "\n",
      "Epoch:   17/60    Loss: 3.479929836988449\n",
      "\n",
      "Epoch:   17/60    Loss: 3.4455114908218385\n",
      "\n",
      "Epoch:   17/60    Loss: 3.4907545621395113\n",
      "\n",
      "Epoch:   17/60    Loss: 3.4817515788078306\n",
      "\n",
      "Epoch:   17/60    Loss: 3.541996322154999\n",
      "\n",
      "Epoch:   17/60    Loss: 3.458978748559952\n",
      "\n",
      "Epoch:   17/60    Loss: 3.4182840259075165\n",
      "\n",
      "Epoch:   17/60    Loss: 3.3545843286514283\n",
      "\n",
      "Epoch:   17/60    Loss: 3.4331324257850646\n",
      "\n",
      "Epoch:   17/60    Loss: 3.304169405221939\n",
      "\n",
      "Epoch:   18/60    Loss: 3.4714655564369066\n",
      "\n",
      "Epoch:   18/60    Loss: 3.4140822927951815\n",
      "\n",
      "Epoch:   18/60    Loss: 3.251315244436264\n",
      "\n",
      "Epoch:   18/60    Loss: 3.269177433013916\n",
      "\n",
      "Epoch:   18/60    Loss: 3.2883712747097014\n",
      "\n",
      "Epoch:   18/60    Loss: 3.3233015048503876\n",
      "\n",
      "Epoch:   18/60    Loss: 3.382745847940445\n",
      "\n",
      "Epoch:   18/60    Loss: 3.3171708369255066\n",
      "\n",
      "Epoch:   18/60    Loss: 3.1352158184051513\n",
      "\n",
      "Epoch:   18/60    Loss: 3.367469040155411\n",
      "\n",
      "Epoch:   18/60    Loss: 3.2886019463539125\n",
      "\n",
      "Epoch:   18/60    Loss: 3.3191893379688264\n",
      "\n",
      "Epoch:   18/60    Loss: 3.1684381909370423\n",
      "\n",
      "Epoch:   18/60    Loss: 3.2163474674224855\n",
      "\n",
      "Epoch:   18/60    Loss: 3.197632654428482\n",
      "\n",
      "Epoch:   18/60    Loss: 3.2028141911029815\n",
      "\n",
      "Epoch:   18/60    Loss: 3.2262202875614165\n",
      "\n",
      "Epoch:   18/60    Loss: 3.32995526266098\n",
      "\n",
      "Epoch:   18/60    Loss: 3.282579352617264\n",
      "\n",
      "Epoch:   18/60    Loss: 3.1851000990867613\n",
      "\n",
      "Epoch:   18/60    Loss: 3.2335304856300353\n",
      "\n",
      "Epoch:   18/60    Loss: 3.1980802302360534\n",
      "\n",
      "Epoch:   18/60    Loss: 3.375347755432129\n",
      "\n",
      "Epoch:   18/60    Loss: 3.258586063861847\n",
      "\n",
      "Epoch:   18/60    Loss: 3.309706920146942\n",
      "\n",
      "Epoch:   18/60    Loss: 3.4028004109859467\n",
      "\n",
      "Epoch:   18/60    Loss: 3.2939742872714994\n",
      "\n",
      "Epoch:   18/60    Loss: 3.3646963982582094\n",
      "\n",
      "Epoch:   18/60    Loss: 3.280197696208954\n",
      "\n",
      "Epoch:   18/60    Loss: 3.2258049211502073\n",
      "\n",
      "Epoch:   18/60    Loss: 3.1296678936481475\n",
      "\n",
      "Epoch:   18/60    Loss: 3.3472199635505677\n",
      "\n",
      "Epoch:   18/60    Loss: 3.303597439289093\n",
      "\n",
      "Epoch:   18/60    Loss: 3.164413017034531\n",
      "\n",
      "Epoch:   18/60    Loss: 3.1386829307079314\n",
      "\n",
      "Epoch:   18/60    Loss: 3.2544331612586976\n",
      "\n",
      "Epoch:   18/60    Loss: 3.168205073595047\n",
      "\n",
      "Epoch:   18/60    Loss: 3.2309611103534697\n",
      "\n",
      "Epoch:   18/60    Loss: 3.2569259586334227\n",
      "\n",
      "Epoch:   18/60    Loss: 3.2254952158927916\n",
      "\n",
      "Epoch:   18/60    Loss: 3.2274992985725404\n",
      "\n",
      "Epoch:   18/60    Loss: 3.2042432553768156\n",
      "\n",
      "Epoch:   18/60    Loss: 3.2595687022209168\n",
      "\n",
      "Epoch:   18/60    Loss: 3.324988003492355\n",
      "\n",
      "Epoch:   18/60    Loss: 3.271938279867172\n",
      "\n",
      "Epoch:   18/60    Loss: 3.3737527990341185\n",
      "\n",
      "Epoch:   18/60    Loss: 3.431216839551926\n",
      "\n",
      "Epoch:   18/60    Loss: 3.337723244905472\n",
      "\n",
      "Epoch:   18/60    Loss: 3.3805225074291227\n",
      "\n",
      "Epoch:   18/60    Loss: 3.4304818847179415\n",
      "\n",
      "Epoch:   18/60    Loss: 3.3939579112529756\n",
      "\n",
      "Epoch:   18/60    Loss: 3.4282503299713136\n",
      "\n",
      "Epoch:   18/60    Loss: 3.4057004628181455\n",
      "\n",
      "Epoch:   18/60    Loss: 3.449468122243881\n",
      "\n",
      "Epoch:   18/60    Loss: 3.383532522439957\n",
      "\n",
      "Epoch:   18/60    Loss: 3.3752264013290407\n",
      "\n",
      "Epoch:   18/60    Loss: 3.314786041021347\n",
      "\n",
      "Epoch:   18/60    Loss: 3.4015134620666503\n",
      "\n",
      "Epoch:   18/60    Loss: 3.2875746097564695\n",
      "\n",
      "Epoch:   19/60    Loss: 3.4435882451741593\n",
      "\n",
      "Epoch:   19/60    Loss: 3.3932451777458192\n",
      "\n",
      "Epoch:   19/60    Loss: 3.2253662605285642\n",
      "\n",
      "Epoch:   19/60    Loss: 3.2515431244373323\n",
      "\n",
      "Epoch:   19/60    Loss: 3.2603689341545103\n",
      "\n",
      "Epoch:   19/60    Loss: 3.3096205270290375\n",
      "\n",
      "Epoch:   19/60    Loss: 3.36932505106926\n",
      "\n",
      "Epoch:   19/60    Loss: 3.29607840180397\n",
      "\n",
      "Epoch:   19/60    Loss: 3.105283158779144\n",
      "\n",
      "Epoch:   19/60    Loss: 3.3419199697971345\n",
      "\n",
      "Epoch:   19/60    Loss: 3.2635259916782378\n",
      "\n",
      "Epoch:   19/60    Loss: 3.299734112739563\n",
      "\n",
      "Epoch:   19/60    Loss: 3.139265462875366\n",
      "\n",
      "Epoch:   19/60    Loss: 3.1742255907058716\n",
      "\n",
      "Epoch:   19/60    Loss: 3.1694970383644105\n",
      "\n",
      "Epoch:   19/60    Loss: 3.1600742609500885\n",
      "\n",
      "Epoch:   19/60    Loss: 3.2217712593078613\n",
      "\n",
      "Epoch:   19/60    Loss: 3.3037006740570067\n",
      "\n",
      "Epoch:   19/60    Loss: 3.265310702800751\n",
      "\n",
      "Epoch:   19/60    Loss: 3.1509880166053774\n",
      "\n",
      "Epoch:   19/60    Loss: 3.220455669879913\n",
      "\n",
      "Epoch:   19/60    Loss: 3.1935297679901122\n",
      "\n",
      "Epoch:   19/60    Loss: 3.361803330898285\n",
      "\n",
      "Epoch:   19/60    Loss: 3.251432709693909\n",
      "\n",
      "Epoch:   19/60    Loss: 3.2931145989894866\n",
      "\n",
      "Epoch:   19/60    Loss: 3.383438886165619\n",
      "\n",
      "Epoch:   19/60    Loss: 3.2602153856754303\n",
      "\n",
      "Epoch:   19/60    Loss: 3.338701689481735\n",
      "\n",
      "Epoch:   19/60    Loss: 3.2609868421554564\n",
      "\n",
      "Epoch:   19/60    Loss: 3.200797885417938\n",
      "\n",
      "Epoch:   19/60    Loss: 3.1007536644935607\n",
      "\n",
      "Epoch:   19/60    Loss: 3.31894855761528\n",
      "\n",
      "Epoch:   19/60    Loss: 3.27019584774971\n",
      "\n",
      "Epoch:   19/60    Loss: 3.1400501639842986\n",
      "\n",
      "Epoch:   19/60    Loss: 3.1215213108062745\n",
      "\n",
      "Epoch:   19/60    Loss: 3.2450032255649566\n",
      "\n",
      "Epoch:   19/60    Loss: 3.144571321487427\n",
      "\n",
      "Epoch:   19/60    Loss: 3.1908742072582243\n",
      "\n",
      "Epoch:   19/60    Loss: 3.2312759172916414\n",
      "\n",
      "Epoch:   19/60    Loss: 3.218325734615326\n",
      "\n",
      "Epoch:   19/60    Loss: 3.2139521064758303\n",
      "\n",
      "Epoch:   19/60    Loss: 3.190109671592712\n",
      "\n",
      "Epoch:   19/60    Loss: 3.256169975280762\n",
      "\n",
      "Epoch:   19/60    Loss: 3.312941780567169\n",
      "\n",
      "Epoch:   19/60    Loss: 3.2579827733039854\n",
      "\n",
      "Epoch:   19/60    Loss: 3.358627333164215\n",
      "\n",
      "Epoch:   19/60    Loss: 3.4230148668289186\n",
      "\n",
      "Epoch:   19/60    Loss: 3.3159169986248016\n",
      "\n",
      "Epoch:   19/60    Loss: 3.3643763372898103\n",
      "\n",
      "Epoch:   19/60    Loss: 3.4035292348861694\n",
      "\n",
      "Epoch:   19/60    Loss: 3.3781617307662963\n",
      "\n",
      "Epoch:   19/60    Loss: 3.393200198173523\n",
      "\n",
      "Epoch:   19/60    Loss: 3.391814904689789\n",
      "\n",
      "Epoch:   19/60    Loss: 3.427008552312851\n",
      "\n",
      "Epoch:   19/60    Loss: 3.359682839870453\n",
      "\n",
      "Epoch:   19/60    Loss: 3.347056525230408\n",
      "\n",
      "Epoch:   19/60    Loss: 3.295238075733185\n",
      "\n",
      "Epoch:   19/60    Loss: 3.380912928104401\n",
      "\n",
      "Epoch:   19/60    Loss: 3.2841401598453523\n",
      "\n",
      "Epoch:   20/60    Loss: 3.44366158966137\n",
      "\n",
      "Epoch:   20/60    Loss: 3.3748048532009123\n",
      "\n",
      "Epoch:   20/60    Loss: 3.2220540900230406\n",
      "\n",
      "Epoch:   20/60    Loss: 3.250820494890213\n",
      "\n",
      "Epoch:   20/60    Loss: 3.2633381228446963\n",
      "\n",
      "Epoch:   20/60    Loss: 3.3013504610061646\n",
      "\n",
      "Epoch:   20/60    Loss: 3.3728490743637085\n",
      "\n",
      "Epoch:   20/60    Loss: 3.3011843864917756\n",
      "\n",
      "Epoch:   20/60    Loss: 3.1004565436840057\n",
      "\n",
      "Epoch:   20/60    Loss: 3.331958844423294\n",
      "\n",
      "Epoch:   20/60    Loss: 3.2458356862068176\n",
      "\n",
      "Epoch:   20/60    Loss: 3.2701011686325074\n",
      "\n",
      "Epoch:   20/60    Loss: 3.1254337661266325\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   20/60    Loss: 3.16709756731987\n",
      "\n",
      "Epoch:   20/60    Loss: 3.155626588821411\n",
      "\n",
      "Epoch:   20/60    Loss: 3.136560223579407\n",
      "\n",
      "Epoch:   20/60    Loss: 3.199279043197632\n",
      "\n",
      "Epoch:   20/60    Loss: 3.2842544367313384\n",
      "\n",
      "Epoch:   20/60    Loss: 3.2330834448337553\n",
      "\n",
      "Epoch:   20/60    Loss: 3.122628919363022\n",
      "\n",
      "Epoch:   20/60    Loss: 3.200595396280289\n",
      "\n",
      "Epoch:   20/60    Loss: 3.1525713675022127\n",
      "\n",
      "Epoch:   20/60    Loss: 3.3322874665260316\n",
      "\n",
      "Epoch:   20/60    Loss: 3.2201295130252836\n",
      "\n",
      "Epoch:   20/60    Loss: 3.290888930082321\n",
      "\n",
      "Epoch:   20/60    Loss: 3.364639599084854\n",
      "\n",
      "Epoch:   20/60    Loss: 3.2395799372196197\n",
      "\n",
      "Epoch:   20/60    Loss: 3.3343406012058256\n",
      "\n",
      "Epoch:   20/60    Loss: 3.24289826130867\n",
      "\n",
      "Epoch:   20/60    Loss: 3.1938642995357513\n",
      "\n",
      "Epoch:   20/60    Loss: 3.081999782085419\n",
      "\n",
      "Epoch:   20/60    Loss: 3.298675107717514\n",
      "\n",
      "Epoch:   20/60    Loss: 3.232543532848358\n",
      "\n",
      "Epoch:   20/60    Loss: 3.0943985736370085\n",
      "\n",
      "Epoch:   20/60    Loss: 3.0767729694843293\n",
      "\n",
      "Epoch:   20/60    Loss: 3.203366997241974\n",
      "\n",
      "Epoch:   20/60    Loss: 3.1085765814781188\n",
      "\n",
      "Epoch:   20/60    Loss: 3.172331338405609\n",
      "\n",
      "Epoch:   20/60    Loss: 3.206588030099869\n",
      "\n",
      "Epoch:   20/60    Loss: 3.1852057688236237\n",
      "\n",
      "Epoch:   20/60    Loss: 3.1891278445720674\n",
      "\n",
      "Epoch:   20/60    Loss: 3.1524035050868986\n",
      "\n",
      "Epoch:   20/60    Loss: 3.2226285595893858\n",
      "\n",
      "Epoch:   20/60    Loss: 3.2939402880668642\n",
      "\n",
      "Epoch:   20/60    Loss: 3.235398077726364\n",
      "\n",
      "Epoch:   20/60    Loss: 3.3165499815940858\n",
      "\n",
      "Epoch:   20/60    Loss: 3.3790861258506775\n",
      "\n",
      "Epoch:   20/60    Loss: 3.2757291321754454\n",
      "\n",
      "Epoch:   20/60    Loss: 3.3181465916633606\n",
      "\n",
      "Epoch:   20/60    Loss: 3.4117147517204285\n",
      "\n",
      "Epoch:   20/60    Loss: 3.393078059196472\n",
      "\n",
      "Epoch:   20/60    Loss: 3.4051807792186737\n",
      "\n",
      "Epoch:   20/60    Loss: 3.4274336278438566\n",
      "\n",
      "Epoch:   20/60    Loss: 3.475057035446167\n",
      "\n",
      "Epoch:   20/60    Loss: 3.3527822237014773\n",
      "\n",
      "Epoch:   20/60    Loss: 3.3457605645656585\n",
      "\n",
      "Epoch:   20/60    Loss: 3.2942122263908384\n",
      "\n",
      "Epoch:   20/60    Loss: 3.372402899503708\n",
      "\n",
      "Epoch:   20/60    Loss: 3.2454360268116\n",
      "\n",
      "Epoch:   21/60    Loss: 3.3890306306597977\n",
      "\n",
      "Epoch:   21/60    Loss: 3.3505555183887483\n",
      "\n",
      "Epoch:   21/60    Loss: 3.1941434059143066\n",
      "\n",
      "Epoch:   21/60    Loss: 3.2214544446468354\n",
      "\n",
      "Epoch:   21/60    Loss: 3.2397784752845764\n",
      "\n",
      "Epoch:   21/60    Loss: 3.2772955420017245\n",
      "\n",
      "Epoch:   21/60    Loss: 3.3453901402950286\n",
      "\n",
      "Epoch:   21/60    Loss: 3.2769277510643007\n",
      "\n",
      "Epoch:   21/60    Loss: 3.0869160294532776\n",
      "\n",
      "Epoch:   21/60    Loss: 3.2896291198730467\n",
      "\n",
      "Epoch:   21/60    Loss: 3.216500338554382\n",
      "\n",
      "Epoch:   21/60    Loss: 3.2540368976593017\n",
      "\n",
      "Epoch:   21/60    Loss: 3.1070007705688476\n",
      "\n",
      "Epoch:   21/60    Loss: 3.1482338845729827\n",
      "\n",
      "Epoch:   21/60    Loss: 3.137527368783951\n",
      "\n",
      "Epoch:   21/60    Loss: 3.127875126838684\n",
      "\n",
      "Epoch:   21/60    Loss: 3.1736760737895966\n",
      "\n",
      "Epoch:   21/60    Loss: 3.2569229340553285\n",
      "\n",
      "Epoch:   21/60    Loss: 3.21292844414711\n",
      "\n",
      "Epoch:   21/60    Loss: 3.09515110039711\n",
      "\n",
      "Epoch:   21/60    Loss: 3.1878458201885223\n",
      "\n",
      "Epoch:   21/60    Loss: 3.1418847529888154\n",
      "\n",
      "Epoch:   21/60    Loss: 3.3174240827560424\n",
      "\n",
      "Epoch:   21/60    Loss: 3.1855021178722382\n",
      "\n",
      "Epoch:   21/60    Loss: 3.229977388381958\n",
      "\n",
      "Epoch:   21/60    Loss: 3.3235807480812074\n",
      "\n",
      "Epoch:   21/60    Loss: 3.2286188554763795\n",
      "\n",
      "Epoch:   21/60    Loss: 3.305500149011612\n",
      "\n",
      "Epoch:   21/60    Loss: 3.234744029045105\n",
      "\n",
      "Epoch:   21/60    Loss: 3.1669623277187346\n",
      "\n",
      "Epoch:   21/60    Loss: 3.0583952803611756\n",
      "\n",
      "Epoch:   21/60    Loss: 3.261802905321121\n",
      "\n",
      "Epoch:   21/60    Loss: 3.202532320022583\n",
      "\n",
      "Epoch:   21/60    Loss: 3.077067308187485\n",
      "\n",
      "Epoch:   21/60    Loss: 3.0665506664514544\n",
      "\n",
      "Epoch:   21/60    Loss: 3.1952502703666688\n",
      "\n",
      "Epoch:   21/60    Loss: 3.089830324411392\n",
      "\n",
      "Epoch:   21/60    Loss: 3.157734303236008\n",
      "\n",
      "Epoch:   21/60    Loss: 3.1906966679096223\n",
      "\n",
      "Epoch:   21/60    Loss: 3.1724193432331087\n",
      "\n",
      "Epoch:   21/60    Loss: 3.1829420773983004\n",
      "\n",
      "Epoch:   21/60    Loss: 3.1479301557540893\n",
      "\n",
      "Epoch:   21/60    Loss: 3.2187497408390047\n",
      "\n",
      "Epoch:   21/60    Loss: 3.2613553190231324\n",
      "\n",
      "Epoch:   21/60    Loss: 3.2187742846012117\n",
      "\n",
      "Epoch:   21/60    Loss: 3.290645385980606\n",
      "\n",
      "Epoch:   21/60    Loss: 3.3661729748249054\n",
      "\n",
      "Epoch:   21/60    Loss: 3.2669912366867067\n",
      "\n",
      "Epoch:   21/60    Loss: 3.3028371243476866\n",
      "\n",
      "Epoch:   21/60    Loss: 3.3879406988620757\n",
      "\n",
      "Epoch:   21/60    Loss: 3.3437950115203856\n",
      "\n",
      "Epoch:   21/60    Loss: 3.345221534490585\n",
      "\n",
      "Epoch:   21/60    Loss: 3.3488168103694917\n",
      "\n",
      "Epoch:   21/60    Loss: 3.3616772651672364\n",
      "\n",
      "Epoch:   21/60    Loss: 3.3017532577514648\n",
      "\n",
      "Epoch:   21/60    Loss: 3.295152482509613\n",
      "\n",
      "Epoch:   21/60    Loss: 3.24951136302948\n",
      "\n",
      "Epoch:   21/60    Loss: 3.3114295167922974\n",
      "\n",
      "Epoch:   21/60    Loss: 3.2175979900360105\n",
      "\n",
      "Epoch:   22/60    Loss: 3.3525230468291305\n",
      "\n",
      "Epoch:   22/60    Loss: 3.329718123435974\n",
      "\n",
      "Epoch:   22/60    Loss: 3.171366690635681\n",
      "\n",
      "Epoch:   22/60    Loss: 3.2111372804641722\n",
      "\n",
      "Epoch:   22/60    Loss: 3.230391526699066\n",
      "\n",
      "Epoch:   22/60    Loss: 3.269884363412857\n",
      "\n",
      "Epoch:   22/60    Loss: 3.3291896250247954\n",
      "\n",
      "Epoch:   22/60    Loss: 3.2702301166057586\n",
      "\n",
      "Epoch:   22/60    Loss: 3.0537908601760866\n",
      "\n",
      "Epoch:   22/60    Loss: 3.279209993839264\n",
      "\n",
      "Epoch:   22/60    Loss: 3.203646239519119\n",
      "\n",
      "Epoch:   22/60    Loss: 3.2303769497871397\n",
      "\n",
      "Epoch:   22/60    Loss: 3.101595013141632\n",
      "\n",
      "Epoch:   22/60    Loss: 3.1341551961898806\n",
      "\n",
      "Epoch:   22/60    Loss: 3.123944275379181\n",
      "\n",
      "Epoch:   22/60    Loss: 3.1119845876693724\n",
      "\n",
      "Epoch:   22/60    Loss: 3.173766445159912\n",
      "\n",
      "Epoch:   22/60    Loss: 3.2340454182624816\n",
      "\n",
      "Epoch:   22/60    Loss: 3.1939045550823213\n",
      "\n",
      "Epoch:   22/60    Loss: 3.078372958421707\n",
      "\n",
      "Epoch:   22/60    Loss: 3.1605537157058716\n",
      "\n",
      "Epoch:   22/60    Loss: 3.1258726296424864\n",
      "\n",
      "Epoch:   22/60    Loss: 3.2935631239414214\n",
      "\n",
      "Epoch:   22/60    Loss: 3.207704310655594\n",
      "\n",
      "Epoch:   22/60    Loss: 3.276477355003357\n",
      "\n",
      "Epoch:   22/60    Loss: 3.358918066740036\n",
      "\n",
      "Epoch:   22/60    Loss: 3.258873100757599\n",
      "\n",
      "Epoch:   22/60    Loss: 3.3475914976596832\n",
      "\n",
      "Epoch:   22/60    Loss: 3.2536139369010924\n",
      "\n",
      "Epoch:   22/60    Loss: 3.1894791519641874\n",
      "\n",
      "Epoch:   22/60    Loss: 3.0837908148765565\n",
      "\n",
      "Epoch:   22/60    Loss: 3.2694993517398836\n",
      "\n",
      "Epoch:   22/60    Loss: 3.1907878777980803\n",
      "\n",
      "Epoch:   22/60    Loss: 3.0637707107067107\n",
      "\n",
      "Epoch:   22/60    Loss: 3.0566560587882994\n",
      "\n",
      "Epoch:   22/60    Loss: 3.1860242097377776\n",
      "\n",
      "Epoch:   22/60    Loss: 3.078820961236954\n",
      "\n",
      "Epoch:   22/60    Loss: 3.13180508852005\n",
      "\n",
      "Epoch:   22/60    Loss: 3.153046749353409\n",
      "\n",
      "Epoch:   22/60    Loss: 3.1433741042613983\n",
      "\n",
      "Epoch:   22/60    Loss: 3.141433486223221\n",
      "\n",
      "Epoch:   22/60    Loss: 3.110483531236649\n",
      "\n",
      "Epoch:   22/60    Loss: 3.179442493438721\n",
      "\n",
      "Epoch:   22/60    Loss: 3.2425625150203703\n",
      "\n",
      "Epoch:   22/60    Loss: 3.183097496032715\n",
      "\n",
      "Epoch:   22/60    Loss: 3.2530018389225006\n",
      "\n",
      "Epoch:   22/60    Loss: 3.297988232374191\n",
      "\n",
      "Epoch:   22/60    Loss: 3.2225471425056456\n",
      "\n",
      "Epoch:   22/60    Loss: 3.232872729063034\n",
      "\n",
      "Epoch:   22/60    Loss: 3.332060234308243\n",
      "\n",
      "Epoch:   22/60    Loss: 3.321972390174866\n",
      "\n",
      "Epoch:   22/60    Loss: 3.3241609709262847\n",
      "\n",
      "Epoch:   22/60    Loss: 3.3384240819215774\n",
      "\n",
      "Epoch:   22/60    Loss: 3.388199050426483\n",
      "\n",
      "Epoch:   22/60    Loss: 3.323750913858414\n",
      "\n",
      "Epoch:   22/60    Loss: 3.3332782142162323\n",
      "\n",
      "Epoch:   22/60    Loss: 3.2562644238471985\n",
      "\n",
      "Epoch:   22/60    Loss: 3.3223790163993834\n",
      "\n",
      "Epoch:   22/60    Loss: 3.2034840342998505\n",
      "\n",
      "Epoch:   23/60    Loss: 3.3494567557683457\n",
      "\n",
      "Epoch:   23/60    Loss: 3.31244424700737\n",
      "\n",
      "Epoch:   23/60    Loss: 3.160527765750885\n",
      "\n",
      "Epoch:   23/60    Loss: 3.185696368932724\n",
      "\n",
      "Epoch:   23/60    Loss: 3.2058851659297942\n",
      "\n",
      "Epoch:   23/60    Loss: 3.2774449214935304\n",
      "\n",
      "Epoch:   23/60    Loss: 3.323592010974884\n",
      "\n",
      "Epoch:   23/60    Loss: 3.252961540222168\n",
      "\n",
      "Epoch:   23/60    Loss: 3.041528793811798\n",
      "\n",
      "Epoch:   23/60    Loss: 3.267077039718628\n",
      "\n",
      "Epoch:   23/60    Loss: 3.200559318304062\n",
      "\n",
      "Epoch:   23/60    Loss: 3.2057689225673673\n",
      "\n",
      "Epoch:   23/60    Loss: 3.0651870827674865\n",
      "\n",
      "Epoch:   23/60    Loss: 3.130100431203842\n",
      "\n",
      "Epoch:   23/60    Loss: 3.1178616077899934\n",
      "\n",
      "Epoch:   23/60    Loss: 3.0867657623291014\n",
      "\n",
      "Epoch:   23/60    Loss: 3.151378420352936\n",
      "\n",
      "Epoch:   23/60    Loss: 3.210068916797638\n",
      "\n",
      "Epoch:   23/60    Loss: 3.1592724165916444\n",
      "\n",
      "Epoch:   23/60    Loss: 3.03513889670372\n",
      "\n",
      "Epoch:   23/60    Loss: 3.154473962545395\n",
      "\n",
      "Epoch:   23/60    Loss: 3.0982229878902436\n",
      "\n",
      "Epoch:   23/60    Loss: 3.236834690570831\n",
      "\n",
      "Epoch:   23/60    Loss: 3.1488859136104583\n",
      "\n",
      "Epoch:   23/60    Loss: 3.2081017920970916\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   23/60    Loss: 3.2918880982398986\n",
      "\n",
      "Epoch:   23/60    Loss: 3.2071077835559847\n",
      "\n",
      "Epoch:   23/60    Loss: 3.280902110815048\n",
      "\n",
      "Epoch:   23/60    Loss: 3.2026264243125917\n",
      "\n",
      "Epoch:   23/60    Loss: 3.136078412294388\n",
      "\n",
      "Epoch:   23/60    Loss: 3.048828910589218\n",
      "\n",
      "Epoch:   23/60    Loss: 3.244369997739792\n",
      "\n",
      "Epoch:   23/60    Loss: 3.187796584367752\n",
      "\n",
      "Epoch:   23/60    Loss: 3.0604088876247406\n",
      "\n",
      "Epoch:   23/60    Loss: 3.065027961730957\n",
      "\n",
      "Epoch:   23/60    Loss: 3.1629499826431275\n",
      "\n",
      "Epoch:   23/60    Loss: 3.0547912983894348\n",
      "\n",
      "Epoch:   23/60    Loss: 3.122392864704132\n",
      "\n",
      "Epoch:   23/60    Loss: 3.1397533531188966\n",
      "\n",
      "Epoch:   23/60    Loss: 3.1241463499069213\n",
      "\n",
      "Epoch:   23/60    Loss: 3.117223782300949\n",
      "\n",
      "Epoch:   23/60    Loss: 3.1003319392204283\n",
      "\n",
      "Epoch:   23/60    Loss: 3.1695787980556487\n",
      "\n",
      "Epoch:   23/60    Loss: 3.227068747520447\n",
      "\n",
      "Epoch:   23/60    Loss: 3.166234560728073\n",
      "\n",
      "Epoch:   23/60    Loss: 3.2481342577934265\n",
      "\n",
      "Epoch:   23/60    Loss: 3.287988368988037\n",
      "\n",
      "Epoch:   23/60    Loss: 3.2103374769687654\n",
      "\n",
      "Epoch:   23/60    Loss: 3.2430268170833587\n",
      "\n",
      "Epoch:   23/60    Loss: 3.30386062335968\n",
      "\n",
      "Epoch:   23/60    Loss: 3.293411366224289\n",
      "\n",
      "Epoch:   23/60    Loss: 3.3104345326423643\n",
      "\n",
      "Epoch:   23/60    Loss: 3.327299517631531\n",
      "\n",
      "Epoch:   23/60    Loss: 3.3518936722278596\n",
      "\n",
      "Epoch:   23/60    Loss: 3.280302752494812\n",
      "\n",
      "Epoch:   23/60    Loss: 3.2564538397789002\n",
      "\n",
      "Epoch:   23/60    Loss: 3.229128796339035\n",
      "\n",
      "Epoch:   23/60    Loss: 3.28719482421875\n",
      "\n",
      "Epoch:   23/60    Loss: 3.194560915708542\n",
      "\n",
      "Epoch:   24/60    Loss: 3.32713197754777\n",
      "\n",
      "Epoch:   24/60    Loss: 3.30367972612381\n",
      "\n",
      "Epoch:   24/60    Loss: 3.1606237008571623\n",
      "\n",
      "Epoch:   24/60    Loss: 3.180560900449753\n",
      "\n",
      "Epoch:   24/60    Loss: 3.206193353176117\n",
      "\n",
      "Epoch:   24/60    Loss: 3.276008516073227\n",
      "\n",
      "Epoch:   24/60    Loss: 3.317097346305847\n",
      "\n",
      "Epoch:   24/60    Loss: 3.2436540951728823\n",
      "\n",
      "Epoch:   24/60    Loss: 3.050613998413086\n",
      "\n",
      "Epoch:   24/60    Loss: 3.2630653309822084\n",
      "\n",
      "Epoch:   24/60    Loss: 3.182581844329834\n",
      "\n",
      "Epoch:   24/60    Loss: 3.204918080329895\n",
      "\n",
      "Epoch:   24/60    Loss: 3.0784280519485474\n",
      "\n",
      "Epoch:   24/60    Loss: 3.1193792691230775\n",
      "\n",
      "Epoch:   24/60    Loss: 3.119899911880493\n",
      "\n",
      "Epoch:   24/60    Loss: 3.0953834183216093\n",
      "\n",
      "Epoch:   24/60    Loss: 3.155800164461136\n",
      "\n",
      "Epoch:   24/60    Loss: 3.198010833024979\n",
      "\n",
      "Epoch:   24/60    Loss: 3.138090211391449\n",
      "\n",
      "Epoch:   24/60    Loss: 3.032639531850815\n",
      "\n",
      "Epoch:   24/60    Loss: 3.1174081799983977\n",
      "\n",
      "Epoch:   24/60    Loss: 3.064105360031128\n",
      "\n",
      "Epoch:   24/60    Loss: 3.23137064409256\n",
      "\n",
      "Epoch:   24/60    Loss: 3.126053014278412\n",
      "\n",
      "Epoch:   24/60    Loss: 3.200216019153595\n",
      "\n",
      "Epoch:   24/60    Loss: 3.2832240488529205\n",
      "\n",
      "Epoch:   24/60    Loss: 3.215441768169403\n",
      "\n",
      "Epoch:   24/60    Loss: 3.2752171585559844\n",
      "\n",
      "Epoch:   24/60    Loss: 3.208848156452179\n",
      "\n",
      "Epoch:   24/60    Loss: 3.1561842405796052\n",
      "\n",
      "Epoch:   24/60    Loss: 3.0241555919647216\n",
      "\n",
      "Epoch:   24/60    Loss: 3.2344521288871766\n",
      "\n",
      "Epoch:   24/60    Loss: 3.1790564608573915\n",
      "\n",
      "Epoch:   24/60    Loss: 3.035922480583191\n",
      "\n",
      "Epoch:   24/60    Loss: 3.047520641088486\n",
      "\n",
      "Epoch:   24/60    Loss: 3.163784691095352\n",
      "\n",
      "Epoch:   24/60    Loss: 3.041408799171448\n",
      "\n",
      "Epoch:   24/60    Loss: 3.1324448010921477\n",
      "\n",
      "Epoch:   24/60    Loss: 3.1347719399929046\n",
      "\n",
      "Epoch:   24/60    Loss: 3.103367799282074\n",
      "\n",
      "Epoch:   24/60    Loss: 3.1094648180007933\n",
      "\n",
      "Epoch:   24/60    Loss: 3.0852584183216094\n",
      "\n",
      "Epoch:   24/60    Loss: 3.1466327958106994\n",
      "\n",
      "Epoch:   24/60    Loss: 3.2002575924396517\n",
      "\n",
      "Epoch:   24/60    Loss: 3.1506952316761017\n",
      "\n",
      "Epoch:   24/60    Loss: 3.2184173090457917\n",
      "\n",
      "Epoch:   24/60    Loss: 3.2642698788642885\n",
      "\n",
      "Epoch:   24/60    Loss: 3.1901793880462646\n",
      "\n",
      "Epoch:   24/60    Loss: 3.2297333736419676\n",
      "\n",
      "Epoch:   24/60    Loss: 3.2935849587917327\n",
      "\n",
      "Epoch:   24/60    Loss: 3.2887387099266054\n",
      "\n",
      "Epoch:   24/60    Loss: 3.288646265745163\n",
      "\n",
      "Epoch:   24/60    Loss: 3.3114688873291014\n",
      "\n",
      "Epoch:   24/60    Loss: 3.3222681365013123\n",
      "\n",
      "Epoch:   24/60    Loss: 3.260840102672577\n",
      "\n",
      "Epoch:   24/60    Loss: 3.246461062192917\n",
      "\n",
      "Epoch:   24/60    Loss: 3.2104096426963804\n",
      "\n",
      "Epoch:   24/60    Loss: 3.2650087802410126\n",
      "\n",
      "Epoch:   24/60    Loss: 3.1767506334781648\n",
      "\n",
      "Epoch:   25/60    Loss: 3.3014464392934157\n",
      "\n",
      "Epoch:   25/60    Loss: 3.2798501904010773\n",
      "\n",
      "Epoch:   25/60    Loss: 3.1423875272274016\n",
      "\n",
      "Epoch:   25/60    Loss: 3.1674541614055634\n",
      "\n",
      "Epoch:   25/60    Loss: 3.1849380800724028\n",
      "\n",
      "Epoch:   25/60    Loss: 3.290565789461136\n",
      "\n",
      "Epoch:   25/60    Loss: 3.332444205760956\n",
      "\n",
      "Epoch:   25/60    Loss: 3.2442870554924013\n",
      "\n",
      "Epoch:   25/60    Loss: 3.044664734840393\n",
      "\n",
      "Epoch:   25/60    Loss: 3.2563874328136446\n",
      "\n",
      "Epoch:   25/60    Loss: 3.1829892530441284\n",
      "\n",
      "Epoch:   25/60    Loss: 3.198612802505493\n",
      "\n",
      "Epoch:   25/60    Loss: 3.067127161026001\n",
      "\n",
      "Epoch:   25/60    Loss: 3.1130473959445952\n",
      "\n",
      "Epoch:   25/60    Loss: 3.1101930370330813\n",
      "\n",
      "Epoch:   25/60    Loss: 3.0828771719932555\n",
      "\n",
      "Epoch:   25/60    Loss: 3.136753133535385\n",
      "\n",
      "Epoch:   25/60    Loss: 3.17970508480072\n",
      "\n",
      "Epoch:   25/60    Loss: 3.111905447244644\n",
      "\n",
      "Epoch:   25/60    Loss: 2.997760966062546\n",
      "\n",
      "Epoch:   25/60    Loss: 3.108935190677643\n",
      "\n",
      "Epoch:   25/60    Loss: 3.0385731463432313\n",
      "\n",
      "Epoch:   25/60    Loss: 3.2227918615341187\n",
      "\n",
      "Epoch:   25/60    Loss: 3.116731342077255\n",
      "\n",
      "Epoch:   25/60    Loss: 3.1832658920288086\n",
      "\n",
      "Epoch:   25/60    Loss: 3.2562838463783264\n",
      "\n",
      "Epoch:   25/60    Loss: 3.17350848031044\n",
      "\n",
      "Epoch:   25/60    Loss: 3.2466956107616425\n",
      "\n",
      "Epoch:   25/60    Loss: 3.1841956508159637\n",
      "\n",
      "Epoch:   25/60    Loss: 3.124103716135025\n",
      "\n",
      "Epoch:   25/60    Loss: 2.993997768640518\n",
      "\n",
      "Epoch:   25/60    Loss: 3.214498744726181\n",
      "\n",
      "Epoch:   25/60    Loss: 3.1646314318180084\n",
      "\n",
      "Epoch:   25/60    Loss: 3.041068286895752\n",
      "\n",
      "Epoch:   25/60    Loss: 3.0428027611970903\n",
      "\n",
      "Epoch:   25/60    Loss: 3.145283654212952\n",
      "\n",
      "Epoch:   25/60    Loss: 3.0467017424106597\n",
      "\n",
      "Epoch:   25/60    Loss: 3.0991668064594267\n",
      "\n",
      "Epoch:   25/60    Loss: 3.114147076368332\n",
      "\n",
      "Epoch:   25/60    Loss: 3.088903252363205\n",
      "\n",
      "Epoch:   25/60    Loss: 3.069813893556595\n",
      "\n",
      "Epoch:   25/60    Loss: 3.0795442578792573\n",
      "\n",
      "Epoch:   25/60    Loss: 3.128224499464035\n",
      "\n",
      "Epoch:   25/60    Loss: 3.1968778812885286\n",
      "\n",
      "Epoch:   25/60    Loss: 3.155699201822281\n",
      "\n",
      "Epoch:   25/60    Loss: 3.2106115558147432\n",
      "\n",
      "Epoch:   25/60    Loss: 3.260142599582672\n",
      "\n",
      "Epoch:   25/60    Loss: 3.181547567605972\n",
      "\n",
      "Epoch:   25/60    Loss: 3.2212612988948823\n",
      "\n",
      "Epoch:   25/60    Loss: 3.3022894823551177\n",
      "\n",
      "Epoch:   25/60    Loss: 3.2678789775371553\n",
      "\n",
      "Epoch:   25/60    Loss: 3.2770699725151062\n",
      "\n",
      "Epoch:   25/60    Loss: 3.29932698225975\n",
      "\n",
      "Epoch:   25/60    Loss: 3.3020890719890597\n",
      "\n",
      "Epoch:   25/60    Loss: 3.243849677801132\n",
      "\n",
      "Epoch:   25/60    Loss: 3.2138840978145597\n",
      "\n",
      "Epoch:   25/60    Loss: 3.204992097616196\n",
      "\n",
      "Epoch:   25/60    Loss: 3.241625812292099\n",
      "\n",
      "Epoch:   25/60    Loss: 3.1753618352413175\n",
      "\n",
      "Epoch:   26/60    Loss: 3.2824100625255834\n",
      "\n",
      "Epoch:   26/60    Loss: 3.2643801357746125\n",
      "\n",
      "Epoch:   26/60    Loss: 3.1429071176052092\n",
      "\n",
      "Epoch:   26/60    Loss: 3.1732819039821623\n",
      "\n",
      "Epoch:   26/60    Loss: 3.1721739330291747\n",
      "\n",
      "Epoch:   26/60    Loss: 3.237333239078522\n",
      "\n",
      "Epoch:   26/60    Loss: 3.299185887813568\n",
      "\n",
      "Epoch:   26/60    Loss: 3.2231822905540466\n",
      "\n",
      "Epoch:   26/60    Loss: 3.015273444890976\n",
      "\n",
      "Epoch:   26/60    Loss: 3.2255232856273652\n",
      "\n",
      "Epoch:   26/60    Loss: 3.172258568525314\n",
      "\n",
      "Epoch:   26/60    Loss: 3.165005084991455\n",
      "\n",
      "Epoch:   26/60    Loss: 3.0573105475902556\n",
      "\n",
      "Epoch:   26/60    Loss: 3.094062237739563\n",
      "\n",
      "Epoch:   26/60    Loss: 3.0762504954338072\n",
      "\n",
      "Epoch:   26/60    Loss: 3.052840411424637\n",
      "\n",
      "Epoch:   26/60    Loss: 3.1043069171905517\n",
      "\n",
      "Epoch:   26/60    Loss: 3.147906328201294\n",
      "\n",
      "Epoch:   26/60    Loss: 3.067091053247452\n",
      "\n",
      "Epoch:   26/60    Loss: 2.9709243824481963\n",
      "\n",
      "Epoch:   26/60    Loss: 3.091760709285736\n",
      "\n",
      "Epoch:   26/60    Loss: 3.0270607771873475\n",
      "\n",
      "Epoch:   26/60    Loss: 3.188534518957138\n",
      "\n",
      "Epoch:   26/60    Loss: 3.1149723739624022\n",
      "\n",
      "Epoch:   26/60    Loss: 3.167436373472214\n",
      "\n",
      "Epoch:   26/60    Loss: 3.252490184545517\n",
      "\n",
      "Epoch:   26/60    Loss: 3.1701221494674683\n",
      "\n",
      "Epoch:   26/60    Loss: 3.2143978855609894\n",
      "\n",
      "Epoch:   26/60    Loss: 3.156895528078079\n",
      "\n",
      "Epoch:   26/60    Loss: 3.0908896300792694\n",
      "\n",
      "Epoch:   26/60    Loss: 2.979009090900421\n",
      "\n",
      "Epoch:   26/60    Loss: 3.180060913801193\n",
      "\n",
      "Epoch:   26/60    Loss: 3.137565226793289\n",
      "\n",
      "Epoch:   26/60    Loss: 3.007013378381729\n",
      "\n",
      "Epoch:   26/60    Loss: 2.9955402559041975\n",
      "\n",
      "Epoch:   26/60    Loss: 3.113186612844467\n",
      "\n",
      "Epoch:   26/60    Loss: 3.0073030800819396\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   26/60    Loss: 3.074005312681198\n",
      "\n",
      "Epoch:   26/60    Loss: 3.0990140192508697\n",
      "\n",
      "Epoch:   26/60    Loss: 3.0603642933368684\n",
      "\n",
      "Epoch:   26/60    Loss: 3.0486267025470735\n",
      "\n",
      "Epoch:   26/60    Loss: 3.0422983050346373\n",
      "\n",
      "Epoch:   26/60    Loss: 3.1140801928043365\n",
      "\n",
      "Epoch:   26/60    Loss: 3.170503722667694\n",
      "\n",
      "Epoch:   26/60    Loss: 3.1184332506656647\n",
      "\n",
      "Epoch:   26/60    Loss: 3.2031474485397338\n",
      "\n",
      "Epoch:   26/60    Loss: 3.241922064781189\n",
      "\n",
      "Epoch:   26/60    Loss: 3.153810519695282\n",
      "\n",
      "Epoch:   26/60    Loss: 3.1913318133354185\n",
      "\n",
      "Epoch:   26/60    Loss: 3.2722426114082337\n",
      "\n",
      "Epoch:   26/60    Loss: 3.240302745103836\n",
      "\n",
      "Epoch:   26/60    Loss: 3.2511712880134582\n",
      "\n",
      "Epoch:   26/60    Loss: 3.2796772305965423\n",
      "\n",
      "Epoch:   26/60    Loss: 3.28140873670578\n",
      "\n",
      "Epoch:   26/60    Loss: 3.219908824443817\n",
      "\n",
      "Epoch:   26/60    Loss: 3.1930616080760954\n",
      "\n",
      "Epoch:   26/60    Loss: 3.179032930135727\n",
      "\n",
      "Epoch:   26/60    Loss: 3.2076800801754\n",
      "\n",
      "Epoch:   26/60    Loss: 3.1514083974361418\n",
      "\n",
      "Epoch:   27/60    Loss: 3.2517395588042945\n",
      "\n",
      "Epoch:   27/60    Loss: 3.2496823348999024\n",
      "\n",
      "Epoch:   27/60    Loss: 3.123064632177353\n",
      "\n",
      "Epoch:   27/60    Loss: 3.151201905012131\n",
      "\n",
      "Epoch:   27/60    Loss: 3.155539333105087\n",
      "\n",
      "Epoch:   27/60    Loss: 3.2152191965579986\n",
      "\n",
      "Epoch:   27/60    Loss: 3.2833662436008453\n",
      "\n",
      "Epoch:   27/60    Loss: 3.202563238143921\n",
      "\n",
      "Epoch:   27/60    Loss: 3.0034579095840455\n",
      "\n",
      "Epoch:   27/60    Loss: 3.252532524347305\n",
      "\n",
      "Epoch:   27/60    Loss: 3.1457058322429656\n",
      "\n",
      "Epoch:   27/60    Loss: 3.153880066394806\n",
      "\n",
      "Epoch:   27/60    Loss: 3.0497526495456695\n",
      "\n",
      "Epoch:   27/60    Loss: 3.0683611574172973\n",
      "\n",
      "Epoch:   27/60    Loss: 3.057412425994873\n",
      "\n",
      "Epoch:   27/60    Loss: 3.054770300149918\n",
      "\n",
      "Epoch:   27/60    Loss: 3.08154034948349\n",
      "\n",
      "Epoch:   27/60    Loss: 3.1272462527751923\n",
      "\n",
      "Epoch:   27/60    Loss: 3.0614929840564726\n",
      "\n",
      "Epoch:   27/60    Loss: 2.96336772274971\n",
      "\n",
      "Epoch:   27/60    Loss: 3.0855437846183777\n",
      "\n",
      "Epoch:   27/60    Loss: 3.0322559411525725\n",
      "\n",
      "Epoch:   27/60    Loss: 3.1900787932872774\n",
      "\n",
      "Epoch:   27/60    Loss: 3.109283920049667\n",
      "\n",
      "Epoch:   27/60    Loss: 3.1666396777629853\n",
      "\n",
      "Epoch:   27/60    Loss: 3.24435404586792\n",
      "\n",
      "Epoch:   27/60    Loss: 3.1530773935317993\n",
      "\n",
      "Epoch:   27/60    Loss: 3.220617554664612\n",
      "\n",
      "Epoch:   27/60    Loss: 3.145743486881256\n",
      "\n",
      "Epoch:   27/60    Loss: 3.0984175999164583\n",
      "\n",
      "Epoch:   27/60    Loss: 2.9804731266498568\n",
      "\n",
      "Epoch:   27/60    Loss: 3.176934023141861\n",
      "\n",
      "Epoch:   27/60    Loss: 3.138734047412872\n",
      "\n",
      "Epoch:   27/60    Loss: 3.019386063337326\n",
      "\n",
      "Epoch:   27/60    Loss: 2.9886224702596667\n",
      "\n",
      "Epoch:   27/60    Loss: 3.104314866065979\n",
      "\n",
      "Epoch:   27/60    Loss: 3.001241199731827\n",
      "\n",
      "Epoch:   27/60    Loss: 3.046669637441635\n",
      "\n",
      "Epoch:   27/60    Loss: 3.069044170856476\n",
      "\n",
      "Epoch:   27/60    Loss: 3.0459380526542663\n",
      "\n",
      "Epoch:   27/60    Loss: 3.0444839708805085\n",
      "\n",
      "Epoch:   27/60    Loss: 3.0271233224868777\n",
      "\n",
      "Epoch:   27/60    Loss: 3.126231763839722\n",
      "\n",
      "Epoch:   27/60    Loss: 3.1644414710998534\n",
      "\n",
      "Epoch:   27/60    Loss: 3.10905611205101\n",
      "\n",
      "Epoch:   27/60    Loss: 3.195855367183685\n",
      "\n",
      "Epoch:   27/60    Loss: 3.206722493171692\n",
      "\n",
      "Epoch:   27/60    Loss: 3.1492760422229766\n",
      "\n",
      "Epoch:   27/60    Loss: 3.173669897556305\n",
      "\n",
      "Epoch:   27/60    Loss: 3.2736987805366518\n",
      "\n",
      "Epoch:   27/60    Loss: 3.219166883468628\n",
      "\n",
      "Epoch:   27/60    Loss: 3.22292259311676\n",
      "\n",
      "Epoch:   27/60    Loss: 3.2495104751586914\n",
      "\n",
      "Epoch:   27/60    Loss: 3.2688429644107817\n",
      "\n",
      "Epoch:   27/60    Loss: 3.2126126382350924\n",
      "\n",
      "Epoch:   27/60    Loss: 3.183524803876877\n",
      "\n",
      "Epoch:   27/60    Loss: 3.1686656134128572\n",
      "\n",
      "Epoch:   27/60    Loss: 3.1977979700565338\n",
      "\n",
      "Epoch:   27/60    Loss: 3.1576051952838897\n",
      "\n",
      "Epoch:   28/60    Loss: 3.2459619798414083\n",
      "\n",
      "Epoch:   28/60    Loss: 3.246616428375244\n",
      "\n",
      "Epoch:   28/60    Loss: 3.116182049036026\n",
      "\n",
      "Epoch:   28/60    Loss: 3.1506019871234896\n",
      "\n",
      "Epoch:   28/60    Loss: 3.169260477542877\n",
      "\n",
      "Epoch:   28/60    Loss: 3.204132674455643\n",
      "\n",
      "Epoch:   28/60    Loss: 3.2584334692955017\n",
      "\n",
      "Epoch:   28/60    Loss: 3.1841353805065156\n",
      "\n",
      "Epoch:   28/60    Loss: 2.993722052574158\n",
      "\n",
      "Epoch:   28/60    Loss: 3.21470391535759\n",
      "\n",
      "Epoch:   28/60    Loss: 3.133639189004898\n",
      "\n",
      "Epoch:   28/60    Loss: 3.1660267231464387\n",
      "\n",
      "Epoch:   28/60    Loss: 3.029148137331009\n",
      "\n",
      "Epoch:   28/60    Loss: 3.0458621933460237\n",
      "\n",
      "Epoch:   28/60    Loss: 3.0369887704849243\n",
      "\n",
      "Epoch:   28/60    Loss: 3.0282894837856293\n",
      "\n",
      "Epoch:   28/60    Loss: 3.0525249104499816\n",
      "\n",
      "Epoch:   28/60    Loss: 3.083208135128021\n",
      "\n",
      "Epoch:   28/60    Loss: 3.0496143662929533\n",
      "\n",
      "Epoch:   28/60    Loss: 2.9526714515686034\n",
      "\n",
      "Epoch:   28/60    Loss: 3.0736707220077513\n",
      "\n",
      "Epoch:   28/60    Loss: 3.023289094209671\n",
      "\n",
      "Epoch:   28/60    Loss: 3.197794517040253\n",
      "\n",
      "Epoch:   28/60    Loss: 3.079053326845169\n",
      "\n",
      "Epoch:   28/60    Loss: 3.1537500088214876\n",
      "\n",
      "Epoch:   28/60    Loss: 3.2268345046043394\n",
      "\n",
      "Epoch:   28/60    Loss: 3.1444077599048614\n",
      "\n",
      "Epoch:   28/60    Loss: 3.199453557729721\n",
      "\n",
      "Epoch:   28/60    Loss: 3.127594259738922\n",
      "\n",
      "Epoch:   28/60    Loss: 3.069702623128891\n",
      "\n",
      "Epoch:   28/60    Loss: 2.9638917729854586\n",
      "\n",
      "Epoch:   28/60    Loss: 3.168306215763092\n",
      "\n",
      "Epoch:   28/60    Loss: 3.1126984531879427\n",
      "\n",
      "Epoch:   28/60    Loss: 3.0057098371982574\n",
      "\n",
      "Epoch:   28/60    Loss: 2.959975458979607\n",
      "\n",
      "Epoch:   28/60    Loss: 3.090817270040512\n",
      "\n",
      "Epoch:   28/60    Loss: 2.9851654028892516\n",
      "\n",
      "Epoch:   28/60    Loss: 3.051480257987976\n",
      "\n",
      "Epoch:   28/60    Loss: 3.0580079784393313\n",
      "\n",
      "Epoch:   28/60    Loss: 3.0476529359817506\n",
      "\n",
      "Epoch:   28/60    Loss: 3.0284366285800934\n",
      "\n",
      "Epoch:   28/60    Loss: 3.042036154985428\n",
      "\n",
      "Epoch:   28/60    Loss: 3.1145613543987274\n",
      "\n",
      "Epoch:   28/60    Loss: 3.167093104362488\n",
      "\n",
      "Epoch:   28/60    Loss: 3.1120325615406035\n",
      "\n",
      "Epoch:   28/60    Loss: 3.1882222232818602\n",
      "\n",
      "Epoch:   28/60    Loss: 3.1957232456207274\n",
      "\n",
      "Epoch:   28/60    Loss: 3.142953670024872\n",
      "\n",
      "Epoch:   28/60    Loss: 3.175559911489487\n",
      "\n",
      "Epoch:   28/60    Loss: 3.2598867933750153\n",
      "\n",
      "Epoch:   28/60    Loss: 3.2056417288780215\n",
      "\n",
      "Epoch:   28/60    Loss: 3.219977255344391\n",
      "\n",
      "Epoch:   28/60    Loss: 3.2372818565368653\n",
      "\n",
      "Epoch:   28/60    Loss: 3.2150800414085388\n",
      "\n",
      "Epoch:   28/60    Loss: 3.151398829460144\n",
      "\n",
      "Epoch:   28/60    Loss: 3.153313445806503\n",
      "\n",
      "Epoch:   28/60    Loss: 3.171240034341812\n",
      "\n",
      "Epoch:   28/60    Loss: 3.181645530223846\n",
      "\n",
      "Epoch:   28/60    Loss: 3.144977261662483\n",
      "\n",
      "Epoch:   29/60    Loss: 3.218468306667131\n",
      "\n",
      "Epoch:   29/60    Loss: 3.218180927991867\n",
      "\n",
      "Epoch:   29/60    Loss: 3.115405396938324\n",
      "\n",
      "Epoch:   29/60    Loss: 3.1389251697063445\n",
      "\n",
      "Epoch:   29/60    Loss: 3.1360567901134493\n",
      "\n",
      "Epoch:   29/60    Loss: 3.190512441158295\n",
      "\n",
      "Epoch:   29/60    Loss: 3.2481078038215636\n",
      "\n",
      "Epoch:   29/60    Loss: 3.164378559112549\n",
      "\n",
      "Epoch:   29/60    Loss: 2.9818544020652773\n",
      "\n",
      "Epoch:   29/60    Loss: 3.1908528852462767\n",
      "\n",
      "Epoch:   29/60    Loss: 3.1027670454978944\n",
      "\n",
      "Epoch:   29/60    Loss: 3.120328179836273\n",
      "\n",
      "Epoch:   29/60    Loss: 3.010430204153061\n",
      "\n",
      "Epoch:   29/60    Loss: 3.015859061002731\n",
      "\n",
      "Epoch:   29/60    Loss: 3.015225519657135\n",
      "\n",
      "Epoch:   29/60    Loss: 3.0030183384418487\n",
      "\n",
      "Epoch:   29/60    Loss: 3.0351644208431243\n",
      "\n",
      "Epoch:   29/60    Loss: 3.0744638538360594\n",
      "\n",
      "Epoch:   29/60    Loss: 3.0254170391559603\n",
      "\n",
      "Epoch:   29/60    Loss: 2.9369632439613342\n",
      "\n",
      "Epoch:   29/60    Loss: 3.061616802215576\n",
      "\n",
      "Epoch:   29/60    Loss: 2.9980540857315066\n",
      "\n",
      "Epoch:   29/60    Loss: 3.1710488119125366\n",
      "\n",
      "Epoch:   29/60    Loss: 3.0713107318878174\n",
      "\n",
      "Epoch:   29/60    Loss: 3.136098598957062\n",
      "\n",
      "Epoch:   29/60    Loss: 3.193192447423935\n",
      "\n",
      "Epoch:   29/60    Loss: 3.1063424854278563\n",
      "\n",
      "Epoch:   29/60    Loss: 3.1761375365257263\n",
      "\n",
      "Epoch:   29/60    Loss: 3.1215568809509278\n",
      "\n",
      "Epoch:   29/60    Loss: 3.0484107785224914\n",
      "\n",
      "Epoch:   29/60    Loss: 2.9387732384204863\n",
      "\n",
      "Epoch:   29/60    Loss: 3.150732218980789\n",
      "\n",
      "Epoch:   29/60    Loss: 3.0981245675086977\n",
      "\n",
      "Epoch:   29/60    Loss: 2.9730623087882995\n",
      "\n",
      "Epoch:   29/60    Loss: 2.9441278114318847\n",
      "\n",
      "Epoch:   29/60    Loss: 3.07008838057518\n",
      "\n",
      "Epoch:   29/60    Loss: 2.9727095427513124\n",
      "\n",
      "Epoch:   29/60    Loss: 3.0355621547698974\n",
      "\n",
      "Epoch:   29/60    Loss: 3.0527125451564787\n",
      "\n",
      "Epoch:   29/60    Loss: 3.017948407411575\n",
      "\n",
      "Epoch:   29/60    Loss: 3.0195788209438326\n",
      "\n",
      "Epoch:   29/60    Loss: 3.0025245711803437\n",
      "\n",
      "Epoch:   29/60    Loss: 3.0793857128620146\n",
      "\n",
      "Epoch:   29/60    Loss: 3.1501694395542144\n",
      "\n",
      "Epoch:   29/60    Loss: 3.086200427055359\n",
      "\n",
      "Epoch:   29/60    Loss: 3.1692429385185243\n",
      "\n",
      "Epoch:   29/60    Loss: 3.1815834295749665\n",
      "\n",
      "Epoch:   29/60    Loss: 3.1299571063518523\n",
      "\n",
      "Epoch:   29/60    Loss: 3.165325443983078\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   29/60    Loss: 3.2626559114456177\n",
      "\n",
      "Epoch:   29/60    Loss: 3.1931901626586914\n",
      "\n",
      "Epoch:   29/60    Loss: 3.201913867235184\n",
      "\n",
      "Epoch:   29/60    Loss: 3.21992192029953\n",
      "\n",
      "Epoch:   29/60    Loss: 3.224096882343292\n",
      "\n",
      "Epoch:   29/60    Loss: 3.163540901184082\n",
      "\n",
      "Epoch:   29/60    Loss: 3.1366022844314574\n",
      "\n",
      "Epoch:   29/60    Loss: 3.1418236718177797\n",
      "\n",
      "Epoch:   29/60    Loss: 3.1760004720687864\n",
      "\n",
      "Epoch:   29/60    Loss: 3.134887305855751\n",
      "\n",
      "Epoch:   30/60    Loss: 3.187243509227815\n",
      "\n",
      "Epoch:   30/60    Loss: 3.203850958108902\n",
      "\n",
      "Epoch:   30/60    Loss: 3.1054005720615385\n",
      "\n",
      "Epoch:   30/60    Loss: 3.1218292503356935\n",
      "\n",
      "Epoch:   30/60    Loss: 3.126458002090454\n",
      "\n",
      "Epoch:   30/60    Loss: 3.167111741781235\n",
      "\n",
      "Epoch:   30/60    Loss: 3.2397584590911865\n",
      "\n",
      "Epoch:   30/60    Loss: 3.1459299998283385\n",
      "\n",
      "Epoch:   30/60    Loss: 2.9654383170604706\n",
      "\n",
      "Epoch:   30/60    Loss: 3.167007639169693\n",
      "\n",
      "Epoch:   30/60    Loss: 3.0810819640159606\n",
      "\n",
      "Epoch:   30/60    Loss: 3.1002568950653075\n",
      "\n",
      "Epoch:   30/60    Loss: 2.9725213961601256\n",
      "\n",
      "Epoch:   30/60    Loss: 2.993962775707245\n",
      "\n",
      "Epoch:   30/60    Loss: 2.991511967420578\n",
      "\n",
      "Epoch:   30/60    Loss: 2.993745790243149\n",
      "\n",
      "Epoch:   30/60    Loss: 3.0240114133358\n",
      "\n",
      "Epoch:   30/60    Loss: 3.060887866973877\n",
      "\n",
      "Epoch:   30/60    Loss: 3.010517231464386\n",
      "\n",
      "Epoch:   30/60    Loss: 2.93312926864624\n",
      "\n",
      "Epoch:   30/60    Loss: 3.0481647379398344\n",
      "\n",
      "Epoch:   30/60    Loss: 2.9815274384021757\n",
      "\n",
      "Epoch:   30/60    Loss: 3.157489766597748\n",
      "\n",
      "Epoch:   30/60    Loss: 3.076118742465973\n",
      "\n",
      "Epoch:   30/60    Loss: 3.124458427667618\n",
      "\n",
      "Epoch:   30/60    Loss: 3.198771340370178\n",
      "\n",
      "Epoch:   30/60    Loss: 3.1020855391025544\n",
      "\n",
      "Epoch:   30/60    Loss: 3.161688735485077\n",
      "\n",
      "Epoch:   30/60    Loss: 3.1078968698978424\n",
      "\n",
      "Epoch:   30/60    Loss: 3.040723175048828\n",
      "\n",
      "Epoch:   30/60    Loss: 2.941658013343811\n",
      "\n",
      "Epoch:   30/60    Loss: 3.159033704280853\n",
      "\n",
      "Epoch:   30/60    Loss: 3.0779104590415955\n",
      "\n",
      "Epoch:   30/60    Loss: 2.9508689806461335\n",
      "\n",
      "Epoch:   30/60    Loss: 2.9317293125391006\n",
      "\n",
      "Epoch:   30/60    Loss: 3.062045939683914\n",
      "\n",
      "Epoch:   30/60    Loss: 2.96294313955307\n",
      "\n",
      "Epoch:   30/60    Loss: 3.0122893900871275\n",
      "\n",
      "Epoch:   30/60    Loss: 3.042671245098114\n",
      "\n",
      "Epoch:   30/60    Loss: 3.0203929522037507\n",
      "\n",
      "Epoch:   30/60    Loss: 3.0017593464851378\n",
      "\n",
      "Epoch:   30/60    Loss: 3.0100570001602174\n",
      "\n",
      "Epoch:   30/60    Loss: 3.0670339584350588\n",
      "\n",
      "Epoch:   30/60    Loss: 3.1475368337631227\n",
      "\n",
      "Epoch:   30/60    Loss: 3.098185524702072\n",
      "\n",
      "Epoch:   30/60    Loss: 3.1626435055732727\n",
      "\n",
      "Epoch:   30/60    Loss: 3.1722052733898165\n",
      "\n",
      "Epoch:   30/60    Loss: 3.1074667232036592\n",
      "\n",
      "Epoch:   30/60    Loss: 3.1526270377635957\n",
      "\n",
      "Epoch:   30/60    Loss: 3.2363417999744417\n",
      "\n",
      "Epoch:   30/60    Loss: 3.1621725404262544\n",
      "\n",
      "Epoch:   30/60    Loss: 3.184684141635895\n",
      "\n",
      "Epoch:   30/60    Loss: 3.2071956992149353\n",
      "\n",
      "Epoch:   30/60    Loss: 3.2244320821762087\n",
      "\n",
      "Epoch:   30/60    Loss: 3.158918437242508\n",
      "\n",
      "Epoch:   30/60    Loss: 3.150056751489639\n",
      "\n",
      "Epoch:   30/60    Loss: 3.1219381046295167\n",
      "\n",
      "Epoch:   30/60    Loss: 3.158297131538391\n",
      "\n",
      "Epoch:   30/60    Loss: 3.103246833562851\n",
      "\n",
      "Epoch:   31/60    Loss: 3.1782259975114595\n",
      "\n",
      "Epoch:   31/60    Loss: 3.196581447839737\n",
      "\n",
      "Epoch:   31/60    Loss: 3.1040210053920747\n",
      "\n",
      "Epoch:   31/60    Loss: 3.1179077801704405\n",
      "\n",
      "Epoch:   31/60    Loss: 3.1125588746070862\n",
      "\n",
      "Epoch:   31/60    Loss: 3.155251037120819\n",
      "\n",
      "Epoch:   31/60    Loss: 3.224366933822632\n",
      "\n",
      "Epoch:   31/60    Loss: 3.1316540677547455\n",
      "\n",
      "Epoch:   31/60    Loss: 2.9668082299232483\n",
      "\n",
      "Epoch:   31/60    Loss: 3.146726080417633\n",
      "\n",
      "Epoch:   31/60    Loss: 3.0646413960456846\n",
      "\n",
      "Epoch:   31/60    Loss: 3.076312267065048\n",
      "\n",
      "Epoch:   31/60    Loss: 2.975865613460541\n",
      "\n",
      "Epoch:   31/60    Loss: 2.985364976644516\n",
      "\n",
      "Epoch:   31/60    Loss: 2.9775849392414093\n",
      "\n",
      "Epoch:   31/60    Loss: 2.9781140625476836\n",
      "\n",
      "Epoch:   31/60    Loss: 3.004886736392975\n",
      "\n",
      "Epoch:   31/60    Loss: 3.049630974769592\n",
      "\n",
      "Epoch:   31/60    Loss: 2.9912080471515656\n",
      "\n",
      "Epoch:   31/60    Loss: 2.9069157140254975\n",
      "\n",
      "Epoch:   31/60    Loss: 3.054383675813675\n",
      "\n",
      "Epoch:   31/60    Loss: 2.9711801595687866\n",
      "\n",
      "Epoch:   31/60    Loss: 3.1315568513870238\n",
      "\n",
      "Epoch:   31/60    Loss: 3.049844933271408\n",
      "\n",
      "Epoch:   31/60    Loss: 3.123380555868149\n",
      "\n",
      "Epoch:   31/60    Loss: 3.165644086360931\n",
      "\n",
      "Epoch:   31/60    Loss: 3.086634991168976\n",
      "\n",
      "Epoch:   31/60    Loss: 3.1576405799388887\n",
      "\n",
      "Epoch:   31/60    Loss: 3.083655501842499\n",
      "\n",
      "Epoch:   31/60    Loss: 3.0428120617866514\n",
      "\n",
      "Epoch:   31/60    Loss: 2.931574454784393\n",
      "\n",
      "Epoch:   31/60    Loss: 3.1417510821819303\n",
      "\n",
      "Epoch:   31/60    Loss: 3.0767595286369325\n",
      "\n",
      "Epoch:   31/60    Loss: 2.9458300352096556\n",
      "\n",
      "Epoch:   31/60    Loss: 2.936626856327057\n",
      "\n",
      "Epoch:   31/60    Loss: 3.0639035873413087\n",
      "\n",
      "Epoch:   31/60    Loss: 2.964131036281586\n",
      "\n",
      "Epoch:   31/60    Loss: 3.021437284708023\n",
      "\n",
      "Epoch:   31/60    Loss: 3.0547752606868745\n",
      "\n",
      "Epoch:   31/60    Loss: 3.000124353647232\n",
      "\n",
      "Epoch:   31/60    Loss: 2.9841701521873474\n",
      "\n",
      "Epoch:   31/60    Loss: 3.010991952896118\n",
      "\n",
      "Epoch:   31/60    Loss: 3.08094780421257\n",
      "\n",
      "Epoch:   31/60    Loss: 3.131435032129288\n",
      "\n",
      "Epoch:   31/60    Loss: 3.092638710975647\n",
      "\n",
      "Epoch:   31/60    Loss: 3.157622986793518\n",
      "\n",
      "Epoch:   31/60    Loss: 3.152037111759186\n",
      "\n",
      "Epoch:   31/60    Loss: 3.090929336309433\n",
      "\n",
      "Epoch:   31/60    Loss: 3.1429014155864716\n",
      "\n",
      "Epoch:   31/60    Loss: 3.2147383258342743\n",
      "\n",
      "Epoch:   31/60    Loss: 3.143448480606079\n",
      "\n",
      "Epoch:   31/60    Loss: 3.1653190810680387\n",
      "\n",
      "Epoch:   31/60    Loss: 3.198370785951614\n",
      "\n",
      "Epoch:   31/60    Loss: 3.202535481929779\n",
      "\n",
      "Epoch:   31/60    Loss: 3.1517985055446625\n",
      "\n",
      "Epoch:   31/60    Loss: 3.1241198625564577\n",
      "\n",
      "Epoch:   31/60    Loss: 3.132288385629654\n",
      "\n",
      "Epoch:   31/60    Loss: 3.1457016088962555\n",
      "\n",
      "Epoch:   31/60    Loss: 3.0990567336082457\n",
      "\n",
      "Epoch:   32/60    Loss: 3.17881835365425\n",
      "\n",
      "Epoch:   32/60    Loss: 3.1918637762069704\n",
      "\n",
      "Epoch:   32/60    Loss: 3.105240847349167\n",
      "\n",
      "Epoch:   32/60    Loss: 3.1123576371669768\n",
      "\n",
      "Epoch:   32/60    Loss: 3.0919654712677\n",
      "\n",
      "Epoch:   32/60    Loss: 3.1546101052761077\n",
      "\n",
      "Epoch:   32/60    Loss: 3.2088785347938535\n",
      "\n",
      "Epoch:   32/60    Loss: 3.113136734485626\n",
      "\n",
      "Epoch:   32/60    Loss: 2.9462667241096496\n",
      "\n",
      "Epoch:   32/60    Loss: 3.1567353401184084\n",
      "\n",
      "Epoch:   32/60    Loss: 3.058941882133484\n",
      "\n",
      "Epoch:   32/60    Loss: 3.064712493181229\n",
      "\n",
      "Epoch:   32/60    Loss: 2.967828981399536\n",
      "\n",
      "Epoch:   32/60    Loss: 2.9885004689693453\n",
      "\n",
      "Epoch:   32/60    Loss: 2.9753766055107116\n",
      "\n",
      "Epoch:   32/60    Loss: 2.982267266511917\n",
      "\n",
      "Epoch:   32/60    Loss: 3.001084571123123\n",
      "\n",
      "Epoch:   32/60    Loss: 3.0460862529277803\n",
      "\n",
      "Epoch:   32/60    Loss: 2.981781590461731\n",
      "\n",
      "Epoch:   32/60    Loss: 2.909105006694794\n",
      "\n",
      "Epoch:   32/60    Loss: 3.0495317492485046\n",
      "\n",
      "Epoch:   32/60    Loss: 2.9569839470386503\n",
      "\n",
      "Epoch:   32/60    Loss: 3.1307226309776306\n",
      "\n",
      "Epoch:   32/60    Loss: 3.0511734731197357\n",
      "\n",
      "Epoch:   32/60    Loss: 3.1257280554771425\n",
      "\n",
      "Epoch:   32/60    Loss: 3.1591051750183103\n",
      "\n",
      "Epoch:   32/60    Loss: 3.0761395530700684\n",
      "\n",
      "Epoch:   32/60    Loss: 3.150798867702484\n",
      "\n",
      "Epoch:   32/60    Loss: 3.0748170235157013\n",
      "\n",
      "Epoch:   32/60    Loss: 3.019593344449997\n",
      "\n",
      "Epoch:   32/60    Loss: 2.9108537013530733\n",
      "\n",
      "Epoch:   32/60    Loss: 3.10223925948143\n",
      "\n",
      "Epoch:   32/60    Loss: 3.0393471343517304\n",
      "\n",
      "Epoch:   32/60    Loss: 2.927425884962082\n",
      "\n",
      "Epoch:   32/60    Loss: 2.918137809753418\n",
      "\n",
      "Epoch:   32/60    Loss: 3.0441638567447664\n",
      "\n",
      "Epoch:   32/60    Loss: 2.954317919969559\n",
      "\n",
      "Epoch:   32/60    Loss: 3.0126265568733217\n",
      "\n",
      "Epoch:   32/60    Loss: 3.0180280675888063\n",
      "\n",
      "Epoch:   32/60    Loss: 2.9952023491859436\n",
      "\n",
      "Epoch:   32/60    Loss: 2.9743887979984285\n",
      "\n",
      "Epoch:   32/60    Loss: 2.9874898557662966\n",
      "\n",
      "Epoch:   32/60    Loss: 3.0520887520313265\n",
      "\n",
      "Epoch:   32/60    Loss: 3.132808999300003\n",
      "\n",
      "Epoch:   32/60    Loss: 3.0795875828266146\n",
      "\n",
      "Epoch:   32/60    Loss: 3.1602372555732727\n",
      "\n",
      "Epoch:   32/60    Loss: 3.158954257249832\n",
      "\n",
      "Epoch:   32/60    Loss: 3.1023238332271577\n",
      "\n",
      "Epoch:   32/60    Loss: 3.1406932299137114\n",
      "\n",
      "Epoch:   32/60    Loss: 3.2285658423900605\n",
      "\n",
      "Epoch:   32/60    Loss: 3.126117061853409\n",
      "\n",
      "Epoch:   32/60    Loss: 3.1678429963588717\n",
      "\n",
      "Epoch:   32/60    Loss: 3.1769622988700865\n",
      "\n",
      "Epoch:   32/60    Loss: 3.199985963344574\n",
      "\n",
      "Epoch:   32/60    Loss: 3.143599509000778\n",
      "\n",
      "Epoch:   32/60    Loss: 3.1261780037879943\n",
      "\n",
      "Epoch:   32/60    Loss: 3.11725160074234\n",
      "\n",
      "Epoch:   32/60    Loss: 3.1238948967456817\n",
      "\n",
      "Epoch:   32/60    Loss: 3.083948718547821\n",
      "\n",
      "Epoch:   33/60    Loss: 3.1705463998343633\n",
      "\n",
      "Epoch:   33/60    Loss: 3.1890233783721924\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   33/60    Loss: 3.0972916464805604\n",
      "\n",
      "Epoch:   33/60    Loss: 3.1054378352165224\n",
      "\n",
      "Epoch:   33/60    Loss: 3.087610771417618\n",
      "\n",
      "Epoch:   33/60    Loss: 3.137322801351547\n",
      "\n",
      "Epoch:   33/60    Loss: 3.207550136804581\n",
      "\n",
      "Epoch:   33/60    Loss: 3.1104293298721313\n",
      "\n",
      "Epoch:   33/60    Loss: 2.9564541738033294\n",
      "\n",
      "Epoch:   33/60    Loss: 3.1338079097270968\n",
      "\n",
      "Epoch:   33/60    Loss: 3.0525307209491728\n",
      "\n",
      "Epoch:   33/60    Loss: 3.0523040096759795\n",
      "\n",
      "Epoch:   33/60    Loss: 2.984789976119995\n",
      "\n",
      "Epoch:   33/60    Loss: 2.9684223103523255\n",
      "\n",
      "Epoch:   33/60    Loss: 2.9658381021022797\n",
      "\n",
      "Epoch:   33/60    Loss: 2.9852140748500826\n",
      "\n",
      "Epoch:   33/60    Loss: 3.0078382341861727\n",
      "\n",
      "Epoch:   33/60    Loss: 3.041002182006836\n",
      "\n",
      "Epoch:   33/60    Loss: 2.976677483558655\n",
      "\n",
      "Epoch:   33/60    Loss: 2.9239862084388735\n",
      "\n",
      "Epoch:   33/60    Loss: 3.04994545173645\n",
      "\n",
      "Epoch:   33/60    Loss: 2.961669871807098\n",
      "\n",
      "Epoch:   33/60    Loss: 3.1258152792453764\n",
      "\n",
      "Epoch:   33/60    Loss: 3.0625193269252775\n",
      "\n",
      "Epoch:   33/60    Loss: 3.1078261854648592\n",
      "\n",
      "Epoch:   33/60    Loss: 3.152232390880585\n",
      "\n",
      "Epoch:   33/60    Loss: 3.0743019559383393\n",
      "\n",
      "Epoch:   33/60    Loss: 3.1514937672615053\n",
      "\n",
      "Epoch:   33/60    Loss: 3.0896307706832884\n",
      "\n",
      "Epoch:   33/60    Loss: 3.014448296070099\n",
      "\n",
      "Epoch:   33/60    Loss: 2.912558705329895\n",
      "\n",
      "Epoch:   33/60    Loss: 3.115330225467682\n",
      "\n",
      "Epoch:   33/60    Loss: 3.0414504408836365\n",
      "\n",
      "Epoch:   33/60    Loss: 2.9362447338104247\n",
      "\n",
      "Epoch:   33/60    Loss: 2.939699576497078\n",
      "\n",
      "Epoch:   33/60    Loss: 3.0637748303413392\n",
      "\n",
      "Epoch:   33/60    Loss: 2.967298913478851\n",
      "\n",
      "Epoch:   33/60    Loss: 3.024495339155197\n",
      "\n",
      "Epoch:   33/60    Loss: 3.0294698882102966\n",
      "\n",
      "Epoch:   33/60    Loss: 2.990122900009155\n",
      "\n",
      "Epoch:   33/60    Loss: 2.971289993286133\n",
      "\n",
      "Epoch:   33/60    Loss: 3.010731971502304\n",
      "\n",
      "Epoch:   33/60    Loss: 3.0654096879959107\n",
      "\n",
      "Epoch:   33/60    Loss: 3.128812580347061\n",
      "\n",
      "Epoch:   33/60    Loss: 3.0737349812984465\n",
      "\n",
      "Epoch:   33/60    Loss: 3.148640888929367\n",
      "\n",
      "Epoch:   33/60    Loss: 3.153101070165634\n",
      "\n",
      "Epoch:   33/60    Loss: 3.081338542222977\n",
      "\n",
      "Epoch:   33/60    Loss: 3.128263285160065\n",
      "\n",
      "Epoch:   33/60    Loss: 3.2049586634635925\n",
      "\n",
      "Epoch:   33/60    Loss: 3.117250919342041\n",
      "\n",
      "Epoch:   33/60    Loss: 3.1584676365852355\n",
      "\n",
      "Epoch:   33/60    Loss: 3.1903491883277892\n",
      "\n",
      "Epoch:   33/60    Loss: 3.1943409068584443\n",
      "\n",
      "Epoch:   33/60    Loss: 3.1335312962532043\n",
      "\n",
      "Epoch:   33/60    Loss: 3.1517373464107514\n",
      "\n",
      "Epoch:   33/60    Loss: 3.116008060216904\n",
      "\n",
      "Epoch:   33/60    Loss: 3.130334142446518\n",
      "\n",
      "Epoch:   33/60    Loss: 3.085222573041916\n",
      "\n",
      "Epoch:   34/60    Loss: 3.1861706899236077\n",
      "\n",
      "Epoch:   34/60    Loss: 3.1849163644313814\n",
      "\n",
      "Epoch:   34/60    Loss: 3.0973918907642366\n",
      "\n",
      "Epoch:   34/60    Loss: 3.0990607764720917\n",
      "\n",
      "Epoch:   34/60    Loss: 3.0733630049228666\n",
      "\n",
      "Epoch:   34/60    Loss: 3.121804697036743\n",
      "\n",
      "Epoch:   34/60    Loss: 3.1933577358722687\n",
      "\n",
      "Epoch:   34/60    Loss: 3.1053919517993926\n",
      "\n",
      "Epoch:   34/60    Loss: 2.964190404176712\n",
      "\n",
      "Epoch:   34/60    Loss: 3.205109890222549\n",
      "\n",
      "Epoch:   34/60    Loss: 3.067805131196976\n",
      "\n",
      "Epoch:   34/60    Loss: 3.0659134476184846\n",
      "\n",
      "Epoch:   34/60    Loss: 2.97984792304039\n",
      "\n",
      "Epoch:   34/60    Loss: 2.963258675098419\n",
      "\n",
      "Epoch:   34/60    Loss: 2.9804603049755096\n",
      "\n",
      "Epoch:   34/60    Loss: 2.996723609685898\n",
      "\n",
      "Epoch:   34/60    Loss: 2.990193009853363\n",
      "\n",
      "Epoch:   34/60    Loss: 3.053738740682602\n",
      "\n",
      "Epoch:   34/60    Loss: 2.9853010942935945\n",
      "\n",
      "Epoch:   34/60    Loss: 2.921634806871414\n",
      "\n",
      "Epoch:   34/60    Loss: 3.0561906580924987\n",
      "\n",
      "Epoch:   34/60    Loss: 2.944456301212311\n",
      "\n",
      "Epoch:   34/60    Loss: 3.128075255870819\n",
      "\n",
      "Epoch:   34/60    Loss: 3.0599674167633055\n",
      "\n",
      "Epoch:   34/60    Loss: 3.1858503000736236\n",
      "\n",
      "Epoch:   34/60    Loss: 3.2118596961498262\n",
      "\n",
      "Epoch:   34/60    Loss: 3.073887254238129\n",
      "\n",
      "Epoch:   34/60    Loss: 3.151592722415924\n",
      "\n",
      "Epoch:   34/60    Loss: 3.11147075009346\n",
      "\n",
      "Epoch:   34/60    Loss: 3.028626959323883\n",
      "\n",
      "Epoch:   34/60    Loss: 2.9251680097579955\n",
      "\n",
      "Epoch:   34/60    Loss: 3.1209397480487824\n",
      "\n",
      "Epoch:   34/60    Loss: 3.0638704338073732\n",
      "\n",
      "Epoch:   34/60    Loss: 2.9260489358901975\n",
      "\n",
      "Epoch:   34/60    Loss: 2.9228864908218384\n",
      "\n",
      "Epoch:   34/60    Loss: 3.0415108785629275\n",
      "\n",
      "Epoch:   34/60    Loss: 3.0140800960063934\n",
      "\n",
      "Epoch:   34/60    Loss: 3.033498083591461\n",
      "\n",
      "Epoch:   34/60    Loss: 3.047578451871872\n",
      "\n",
      "Epoch:   34/60    Loss: 3.0089014930725098\n",
      "\n",
      "Epoch:   34/60    Loss: 3.0018775975704193\n",
      "\n",
      "Epoch:   34/60    Loss: 3.03071093583107\n",
      "\n",
      "Epoch:   34/60    Loss: 3.0750710945129396\n",
      "\n",
      "Epoch:   34/60    Loss: 3.1473272392749787\n",
      "\n",
      "Epoch:   34/60    Loss: 3.096860668897629\n",
      "\n",
      "Epoch:   34/60    Loss: 3.1652978703975676\n",
      "\n",
      "Epoch:   34/60    Loss: 3.185614676475525\n",
      "\n",
      "Epoch:   34/60    Loss: 3.1036993639469146\n",
      "\n",
      "Epoch:   34/60    Loss: 3.138181200504303\n",
      "\n",
      "Epoch:   34/60    Loss: 3.2179928283691406\n",
      "\n",
      "Epoch:   34/60    Loss: 3.14386789894104\n",
      "\n",
      "Epoch:   34/60    Loss: 3.2092092785835264\n",
      "\n",
      "Epoch:   34/60    Loss: 3.2170609834194184\n",
      "\n",
      "Epoch:   34/60    Loss: 3.2053499948978423\n",
      "\n",
      "Epoch:   34/60    Loss: 3.1380536398887635\n",
      "\n",
      "Epoch:   34/60    Loss: 3.140747343301773\n",
      "\n",
      "Epoch:   34/60    Loss: 3.119494415283203\n",
      "\n",
      "Epoch:   34/60    Loss: 3.123211730003357\n",
      "\n",
      "Epoch:   34/60    Loss: 3.0886306030750275\n",
      "\n",
      "Epoch:   35/60    Loss: 3.1894821929542916\n",
      "\n",
      "Epoch:   35/60    Loss: 3.1784431595802305\n",
      "\n",
      "Epoch:   35/60    Loss: 3.084380681037903\n",
      "\n",
      "Epoch:   35/60    Loss: 3.0911667363643645\n",
      "\n",
      "Epoch:   35/60    Loss: 3.072069806098938\n",
      "\n",
      "Epoch:   35/60    Loss: 3.12794201874733\n",
      "\n",
      "Epoch:   35/60    Loss: 3.1895361847877504\n",
      "\n",
      "Epoch:   35/60    Loss: 3.104860337257385\n",
      "\n",
      "Epoch:   35/60    Loss: 2.9512898609638216\n",
      "\n",
      "Epoch:   35/60    Loss: 3.187531141281128\n",
      "\n",
      "Epoch:   35/60    Loss: 3.0593538382053374\n",
      "\n",
      "Epoch:   35/60    Loss: 3.059458706378937\n",
      "\n",
      "Epoch:   35/60    Loss: 2.9752501220703125\n",
      "\n",
      "Epoch:   35/60    Loss: 2.9762490532398225\n",
      "\n",
      "Epoch:   35/60    Loss: 2.9670818445682525\n",
      "\n",
      "Epoch:   35/60    Loss: 2.98245666885376\n",
      "\n",
      "Epoch:   35/60    Loss: 2.9908998320102693\n",
      "\n",
      "Epoch:   35/60    Loss: 3.0524499039649964\n",
      "\n",
      "Epoch:   35/60    Loss: 2.975510601520538\n",
      "\n",
      "Epoch:   35/60    Loss: 2.9055240569114686\n",
      "\n",
      "Epoch:   35/60    Loss: 3.03635653591156\n",
      "\n",
      "Epoch:   35/60    Loss: 2.9379790630340574\n",
      "\n",
      "Epoch:   35/60    Loss: 3.122620486021042\n",
      "\n",
      "Epoch:   35/60    Loss: 3.0484653027057647\n",
      "\n",
      "Epoch:   35/60    Loss: 3.1623841247558593\n",
      "\n",
      "Epoch:   35/60    Loss: 3.1766760089397432\n",
      "\n",
      "Epoch:   35/60    Loss: 3.07910777425766\n",
      "\n",
      "Epoch:   35/60    Loss: 3.143934928655624\n",
      "\n",
      "Epoch:   35/60    Loss: 3.089844637393951\n",
      "\n",
      "Epoch:   35/60    Loss: 3.0007282090187073\n",
      "\n",
      "Epoch:   35/60    Loss: 2.892428570270538\n",
      "\n",
      "Epoch:   35/60    Loss: 3.0971471738815306\n",
      "\n",
      "Epoch:   35/60    Loss: 3.0372003479003906\n",
      "\n",
      "Epoch:   35/60    Loss: 2.9150333194732667\n",
      "\n",
      "Epoch:   35/60    Loss: 2.9144302361011505\n",
      "\n",
      "Epoch:   35/60    Loss: 3.040918859243393\n",
      "\n",
      "Epoch:   35/60    Loss: 2.9727069697380064\n",
      "\n",
      "Epoch:   35/60    Loss: 2.995165593624115\n",
      "\n",
      "Epoch:   35/60    Loss: 3.018919582128525\n",
      "\n",
      "Epoch:   35/60    Loss: 2.9630650074481966\n",
      "\n",
      "Epoch:   35/60    Loss: 2.981726763010025\n",
      "\n",
      "Epoch:   35/60    Loss: 2.99874086022377\n",
      "\n",
      "Epoch:   35/60    Loss: 3.0512151327133177\n",
      "\n",
      "Epoch:   35/60    Loss: 3.128644435405731\n",
      "\n",
      "Epoch:   35/60    Loss: 3.075453406572342\n",
      "\n",
      "Epoch:   35/60    Loss: 3.147720549106598\n",
      "\n",
      "Epoch:   35/60    Loss: 3.1838462364673616\n",
      "\n",
      "Epoch:   35/60    Loss: 3.0882269954681396\n",
      "\n",
      "Epoch:   35/60    Loss: 3.1131210112571717\n",
      "\n",
      "Epoch:   35/60    Loss: 3.1803090524673463\n",
      "\n",
      "Epoch:   35/60    Loss: 3.1348936271667482\n",
      "\n",
      "Epoch:   35/60    Loss: 3.176943425178528\n",
      "\n",
      "Epoch:   35/60    Loss: 3.2020690510272978\n",
      "\n",
      "Epoch:   35/60    Loss: 3.1980169138908385\n",
      "\n",
      "Epoch:   35/60    Loss: 3.141498408794403\n",
      "\n",
      "Epoch:   35/60    Loss: 3.14187984752655\n",
      "\n",
      "Epoch:   35/60    Loss: 3.114202605485916\n",
      "\n",
      "Epoch:   35/60    Loss: 3.124638273000717\n",
      "\n",
      "Epoch:   35/60    Loss: 3.078050146818161\n",
      "\n",
      "Epoch:   36/60    Loss: 3.173302885144949\n",
      "\n",
      "Epoch:   36/60    Loss: 3.1792861087322235\n",
      "\n",
      "Epoch:   36/60    Loss: 3.095037763118744\n",
      "\n",
      "Epoch:   36/60    Loss: 3.1029393763542177\n",
      "\n",
      "Epoch:   36/60    Loss: 3.067325219154358\n",
      "\n",
      "Epoch:   36/60    Loss: 3.1168304505348208\n",
      "\n",
      "Epoch:   36/60    Loss: 3.1881619834899904\n",
      "\n",
      "Epoch:   36/60    Loss: 3.075036755800247\n",
      "\n",
      "Epoch:   36/60    Loss: 2.954404410123825\n",
      "\n",
      "Epoch:   36/60    Loss: 3.1496875107288362\n",
      "\n",
      "Epoch:   36/60    Loss: 3.0602037682533263\n",
      "\n",
      "Epoch:   36/60    Loss: 3.0568134360313417\n",
      "\n",
      "Epoch:   36/60    Loss: 2.9789441928863525\n",
      "\n",
      "Epoch:   36/60    Loss: 2.9810759470462798\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   36/60    Loss: 2.9656807379722596\n",
      "\n",
      "Epoch:   36/60    Loss: 2.96777165055275\n",
      "\n",
      "Epoch:   36/60    Loss: 2.982442436695099\n",
      "\n",
      "Epoch:   36/60    Loss: 3.033561665058136\n",
      "\n",
      "Epoch:   36/60    Loss: 2.952042234659195\n",
      "\n",
      "Epoch:   36/60    Loss: 2.9103558406829833\n",
      "\n",
      "Epoch:   36/60    Loss: 3.0334262130260465\n",
      "\n",
      "Epoch:   36/60    Loss: 2.934503564119339\n",
      "\n",
      "Epoch:   36/60    Loss: 3.104118376970291\n",
      "\n",
      "Epoch:   36/60    Loss: 3.0418269124031068\n",
      "\n",
      "Epoch:   36/60    Loss: 3.1539673998355866\n",
      "\n",
      "Epoch:   36/60    Loss: 3.1702045578956604\n",
      "\n",
      "Epoch:   36/60    Loss: 3.058209401845932\n",
      "\n",
      "Epoch:   36/60    Loss: 3.138608909845352\n",
      "\n",
      "Epoch:   36/60    Loss: 3.084193307161331\n",
      "\n",
      "Epoch:   36/60    Loss: 2.9993287224769594\n",
      "\n",
      "Epoch:   36/60    Loss: 2.8763644599914553\n",
      "\n",
      "Epoch:   36/60    Loss: 3.105853671312332\n",
      "\n",
      "Epoch:   36/60    Loss: 3.0435115427970887\n",
      "\n",
      "Epoch:   36/60    Loss: 2.917991832256317\n",
      "\n",
      "Epoch:   36/60    Loss: 2.904712725877762\n",
      "\n",
      "Epoch:   36/60    Loss: 3.048201247930527\n",
      "\n",
      "Epoch:   36/60    Loss: 2.96268443107605\n",
      "\n",
      "Epoch:   36/60    Loss: 3.0081600432395934\n",
      "\n",
      "Epoch:   36/60    Loss: 3.028305340528488\n",
      "\n",
      "Epoch:   36/60    Loss: 2.9888019688129424\n",
      "\n",
      "Epoch:   36/60    Loss: 2.9759749593734743\n",
      "\n",
      "Epoch:   36/60    Loss: 2.9854643242359162\n",
      "\n",
      "Epoch:   36/60    Loss: 3.0548310639858247\n",
      "\n",
      "Epoch:   36/60    Loss: 3.1199749495983125\n",
      "\n",
      "Epoch:   36/60    Loss: 3.0759076635837554\n",
      "\n",
      "Epoch:   36/60    Loss: 3.1325815575122835\n",
      "\n",
      "Epoch:   36/60    Loss: 3.160965591430664\n",
      "\n",
      "Epoch:   36/60    Loss: 3.0680247476100924\n",
      "\n",
      "Epoch:   36/60    Loss: 3.1109073255062105\n",
      "\n",
      "Epoch:   36/60    Loss: 3.16745755982399\n",
      "\n",
      "Epoch:   36/60    Loss: 3.117165856838226\n",
      "\n",
      "Epoch:   36/60    Loss: 3.1736557612419127\n",
      "\n",
      "Epoch:   36/60    Loss: 3.1997082562446595\n",
      "\n",
      "Epoch:   36/60    Loss: 3.1962783110141753\n",
      "\n",
      "Epoch:   36/60    Loss: 3.132851837396622\n",
      "\n",
      "Epoch:   36/60    Loss: 3.1437093484401704\n",
      "\n",
      "Epoch:   36/60    Loss: 3.1081204872131347\n",
      "\n",
      "Epoch:   36/60    Loss: 3.1227819180488585\n",
      "\n",
      "Epoch:   36/60    Loss: 3.0703429045677186\n",
      "\n",
      "Epoch:   37/60    Loss: 3.1481142563988334\n",
      "\n",
      "Epoch:   37/60    Loss: 3.1700779001712798\n",
      "\n",
      "Epoch:   37/60    Loss: 3.0801383843421934\n",
      "\n",
      "Epoch:   37/60    Loss: 3.0936452903747558\n",
      "\n",
      "Epoch:   37/60    Loss: 3.0428838410377503\n",
      "\n",
      "Epoch:   37/60    Loss: 3.129092566251755\n",
      "\n",
      "Epoch:   37/60    Loss: 3.17870907497406\n",
      "\n",
      "Epoch:   37/60    Loss: 3.0788731503486635\n",
      "\n",
      "Epoch:   37/60    Loss: 2.9650612819194793\n",
      "\n",
      "Epoch:   37/60    Loss: 3.1427767186164854\n",
      "\n",
      "Epoch:   37/60    Loss: 3.0405018367767336\n",
      "\n",
      "Epoch:   37/60    Loss: 3.0382130880355835\n",
      "\n",
      "Epoch:   37/60    Loss: 2.972416882753372\n",
      "\n",
      "Epoch:   37/60    Loss: 2.9789421162605287\n",
      "\n",
      "Epoch:   37/60    Loss: 2.9543784708976744\n",
      "\n",
      "Epoch:   37/60    Loss: 2.971674109697342\n",
      "\n",
      "Epoch:   37/60    Loss: 2.989449418306351\n",
      "\n",
      "Epoch:   37/60    Loss: 3.0192961916923524\n",
      "\n",
      "Epoch:   37/60    Loss: 2.9442588551044464\n",
      "\n",
      "Epoch:   37/60    Loss: 2.891411461353302\n",
      "\n",
      "Epoch:   37/60    Loss: 3.0258099892139434\n",
      "\n",
      "Epoch:   37/60    Loss: 2.9225511248111724\n",
      "\n",
      "Epoch:   37/60    Loss: 3.107248735189438\n",
      "\n",
      "Epoch:   37/60    Loss: 3.035632571697235\n",
      "\n",
      "Epoch:   37/60    Loss: 3.136086362838745\n",
      "\n",
      "Epoch:   37/60    Loss: 3.1494858944416046\n",
      "\n",
      "Epoch:   37/60    Loss: 3.0605237138271333\n",
      "\n",
      "Epoch:   37/60    Loss: 3.125300415992737\n",
      "\n",
      "Epoch:   37/60    Loss: 3.076999696969986\n",
      "\n",
      "Epoch:   37/60    Loss: 2.983711388349533\n",
      "\n",
      "Epoch:   37/60    Loss: 2.8714251239299773\n",
      "\n",
      "Epoch:   37/60    Loss: 3.0682800340652467\n",
      "\n",
      "Epoch:   37/60    Loss: 3.022811788320541\n",
      "\n",
      "Epoch:   37/60    Loss: 2.8985137860774994\n",
      "\n",
      "Epoch:   37/60    Loss: 2.898397704958916\n",
      "\n",
      "Epoch:   37/60    Loss: 3.0313122229576113\n",
      "\n",
      "Epoch:   37/60    Loss: 2.9597419822216033\n",
      "\n",
      "Epoch:   37/60    Loss: 2.9815456066131594\n",
      "\n",
      "Epoch:   37/60    Loss: 3.0218827304840086\n",
      "\n",
      "Epoch:   37/60    Loss: 2.97951970911026\n",
      "\n",
      "Epoch:   37/60    Loss: 2.9797503004074097\n",
      "\n",
      "Epoch:   37/60    Loss: 2.972579386949539\n",
      "\n",
      "Epoch:   37/60    Loss: 3.0605340282917024\n",
      "\n",
      "Epoch:   37/60    Loss: 3.12198556137085\n",
      "\n",
      "Epoch:   37/60    Loss: 3.0656176595687867\n",
      "\n",
      "Epoch:   37/60    Loss: 3.1309004652500154\n",
      "\n",
      "Epoch:   37/60    Loss: 3.177590415239334\n",
      "\n",
      "Epoch:   37/60    Loss: 3.0528208725452424\n",
      "\n",
      "Epoch:   37/60    Loss: 3.081958196401596\n",
      "\n",
      "Epoch:   37/60    Loss: 3.168526504278183\n",
      "\n",
      "Epoch:   37/60    Loss: 3.1100663096904753\n",
      "\n",
      "Epoch:   37/60    Loss: 3.177379049539566\n",
      "\n",
      "Epoch:   37/60    Loss: 3.2014407675266265\n",
      "\n",
      "Epoch:   37/60    Loss: 3.2013019881248472\n",
      "\n",
      "Epoch:   37/60    Loss: 3.1116405363082884\n",
      "\n",
      "Epoch:   37/60    Loss: 3.131434072494507\n",
      "\n",
      "Epoch:   37/60    Loss: 3.0917666301727293\n",
      "\n",
      "Epoch:   37/60    Loss: 3.096025139808655\n",
      "\n",
      "Epoch:   37/60    Loss: 3.0715293262004852\n",
      "\n",
      "Epoch:   38/60    Loss: 3.1389347170682056\n",
      "\n",
      "Epoch:   38/60    Loss: 3.144345749616623\n",
      "\n",
      "Epoch:   38/60    Loss: 3.058508293390274\n",
      "\n",
      "Epoch:   38/60    Loss: 3.0820131916999816\n",
      "\n",
      "Epoch:   38/60    Loss: 3.0240564024448395\n",
      "\n",
      "Epoch:   38/60    Loss: 3.118771219730377\n",
      "\n",
      "Epoch:   38/60    Loss: 3.1633186745643616\n",
      "\n",
      "Epoch:   38/60    Loss: 3.064795875787735\n",
      "\n",
      "Epoch:   38/60    Loss: 2.9454488620758057\n",
      "\n",
      "Epoch:   38/60    Loss: 3.1307691967487337\n",
      "\n",
      "Epoch:   38/60    Loss: 3.039781153678894\n",
      "\n",
      "Epoch:   38/60    Loss: 3.031111707687378\n",
      "\n",
      "Epoch:   38/60    Loss: 2.9667810270786283\n",
      "\n",
      "Epoch:   38/60    Loss: 2.9841043014526365\n",
      "\n",
      "Epoch:   38/60    Loss: 2.950550648212433\n",
      "\n",
      "Epoch:   38/60    Loss: 2.952563541173935\n",
      "\n",
      "Epoch:   38/60    Loss: 2.987652824640274\n",
      "\n",
      "Epoch:   38/60    Loss: 3.0067065947055815\n",
      "\n",
      "Epoch:   38/60    Loss: 2.953228824853897\n",
      "\n",
      "Epoch:   38/60    Loss: 2.894010226011276\n",
      "\n",
      "Epoch:   38/60    Loss: 3.014816735744476\n",
      "\n",
      "Epoch:   38/60    Loss: 2.9212001101970673\n",
      "\n",
      "Epoch:   38/60    Loss: 3.092692663192749\n",
      "\n",
      "Epoch:   38/60    Loss: 3.0314877688884736\n",
      "\n",
      "Epoch:   38/60    Loss: 3.1489054553508757\n",
      "\n",
      "Epoch:   38/60    Loss: 3.1366248598098756\n",
      "\n",
      "Epoch:   38/60    Loss: 3.051818100452423\n",
      "\n",
      "Epoch:   38/60    Loss: 3.117445320606232\n",
      "\n",
      "Epoch:   38/60    Loss: 3.0770897059440614\n",
      "\n",
      "Epoch:   38/60    Loss: 2.9868664031028747\n",
      "\n",
      "Epoch:   38/60    Loss: 2.8650772910118105\n",
      "\n",
      "Epoch:   38/60    Loss: 3.0584479722976683\n",
      "\n",
      "Epoch:   38/60    Loss: 3.004020450592041\n",
      "\n",
      "Epoch:   38/60    Loss: 2.9009191098213196\n",
      "\n",
      "Epoch:   38/60    Loss: 2.899100332379341\n",
      "\n",
      "Epoch:   38/60    Loss: 3.019701493501663\n",
      "\n",
      "Epoch:   38/60    Loss: 2.9504950494766233\n",
      "\n",
      "Epoch:   38/60    Loss: 2.988217223882675\n",
      "\n",
      "Epoch:   38/60    Loss: 3.01880958032608\n",
      "\n",
      "Epoch:   38/60    Loss: 2.9579134821891784\n",
      "\n",
      "Epoch:   38/60    Loss: 2.9615123476982115\n",
      "\n",
      "Epoch:   38/60    Loss: 2.9815971457958224\n",
      "\n",
      "Epoch:   38/60    Loss: 3.047356778860092\n",
      "\n",
      "Epoch:   38/60    Loss: 3.110862074136734\n",
      "\n",
      "Epoch:   38/60    Loss: 3.0599793372154234\n",
      "\n",
      "Epoch:   38/60    Loss: 3.1147408182621\n",
      "\n",
      "Epoch:   38/60    Loss: 3.156835874080658\n",
      "\n",
      "Epoch:   38/60    Loss: 3.0447343776226043\n",
      "\n",
      "Epoch:   38/60    Loss: 3.088047639608383\n",
      "\n",
      "Epoch:   38/60    Loss: 3.173002005815506\n",
      "\n",
      "Epoch:   38/60    Loss: 3.109811360836029\n",
      "\n",
      "Epoch:   38/60    Loss: 3.154600687265396\n",
      "\n",
      "Epoch:   38/60    Loss: 3.16610284948349\n",
      "\n",
      "Epoch:   38/60    Loss: 3.1789481678009035\n",
      "\n",
      "Epoch:   38/60    Loss: 3.1080629715919494\n",
      "\n",
      "Epoch:   38/60    Loss: 3.13068598818779\n",
      "\n",
      "Epoch:   38/60    Loss: 3.0910221350193026\n",
      "\n",
      "Epoch:   38/60    Loss: 3.107727843761444\n",
      "\n",
      "Epoch:   38/60    Loss: 3.062282696247101\n",
      "\n",
      "Epoch:   39/60    Loss: 3.1250405731084556\n",
      "\n",
      "Epoch:   39/60    Loss: 3.15772588801384\n",
      "\n",
      "Epoch:   39/60    Loss: 3.07127366566658\n",
      "\n",
      "Epoch:   39/60    Loss: 3.082715462207794\n",
      "\n",
      "Epoch:   39/60    Loss: 3.0463307187557223\n",
      "\n",
      "Epoch:   39/60    Loss: 3.1374029169082642\n",
      "\n",
      "Epoch:   39/60    Loss: 3.1684657254219055\n",
      "\n",
      "Epoch:   39/60    Loss: 3.0719260218143463\n",
      "\n",
      "Epoch:   39/60    Loss: 2.9429920599460604\n",
      "\n",
      "Epoch:   39/60    Loss: 3.1235665628910065\n",
      "\n",
      "Epoch:   39/60    Loss: 3.0425378983020783\n",
      "\n",
      "Epoch:   39/60    Loss: 3.037440004348755\n",
      "\n",
      "Epoch:   39/60    Loss: 2.9713542261123655\n",
      "\n",
      "Epoch:   39/60    Loss: 2.991943059921265\n",
      "\n",
      "Epoch:   39/60    Loss: 2.946016527175903\n",
      "\n",
      "Epoch:   39/60    Loss: 2.9659835741519927\n",
      "\n",
      "Epoch:   39/60    Loss: 2.9811646983623503\n",
      "\n",
      "Epoch:   39/60    Loss: 3.0268825647830964\n",
      "\n",
      "Epoch:   39/60    Loss: 2.9480661749839783\n",
      "\n",
      "Epoch:   39/60    Loss: 2.8944881286621094\n",
      "\n",
      "Epoch:   39/60    Loss: 3.0162426176071166\n",
      "\n",
      "Epoch:   39/60    Loss: 2.9168019099235534\n",
      "\n",
      "Epoch:   39/60    Loss: 3.0922558283805848\n",
      "\n",
      "Epoch:   39/60    Loss: 3.0300139379501343\n",
      "\n",
      "Epoch:   39/60    Loss: 3.147718927145004\n",
      "\n",
      "Epoch:   39/60    Loss: 3.127772345542908\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   39/60    Loss: 3.038557509422302\n",
      "\n",
      "Epoch:   39/60    Loss: 3.117521201133728\n",
      "\n",
      "Epoch:   39/60    Loss: 3.0802025334835053\n",
      "\n",
      "Epoch:   39/60    Loss: 2.9909650919437407\n",
      "\n",
      "Epoch:   39/60    Loss: 2.8562294316291807\n",
      "\n",
      "Epoch:   39/60    Loss: 3.055903832912445\n",
      "\n",
      "Epoch:   39/60    Loss: 3.005458951711655\n",
      "\n",
      "Epoch:   39/60    Loss: 2.9040640454292297\n",
      "\n",
      "Epoch:   39/60    Loss: 2.914397147655487\n",
      "\n",
      "Epoch:   39/60    Loss: 3.0236536610126494\n",
      "\n",
      "Epoch:   39/60    Loss: 2.9534739577770233\n",
      "\n",
      "Epoch:   39/60    Loss: 3.0052827398777007\n",
      "\n",
      "Epoch:   39/60    Loss: 3.0413389294147493\n",
      "\n",
      "Epoch:   39/60    Loss: 2.9607503249645233\n",
      "\n",
      "Epoch:   39/60    Loss: 2.9586686508655546\n",
      "\n",
      "Epoch:   39/60    Loss: 2.995025770664215\n",
      "\n",
      "Epoch:   39/60    Loss: 3.0581513793468473\n",
      "\n",
      "Epoch:   39/60    Loss: 3.120459712743759\n",
      "\n",
      "Epoch:   39/60    Loss: 3.060416044473648\n",
      "\n",
      "Epoch:   39/60    Loss: 3.1194103260040285\n",
      "\n",
      "Epoch:   39/60    Loss: 3.1485910918712614\n",
      "\n",
      "Epoch:   39/60    Loss: 3.0498586325645447\n",
      "\n",
      "Epoch:   39/60    Loss: 3.093242623806\n",
      "\n",
      "Epoch:   39/60    Loss: 3.1592773957252502\n",
      "\n",
      "Epoch:   39/60    Loss: 3.1060505237579346\n",
      "\n",
      "Epoch:   39/60    Loss: 3.141702759027481\n",
      "\n",
      "Epoch:   39/60    Loss: 3.178971615791321\n",
      "\n",
      "Epoch:   39/60    Loss: 3.1936564288139344\n",
      "\n",
      "Epoch:   39/60    Loss: 3.097660556316376\n",
      "\n",
      "Epoch:   39/60    Loss: 3.1185722861289977\n",
      "\n",
      "Epoch:   39/60    Loss: 3.083045645236969\n",
      "\n",
      "Epoch:   39/60    Loss: 3.082092263698578\n",
      "\n",
      "Epoch:   39/60    Loss: 3.066607334136963\n",
      "\n",
      "Epoch:   40/60    Loss: 3.1262721749751465\n",
      "\n",
      "Epoch:   40/60    Loss: 3.148907691001892\n",
      "\n",
      "Epoch:   40/60    Loss: 3.0517247793674467\n",
      "\n",
      "Epoch:   40/60    Loss: 3.10187824678421\n",
      "\n",
      "Epoch:   40/60    Loss: 3.142848861217499\n",
      "\n",
      "Epoch:   40/60    Loss: 3.173131920814514\n",
      "\n",
      "Epoch:   40/60    Loss: 3.2105554661750793\n",
      "\n",
      "Epoch:   40/60    Loss: 3.0995560040473937\n",
      "\n",
      "Epoch:   40/60    Loss: 2.9687626230716706\n",
      "\n",
      "Epoch:   40/60    Loss: 3.1522324459552764\n",
      "\n",
      "Epoch:   40/60    Loss: 3.0421516778469084\n",
      "\n",
      "Epoch:   40/60    Loss: 3.0263333070278167\n",
      "\n",
      "Epoch:   40/60    Loss: 2.955805886030197\n",
      "\n",
      "Epoch:   40/60    Loss: 2.9651662061214448\n",
      "\n",
      "Epoch:   40/60    Loss: 2.9366647222042084\n",
      "\n",
      "Epoch:   40/60    Loss: 2.961541243314743\n",
      "\n",
      "Epoch:   40/60    Loss: 2.969838995218277\n",
      "\n",
      "Epoch:   40/60    Loss: 3.0214133851528167\n",
      "\n",
      "Epoch:   40/60    Loss: 2.9352246391773225\n",
      "\n",
      "Epoch:   40/60    Loss: 2.8740109627246855\n",
      "\n",
      "Epoch:   40/60    Loss: 2.997951092481613\n",
      "\n",
      "Epoch:   40/60    Loss: 2.915254445075989\n",
      "\n",
      "Epoch:   40/60    Loss: 3.1049278421401976\n",
      "\n",
      "Epoch:   40/60    Loss: 3.046305191993713\n",
      "\n",
      "Epoch:   40/60    Loss: 3.1553846259117124\n",
      "\n",
      "Epoch:   40/60    Loss: 3.0973890750408173\n",
      "\n",
      "Epoch:   40/60    Loss: 3.0563858513832094\n",
      "\n",
      "Epoch:   40/60    Loss: 3.1086518144607544\n",
      "\n",
      "Epoch:   40/60    Loss: 3.057493339776993\n",
      "\n",
      "Epoch:   40/60    Loss: 3.0017341783046723\n",
      "\n",
      "Epoch:   40/60    Loss: 2.8658252255916596\n",
      "\n",
      "Epoch:   40/60    Loss: 3.058959479570389\n",
      "\n",
      "Epoch:   40/60    Loss: 3.0000039873123168\n",
      "\n",
      "Epoch:   40/60    Loss: 2.8963545966148376\n",
      "\n",
      "Epoch:   40/60    Loss: 2.890125222444534\n",
      "\n",
      "Epoch:   40/60    Loss: 3.029244445323944\n",
      "\n",
      "Epoch:   40/60    Loss: 2.9513508982658387\n",
      "\n",
      "Epoch:   40/60    Loss: 2.9996849813461304\n",
      "\n",
      "Epoch:   40/60    Loss: 3.047045772790909\n",
      "\n",
      "Epoch:   40/60    Loss: 2.9656163747310638\n",
      "\n",
      "Epoch:   40/60    Loss: 2.9553837544918062\n",
      "\n",
      "Epoch:   40/60    Loss: 2.9714024970531465\n",
      "\n",
      "Epoch:   40/60    Loss: 3.053172397851944\n",
      "\n",
      "Epoch:   40/60    Loss: 3.1181537103652954\n",
      "\n",
      "Epoch:   40/60    Loss: 3.0446594023704527\n",
      "\n",
      "Epoch:   40/60    Loss: 3.1095355508327485\n",
      "\n",
      "Epoch:   40/60    Loss: 3.1461827986240385\n",
      "\n",
      "Epoch:   40/60    Loss: 3.0466291913986208\n",
      "\n",
      "Epoch:   40/60    Loss: 3.0681727793216704\n",
      "\n",
      "Epoch:   40/60    Loss: 3.1494550058841706\n",
      "\n",
      "Epoch:   40/60    Loss: 3.0827660233974457\n",
      "\n",
      "Epoch:   40/60    Loss: 3.1503564772605896\n",
      "\n",
      "Epoch:   40/60    Loss: 3.1694176137447356\n",
      "\n",
      "Epoch:   40/60    Loss: 3.1773688747882844\n",
      "\n",
      "Epoch:   40/60    Loss: 3.0824504415988923\n",
      "\n",
      "Epoch:   40/60    Loss: 3.1022457056045534\n",
      "\n",
      "Epoch:   40/60    Loss: 3.068397121191025\n",
      "\n",
      "Epoch:   40/60    Loss: 3.075532869338989\n",
      "\n",
      "Epoch:   40/60    Loss: 3.0700600798130036\n",
      "\n",
      "Epoch:   41/60    Loss: 3.086030999927417\n",
      "\n",
      "Epoch:   41/60    Loss: 3.116550425291061\n",
      "\n",
      "Epoch:   41/60    Loss: 3.0376320865154267\n",
      "\n",
      "Epoch:   41/60    Loss: 3.060008834838867\n",
      "\n",
      "Epoch:   41/60    Loss: 3.0272209384441378\n",
      "\n",
      "Epoch:   41/60    Loss: 3.1179986658096315\n",
      "\n",
      "Epoch:   41/60    Loss: 3.148656722307205\n",
      "\n",
      "Epoch:   41/60    Loss: 3.050597101211548\n",
      "\n",
      "Epoch:   41/60    Loss: 2.9265604510307313\n",
      "\n",
      "Epoch:   41/60    Loss: 3.0997251217365265\n",
      "\n",
      "Epoch:   41/60    Loss: 3.0229703443050386\n",
      "\n",
      "Epoch:   41/60    Loss: 3.0274320492744446\n",
      "\n",
      "Epoch:   41/60    Loss: 2.966873325586319\n",
      "\n",
      "Epoch:   41/60    Loss: 2.960293667078018\n",
      "\n",
      "Epoch:   41/60    Loss: 2.9374149515628813\n",
      "\n",
      "Epoch:   41/60    Loss: 2.9706977529525758\n",
      "\n",
      "Epoch:   41/60    Loss: 2.9651681380271913\n",
      "\n",
      "Epoch:   41/60    Loss: 3.0076396260261538\n",
      "\n",
      "Epoch:   41/60    Loss: 2.9499938471317293\n",
      "\n",
      "Epoch:   41/60    Loss: 2.8843137681484223\n",
      "\n",
      "Epoch:   41/60    Loss: 3.002869258880615\n",
      "\n",
      "Epoch:   41/60    Loss: 2.912875291109085\n",
      "\n",
      "Epoch:   41/60    Loss: 3.0777210726737976\n",
      "\n",
      "Epoch:   41/60    Loss: 3.027593333005905\n",
      "\n",
      "Epoch:   41/60    Loss: 3.1373018810749054\n",
      "\n",
      "Epoch:   41/60    Loss: 3.099492845058441\n",
      "\n",
      "Epoch:   41/60    Loss: 3.0316268074512482\n",
      "\n",
      "Epoch:   41/60    Loss: 3.1009825830459596\n",
      "\n",
      "Epoch:   41/60    Loss: 3.0388744921684263\n",
      "\n",
      "Epoch:   41/60    Loss: 2.965761347770691\n",
      "\n",
      "Epoch:   41/60    Loss: 2.851779157400131\n",
      "\n",
      "Epoch:   41/60    Loss: 3.033067460775375\n",
      "\n",
      "Epoch:   41/60    Loss: 3.011154436826706\n",
      "\n",
      "Epoch:   41/60    Loss: 2.873066217660904\n",
      "\n",
      "Epoch:   41/60    Loss: 2.886397496461868\n",
      "\n",
      "Epoch:   41/60    Loss: 3.015625423908234\n",
      "\n",
      "Epoch:   41/60    Loss: 2.9514209656715393\n",
      "\n",
      "Epoch:   41/60    Loss: 2.9817888679504394\n",
      "\n",
      "Epoch:   41/60    Loss: 3.0122427484989167\n",
      "\n",
      "Epoch:   41/60    Loss: 2.9557553970813752\n",
      "\n",
      "Epoch:   41/60    Loss: 2.946123316049576\n",
      "\n",
      "Epoch:   41/60    Loss: 2.96768151807785\n",
      "\n",
      "Epoch:   41/60    Loss: 3.0333781740665438\n",
      "\n",
      "Epoch:   41/60    Loss: 3.104801787137985\n",
      "\n",
      "Epoch:   41/60    Loss: 3.0382493803501127\n",
      "\n",
      "Epoch:   41/60    Loss: 3.118915191411972\n",
      "\n",
      "Epoch:   41/60    Loss: 3.1279202046394348\n",
      "\n",
      "Epoch:   41/60    Loss: 3.0094738745689393\n",
      "\n",
      "Epoch:   41/60    Loss: 3.0573804059028626\n",
      "\n",
      "Epoch:   41/60    Loss: 3.1436093454360963\n",
      "\n",
      "Epoch:   41/60    Loss: 3.082442863225937\n",
      "\n",
      "Epoch:   41/60    Loss: 3.1261413323879244\n",
      "\n",
      "Epoch:   41/60    Loss: 3.1618354506492614\n",
      "\n",
      "Epoch:   41/60    Loss: 3.181948473453522\n",
      "\n",
      "Epoch:   41/60    Loss: 3.0704736166000366\n",
      "\n",
      "Epoch:   41/60    Loss: 3.1182702403068543\n",
      "\n",
      "Epoch:   41/60    Loss: 3.0651849091053007\n",
      "\n",
      "Epoch:   41/60    Loss: 3.057775611639023\n",
      "\n",
      "Epoch:   41/60    Loss: 3.0434089710712433\n",
      "\n",
      "Epoch:   42/60    Loss: 3.092148725591276\n",
      "\n",
      "Epoch:   42/60    Loss: 3.1293621854782105\n",
      "\n",
      "Epoch:   42/60    Loss: 3.0457620327472688\n",
      "\n",
      "Epoch:   42/60    Loss: 3.0670481851100924\n",
      "\n",
      "Epoch:   42/60    Loss: 3.0581257984638213\n",
      "\n",
      "Epoch:   42/60    Loss: 3.115144844532013\n",
      "\n",
      "Epoch:   42/60    Loss: 3.1493120954036713\n",
      "\n",
      "Epoch:   42/60    Loss: 3.0499859528541564\n",
      "\n",
      "Epoch:   42/60    Loss: 2.9254602830410006\n",
      "\n",
      "Epoch:   42/60    Loss: 3.0729503524303436\n",
      "\n",
      "Epoch:   42/60    Loss: 3.023276232481003\n",
      "\n",
      "Epoch:   42/60    Loss: 3.0174328706264495\n",
      "\n",
      "Epoch:   42/60    Loss: 2.9666012465953826\n",
      "\n",
      "Epoch:   42/60    Loss: 2.9638283627033233\n",
      "\n",
      "Epoch:   42/60    Loss: 2.9287453491687776\n",
      "\n",
      "Epoch:   42/60    Loss: 2.9471066427230834\n",
      "\n",
      "Epoch:   42/60    Loss: 2.974882519006729\n",
      "\n",
      "Epoch:   42/60    Loss: 3.0059455924034117\n",
      "\n",
      "Epoch:   42/60    Loss: 2.948490542173386\n",
      "\n",
      "Epoch:   42/60    Loss: 2.871450941801071\n",
      "\n",
      "Epoch:   42/60    Loss: 3.006770128250122\n",
      "\n",
      "Epoch:   42/60    Loss: 2.9016582918167115\n",
      "\n",
      "Epoch:   42/60    Loss: 3.0764598083496093\n",
      "\n",
      "Epoch:   42/60    Loss: 3.03523712515831\n",
      "\n",
      "Epoch:   42/60    Loss: 3.1342465941905977\n",
      "\n",
      "Epoch:   42/60    Loss: 3.106542479991913\n",
      "\n",
      "Epoch:   42/60    Loss: 3.0428971168994905\n",
      "\n",
      "Epoch:   42/60    Loss: 3.1229171984195707\n",
      "\n",
      "Epoch:   42/60    Loss: 3.0607087128162385\n",
      "\n",
      "Epoch:   42/60    Loss: 2.9672075123786925\n",
      "\n",
      "Epoch:   42/60    Loss: 2.842102677345276\n",
      "\n",
      "Epoch:   42/60    Loss: 3.028514805316925\n",
      "\n",
      "Epoch:   42/60    Loss: 3.005133458137512\n",
      "\n",
      "Epoch:   42/60    Loss: 2.8838301157951354\n",
      "\n",
      "Epoch:   42/60    Loss: 2.8944777755737303\n",
      "\n",
      "Epoch:   42/60    Loss: 3.0239533140659334\n",
      "\n",
      "Epoch:   42/60    Loss: 2.9547366995811464\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   42/60    Loss: 3.0098736870288847\n",
      "\n",
      "Epoch:   42/60    Loss: 3.0317411084175108\n",
      "\n",
      "Epoch:   42/60    Loss: 2.967855660200119\n",
      "\n",
      "Epoch:   42/60    Loss: 2.9548491938114165\n",
      "\n",
      "Epoch:   42/60    Loss: 2.978021357059479\n",
      "\n",
      "Epoch:   42/60    Loss: 3.051149995803833\n",
      "\n",
      "Epoch:   42/60    Loss: 3.130338718891144\n",
      "\n",
      "Epoch:   42/60    Loss: 3.0561192433834075\n",
      "\n",
      "Epoch:   42/60    Loss: 3.1148892934322356\n",
      "\n",
      "Epoch:   42/60    Loss: 3.1519591093063353\n",
      "\n",
      "Epoch:   42/60    Loss: 3.0412966356277464\n",
      "\n",
      "Epoch:   42/60    Loss: 3.0832574646472932\n",
      "\n",
      "Epoch:   42/60    Loss: 3.151954854488373\n",
      "\n",
      "Epoch:   42/60    Loss: 3.1058541417121885\n",
      "\n",
      "Epoch:   42/60    Loss: 3.124259605884552\n",
      "\n",
      "Epoch:   42/60    Loss: 3.1767401390075682\n",
      "\n",
      "Epoch:   42/60    Loss: 3.180327879190445\n",
      "\n",
      "Epoch:   42/60    Loss: 3.0894172797203066\n",
      "\n",
      "Epoch:   42/60    Loss: 3.118107046842575\n",
      "\n",
      "Epoch:   42/60    Loss: 3.073662515163422\n",
      "\n",
      "Epoch:   42/60    Loss: 3.057678426027298\n",
      "\n",
      "Epoch:   42/60    Loss: 3.0592990016937254\n",
      "\n",
      "Epoch:   43/60    Loss: 3.1100704694247763\n",
      "\n",
      "Epoch:   43/60    Loss: 3.110792987585068\n",
      "\n",
      "Epoch:   43/60    Loss: 3.0422075967788698\n",
      "\n",
      "Epoch:   43/60    Loss: 3.0662009761333464\n",
      "\n",
      "Epoch:   43/60    Loss: 3.0339917266368865\n",
      "\n",
      "Epoch:   43/60    Loss: 3.0826671562194825\n",
      "\n",
      "Epoch:   43/60    Loss: 3.1384483904838563\n",
      "\n",
      "Epoch:   43/60    Loss: 3.0543555226325987\n",
      "\n",
      "Epoch:   43/60    Loss: 2.91785999917984\n",
      "\n",
      "Epoch:   43/60    Loss: 3.096923757314682\n",
      "\n",
      "Epoch:   43/60    Loss: 3.0183658010959626\n",
      "\n",
      "Epoch:   43/60    Loss: 3.0245808005332946\n",
      "\n",
      "Epoch:   43/60    Loss: 2.9725626828670504\n",
      "\n",
      "Epoch:   43/60    Loss: 2.969960765838623\n",
      "\n",
      "Epoch:   43/60    Loss: 2.93476940703392\n",
      "\n",
      "Epoch:   43/60    Loss: 2.94625671505928\n",
      "\n",
      "Epoch:   43/60    Loss: 2.986353925704956\n",
      "\n",
      "Epoch:   43/60    Loss: 3.024359981536865\n",
      "\n",
      "Epoch:   43/60    Loss: 2.949137754201889\n",
      "\n",
      "Epoch:   43/60    Loss: 2.8770002391338347\n",
      "\n",
      "Epoch:   43/60    Loss: 3.012836408853531\n",
      "\n",
      "Epoch:   43/60    Loss: 2.9257607207298277\n",
      "\n",
      "Epoch:   43/60    Loss: 3.090638847112656\n",
      "\n",
      "Epoch:   43/60    Loss: 3.030079158067703\n",
      "\n",
      "Epoch:   43/60    Loss: 3.1261641302108765\n",
      "\n",
      "Epoch:   43/60    Loss: 3.11188418340683\n",
      "\n",
      "Epoch:   43/60    Loss: 3.0341323969364167\n",
      "\n",
      "Epoch:   43/60    Loss: 3.1006702978610994\n",
      "\n",
      "Epoch:   43/60    Loss: 3.0408530402183533\n",
      "\n",
      "Epoch:   43/60    Loss: 2.983079584121704\n",
      "\n",
      "Epoch:   43/60    Loss: 2.841561742544174\n",
      "\n",
      "Epoch:   43/60    Loss: 3.0360674197673796\n",
      "\n",
      "Epoch:   43/60    Loss: 2.9797712275981905\n",
      "\n",
      "Epoch:   43/60    Loss: 2.885895172357559\n",
      "\n",
      "Epoch:   43/60    Loss: 2.875544925570488\n",
      "\n",
      "Epoch:   43/60    Loss: 3.0098095169067385\n",
      "\n",
      "Epoch:   43/60    Loss: 2.9556259937286375\n",
      "\n",
      "Epoch:   43/60    Loss: 2.987063666343689\n",
      "\n",
      "Epoch:   43/60    Loss: 3.0266947734355925\n",
      "\n",
      "Epoch:   43/60    Loss: 2.946428050041199\n",
      "\n",
      "Epoch:   43/60    Loss: 2.9363732914924623\n",
      "\n",
      "Epoch:   43/60    Loss: 2.9498360884189605\n",
      "\n",
      "Epoch:   43/60    Loss: 3.0379798431396483\n",
      "\n",
      "Epoch:   43/60    Loss: 3.1003151862621308\n",
      "\n",
      "Epoch:   43/60    Loss: 3.037814037322998\n",
      "\n",
      "Epoch:   43/60    Loss: 3.0850671153068543\n",
      "\n",
      "Epoch:   43/60    Loss: 3.1214787628650664\n",
      "\n",
      "Epoch:   43/60    Loss: 3.0000205056667326\n",
      "\n",
      "Epoch:   43/60    Loss: 3.056643347978592\n",
      "\n",
      "Epoch:   43/60    Loss: 3.1416377391815185\n",
      "\n",
      "Epoch:   43/60    Loss: 3.084012977361679\n",
      "\n",
      "Epoch:   43/60    Loss: 3.128134729385376\n",
      "\n",
      "Epoch:   43/60    Loss: 3.1732988739013672\n",
      "\n",
      "Epoch:   43/60    Loss: 3.174706595182419\n",
      "\n",
      "Epoch:   43/60    Loss: 3.0619075965881346\n",
      "\n",
      "Epoch:   43/60    Loss: 3.0975652322769167\n",
      "\n",
      "Epoch:   43/60    Loss: 3.047823598861694\n",
      "\n",
      "Epoch:   43/60    Loss: 3.0527428700923918\n",
      "\n",
      "Epoch:   43/60    Loss: 3.038299885034561\n",
      "\n",
      "Epoch:   44/60    Loss: 3.1057871965610464\n",
      "\n",
      "Epoch:   44/60    Loss: 3.1175356798171996\n",
      "\n",
      "Epoch:   44/60    Loss: 3.0338140335083006\n",
      "\n",
      "Epoch:   44/60    Loss: 3.050504264354706\n",
      "\n",
      "Epoch:   44/60    Loss: 3.015196985244751\n",
      "\n",
      "Epoch:   44/60    Loss: 3.103215345621109\n",
      "\n",
      "Epoch:   44/60    Loss: 3.145182144165039\n",
      "\n",
      "Epoch:   44/60    Loss: 3.017931983232498\n",
      "\n",
      "Epoch:   44/60    Loss: 2.910377662420273\n",
      "\n",
      "Epoch:   44/60    Loss: 3.0890840301513673\n",
      "\n",
      "Epoch:   44/60    Loss: 3.030639253139496\n",
      "\n",
      "Epoch:   44/60    Loss: 3.0088644890785217\n",
      "\n",
      "Epoch:   44/60    Loss: 2.959332175016403\n",
      "\n",
      "Epoch:   44/60    Loss: 2.9415709199905398\n",
      "\n",
      "Epoch:   44/60    Loss: 2.911150344133377\n",
      "\n",
      "Epoch:   44/60    Loss: 2.9494465682506563\n",
      "\n",
      "Epoch:   44/60    Loss: 2.950033944606781\n",
      "\n",
      "Epoch:   44/60    Loss: 3.002642254114151\n",
      "\n",
      "Epoch:   44/60    Loss: 2.9393729462623597\n",
      "\n",
      "Epoch:   44/60    Loss: 2.859626454591751\n",
      "\n",
      "Epoch:   44/60    Loss: 3.002092875242233\n",
      "\n",
      "Epoch:   44/60    Loss: 2.9063120617866516\n",
      "\n",
      "Epoch:   44/60    Loss: 3.0796995782852172\n",
      "\n",
      "Epoch:   44/60    Loss: 3.0132444450855256\n",
      "\n",
      "Epoch:   44/60    Loss: 3.150618716478348\n",
      "\n",
      "Epoch:   44/60    Loss: 3.0920152773857117\n",
      "\n",
      "Epoch:   44/60    Loss: 3.031526552438736\n",
      "\n",
      "Epoch:   44/60    Loss: 3.1133728475570677\n",
      "\n",
      "Epoch:   44/60    Loss: 3.0479983882904054\n",
      "\n",
      "Epoch:   44/60    Loss: 2.9737456340789796\n",
      "\n",
      "Epoch:   44/60    Loss: 2.853150385379791\n",
      "\n",
      "Epoch:   44/60    Loss: 3.0482267425060274\n",
      "\n",
      "Epoch:   44/60    Loss: 2.967641756057739\n",
      "\n",
      "Epoch:   44/60    Loss: 2.8796323933601378\n",
      "\n",
      "Epoch:   44/60    Loss: 2.869545225262642\n",
      "\n",
      "Epoch:   44/60    Loss: 3.001022027730942\n",
      "\n",
      "Epoch:   44/60    Loss: 2.948321983098984\n",
      "\n",
      "Epoch:   44/60    Loss: 2.9591350131034853\n",
      "\n",
      "Epoch:   44/60    Loss: 3.010930519104004\n",
      "\n",
      "Epoch:   44/60    Loss: 2.947244173526764\n",
      "\n",
      "Epoch:   44/60    Loss: 2.9340159480571746\n",
      "\n",
      "Epoch:   44/60    Loss: 2.9769789826869966\n",
      "\n",
      "Epoch:   44/60    Loss: 3.0205305223464967\n",
      "\n",
      "Epoch:   44/60    Loss: 3.121595125436783\n",
      "\n",
      "Epoch:   44/60    Loss: 3.018134928703308\n",
      "\n",
      "Epoch:   44/60    Loss: 3.0962358458042143\n",
      "\n",
      "Epoch:   44/60    Loss: 3.1218710577487947\n",
      "\n",
      "Epoch:   44/60    Loss: 3.024410885334015\n",
      "\n",
      "Epoch:   44/60    Loss: 3.081345404148102\n",
      "\n",
      "Epoch:   44/60    Loss: 3.136372030735016\n",
      "\n",
      "Epoch:   44/60    Loss: 3.1000461423397065\n",
      "\n",
      "Epoch:   44/60    Loss: 3.1218565871715547\n",
      "\n",
      "Epoch:   44/60    Loss: 3.142817758560181\n",
      "\n",
      "Epoch:   44/60    Loss: 3.1663548185825348\n",
      "\n",
      "Epoch:   44/60    Loss: 3.086637711763382\n",
      "\n",
      "Epoch:   44/60    Loss: 3.152047376871109\n",
      "\n",
      "Epoch:   44/60    Loss: 3.077839470624924\n",
      "\n",
      "Epoch:   44/60    Loss: 3.0717997167110442\n",
      "\n",
      "Epoch:   44/60    Loss: 3.048148946046829\n",
      "\n",
      "Epoch:   45/60    Loss: 3.096145106236572\n",
      "\n",
      "Epoch:   45/60    Loss: 3.117184024333954\n",
      "\n",
      "Epoch:   45/60    Loss: 3.026113163471222\n",
      "\n",
      "Epoch:   45/60    Loss: 3.048919434070587\n",
      "\n",
      "Epoch:   45/60    Loss: 2.992741417884827\n",
      "\n",
      "Epoch:   45/60    Loss: 3.0947959408760073\n",
      "\n",
      "Epoch:   45/60    Loss: 3.109008890628815\n",
      "\n",
      "Epoch:   45/60    Loss: 3.0152339799404144\n",
      "\n",
      "Epoch:   45/60    Loss: 2.9140649747848513\n",
      "\n",
      "Epoch:   45/60    Loss: 3.0742836170196535\n",
      "\n",
      "Epoch:   45/60    Loss: 3.0242112703323363\n",
      "\n",
      "Epoch:   45/60    Loss: 3.004214734554291\n",
      "\n",
      "Epoch:   45/60    Loss: 2.9563051991462705\n",
      "\n",
      "Epoch:   45/60    Loss: 2.951890959262848\n",
      "\n",
      "Epoch:   45/60    Loss: 2.9096975111961365\n",
      "\n",
      "Epoch:   45/60    Loss: 2.923230703353882\n",
      "\n",
      "Epoch:   45/60    Loss: 2.9575631000995637\n",
      "\n",
      "Epoch:   45/60    Loss: 3.0021615102291106\n",
      "\n",
      "Epoch:   45/60    Loss: 2.9308499546051023\n",
      "\n",
      "Epoch:   45/60    Loss: 2.863070547580719\n",
      "\n",
      "Epoch:   45/60    Loss: 2.995648373603821\n",
      "\n",
      "Epoch:   45/60    Loss: 2.8993592348098756\n",
      "\n",
      "Epoch:   45/60    Loss: 3.0641955029964447\n",
      "\n",
      "Epoch:   45/60    Loss: 3.0131485736370087\n",
      "\n",
      "Epoch:   45/60    Loss: 3.1330907990932464\n",
      "\n",
      "Epoch:   45/60    Loss: 3.08722270154953\n",
      "\n",
      "Epoch:   45/60    Loss: 3.03753826379776\n",
      "\n",
      "Epoch:   45/60    Loss: 3.0896341059207915\n",
      "\n",
      "Epoch:   45/60    Loss: 3.039579493045807\n",
      "\n",
      "Epoch:   45/60    Loss: 2.9580710937976837\n",
      "\n",
      "Epoch:   45/60    Loss: 2.8592309663295747\n",
      "\n",
      "Epoch:   45/60    Loss: 3.0103370485305785\n",
      "\n",
      "Epoch:   45/60    Loss: 2.972384529352188\n",
      "\n",
      "Epoch:   45/60    Loss: 2.9228383400440214\n",
      "\n",
      "Epoch:   45/60    Loss: 2.8722664778232576\n",
      "\n",
      "Epoch:   45/60    Loss: 2.9962532968521116\n",
      "\n",
      "Epoch:   45/60    Loss: 2.939050582408905\n",
      "\n",
      "Epoch:   45/60    Loss: 2.950337362289429\n",
      "\n",
      "Epoch:   45/60    Loss: 3.008650138616562\n",
      "\n",
      "Epoch:   45/60    Loss: 2.9369109725952147\n",
      "\n",
      "Epoch:   45/60    Loss: 2.930461907148361\n",
      "\n",
      "Epoch:   45/60    Loss: 2.9640975024700165\n",
      "\n",
      "Epoch:   45/60    Loss: 3.007123285770416\n",
      "\n",
      "Epoch:   45/60    Loss: 3.0964926657676695\n",
      "\n",
      "Epoch:   45/60    Loss: 2.9979764337539674\n",
      "\n",
      "Epoch:   45/60    Loss: 3.088160542011261\n",
      "\n",
      "Epoch:   45/60    Loss: 3.106951784849167\n",
      "\n",
      "Epoch:   45/60    Loss: 3.015046206712723\n",
      "\n",
      "Epoch:   45/60    Loss: 3.0580741403102873\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   45/60    Loss: 3.138214866399765\n",
      "\n",
      "Epoch:   45/60    Loss: 3.113639970779419\n",
      "\n",
      "Epoch:   45/60    Loss: 3.1191043486595156\n",
      "\n",
      "Epoch:   45/60    Loss: 3.1322926981449126\n",
      "\n",
      "Epoch:   45/60    Loss: 3.158511768102646\n",
      "\n",
      "Epoch:   45/60    Loss: 3.092940051794052\n",
      "\n",
      "Epoch:   45/60    Loss: 3.147403843641281\n",
      "\n",
      "Epoch:   45/60    Loss: 3.051437216758728\n",
      "\n",
      "Epoch:   45/60    Loss: 3.063143036365509\n",
      "\n",
      "Epoch:   45/60    Loss: 3.0337309668064116\n",
      "\n",
      "Epoch:   46/60    Loss: 3.0976372879484426\n",
      "\n",
      "Epoch:   46/60    Loss: 3.110047564983368\n",
      "\n",
      "Epoch:   46/60    Loss: 3.032273302078247\n",
      "\n",
      "Epoch:   46/60    Loss: 3.053340095043182\n",
      "\n",
      "Epoch:   46/60    Loss: 2.9990861237049105\n",
      "\n",
      "Epoch:   46/60    Loss: 3.093832799434662\n",
      "\n",
      "Epoch:   46/60    Loss: 3.0983972034454346\n",
      "\n",
      "Epoch:   46/60    Loss: 3.0014361157417295\n",
      "\n",
      "Epoch:   46/60    Loss: 2.895834550857544\n",
      "\n",
      "Epoch:   46/60    Loss: 3.063236252784729\n",
      "\n",
      "Epoch:   46/60    Loss: 3.008116314411163\n",
      "\n",
      "Epoch:   46/60    Loss: 3.002519870519638\n",
      "\n",
      "Epoch:   46/60    Loss: 2.931067692995071\n",
      "\n",
      "Epoch:   46/60    Loss: 2.9414340682029723\n",
      "\n",
      "Epoch:   46/60    Loss: 2.9124692249298096\n",
      "\n",
      "Epoch:   46/60    Loss: 2.9470260190963744\n",
      "\n",
      "Epoch:   46/60    Loss: 2.965022222518921\n",
      "\n",
      "Epoch:   46/60    Loss: 2.988706797838211\n",
      "\n",
      "Epoch:   46/60    Loss: 2.947237141370773\n",
      "\n",
      "Epoch:   46/60    Loss: 2.865762429237366\n",
      "\n",
      "Epoch:   46/60    Loss: 2.9860402228832243\n",
      "\n",
      "Epoch:   46/60    Loss: 2.90588667011261\n",
      "\n",
      "Epoch:   46/60    Loss: 3.059682575941086\n",
      "\n",
      "Epoch:   46/60    Loss: 3.0241614813804625\n",
      "\n",
      "Epoch:   46/60    Loss: 3.1351639831066134\n",
      "\n",
      "Epoch:   46/60    Loss: 3.0844789712429046\n",
      "\n",
      "Epoch:   46/60    Loss: 3.0185905051231385\n",
      "\n",
      "Epoch:   46/60    Loss: 3.1148258240222932\n",
      "\n",
      "Epoch:   46/60    Loss: 3.041685434818268\n",
      "\n",
      "Epoch:   46/60    Loss: 2.9692048134803772\n",
      "\n",
      "Epoch:   46/60    Loss: 2.8650081973075867\n",
      "\n",
      "Epoch:   46/60    Loss: 3.01297505068779\n",
      "\n",
      "Epoch:   46/60    Loss: 2.979734571456909\n",
      "\n",
      "Epoch:   46/60    Loss: 2.888355106830597\n",
      "\n",
      "Epoch:   46/60    Loss: 2.881117057442665\n",
      "\n",
      "Epoch:   46/60    Loss: 2.9971380496025084\n",
      "\n",
      "Epoch:   46/60    Loss: 2.9374815347194674\n",
      "\n",
      "Epoch:   46/60    Loss: 2.9692651193141937\n",
      "\n",
      "Epoch:   46/60    Loss: 3.0108868761062624\n",
      "\n",
      "Epoch:   46/60    Loss: 2.9296825635433197\n",
      "\n",
      "Epoch:   46/60    Loss: 2.949569267034531\n",
      "\n",
      "Epoch:   46/60    Loss: 2.9574543783664704\n",
      "\n",
      "Epoch:   46/60    Loss: 3.020563673019409\n",
      "\n",
      "Epoch:   46/60    Loss: 3.097684848308563\n",
      "\n",
      "Epoch:   46/60    Loss: 2.9947271721363067\n",
      "\n",
      "Epoch:   46/60    Loss: 3.0907340133190155\n",
      "\n",
      "Epoch:   46/60    Loss: 3.103367785453796\n",
      "\n",
      "Epoch:   46/60    Loss: 3.016656225681305\n",
      "\n",
      "Epoch:   46/60    Loss: 3.054153949022293\n",
      "\n",
      "Epoch:   46/60    Loss: 3.1226656782627105\n",
      "\n",
      "Epoch:   46/60    Loss: 3.078036957502365\n",
      "\n",
      "Epoch:   46/60    Loss: 3.124737919330597\n",
      "\n",
      "Epoch:   46/60    Loss: 3.131183156132698\n",
      "\n",
      "Epoch:   46/60    Loss: 3.176480851173401\n",
      "\n",
      "Epoch:   46/60    Loss: 3.0664112498760225\n",
      "\n",
      "Epoch:   46/60    Loss: 3.1156598417758943\n",
      "\n",
      "Epoch:   46/60    Loss: 3.0571302139759062\n",
      "\n",
      "Epoch:   46/60    Loss: 3.0493595592975615\n",
      "\n",
      "Epoch:   46/60    Loss: 3.0304821765422822\n",
      "\n",
      "Epoch:   47/60    Loss: 3.086216467878093\n",
      "\n",
      "Epoch:   47/60    Loss: 3.1069427399635314\n",
      "\n",
      "Epoch:   47/60    Loss: 3.0337973246574403\n",
      "\n",
      "Epoch:   47/60    Loss: 3.0624477746486662\n",
      "\n",
      "Epoch:   47/60    Loss: 3.005125830888748\n",
      "\n",
      "Epoch:   47/60    Loss: 3.101511426925659\n",
      "\n",
      "Epoch:   47/60    Loss: 3.1103211760520937\n",
      "\n",
      "Epoch:   47/60    Loss: 3.007653996229172\n",
      "\n",
      "Epoch:   47/60    Loss: 2.9066615147590635\n",
      "\n",
      "Epoch:   47/60    Loss: 3.067049268960953\n",
      "\n",
      "Epoch:   47/60    Loss: 3.003788236141205\n",
      "\n",
      "Epoch:   47/60    Loss: 2.9968197603225706\n",
      "\n",
      "Epoch:   47/60    Loss: 2.950217666864395\n",
      "\n",
      "Epoch:   47/60    Loss: 2.9441307888031005\n",
      "\n",
      "Epoch:   47/60    Loss: 2.886631462097168\n",
      "\n",
      "Epoch:   47/60    Loss: 2.9580254983901977\n",
      "\n",
      "Epoch:   47/60    Loss: 2.9496497304439546\n",
      "\n",
      "Epoch:   47/60    Loss: 3.005276326417923\n",
      "\n",
      "Epoch:   47/60    Loss: 2.9347076025009153\n",
      "\n",
      "Epoch:   47/60    Loss: 2.858466131210327\n",
      "\n",
      "Epoch:   47/60    Loss: 2.998891371011734\n",
      "\n",
      "Epoch:   47/60    Loss: 2.9171423506736756\n",
      "\n",
      "Epoch:   47/60    Loss: 3.063275590181351\n",
      "\n",
      "Epoch:   47/60    Loss: 3.0317487888336183\n",
      "\n",
      "Epoch:   47/60    Loss: 3.1481201915740966\n",
      "\n",
      "Epoch:   47/60    Loss: 3.0931300354003906\n",
      "\n",
      "Epoch:   47/60    Loss: 3.042589370727539\n",
      "\n",
      "Epoch:   47/60    Loss: 3.1124799530506135\n",
      "\n",
      "Epoch:   47/60    Loss: 3.0481827301979063\n",
      "\n",
      "Epoch:   47/60    Loss: 2.9800547180175783\n",
      "\n",
      "Epoch:   47/60    Loss: 2.8600639281272886\n",
      "\n",
      "Epoch:   47/60    Loss: 3.0223714332580567\n",
      "\n",
      "Epoch:   47/60    Loss: 2.9774523451328276\n",
      "\n",
      "Epoch:   47/60    Loss: 2.883713107585907\n",
      "\n",
      "Epoch:   47/60    Loss: 2.8886713383197784\n",
      "\n",
      "Epoch:   47/60    Loss: 3.006787141084671\n",
      "\n",
      "Epoch:   47/60    Loss: 2.9375072431564333\n",
      "\n",
      "Epoch:   47/60    Loss: 2.977167944908142\n",
      "\n",
      "Epoch:   47/60    Loss: 2.997740655660629\n",
      "\n",
      "Epoch:   47/60    Loss: 2.9333864810466768\n",
      "\n",
      "Epoch:   47/60    Loss: 2.937172237634659\n",
      "\n",
      "Epoch:   47/60    Loss: 2.946501904249191\n",
      "\n",
      "Epoch:   47/60    Loss: 3.0056193096637727\n",
      "\n",
      "Epoch:   47/60    Loss: 3.106282942056656\n",
      "\n",
      "Epoch:   47/60    Loss: 3.0042909655570984\n",
      "\n",
      "Epoch:   47/60    Loss: 3.077782829284668\n",
      "\n",
      "Epoch:   47/60    Loss: 3.086987367391586\n",
      "\n",
      "Epoch:   47/60    Loss: 3.016266874074936\n",
      "\n",
      "Epoch:   47/60    Loss: 3.039120304584503\n",
      "\n",
      "Epoch:   47/60    Loss: 3.1126444849967956\n",
      "\n",
      "Epoch:   47/60    Loss: 3.0811812076568605\n",
      "\n",
      "Epoch:   47/60    Loss: 3.1203634719848634\n",
      "\n",
      "Epoch:   47/60    Loss: 3.1192327497005463\n",
      "\n",
      "Epoch:   47/60    Loss: 3.1476015651226046\n",
      "\n",
      "Epoch:   47/60    Loss: 3.0632222638130187\n",
      "\n",
      "Epoch:   47/60    Loss: 3.097335669517517\n",
      "\n",
      "Epoch:   47/60    Loss: 3.047910796880722\n",
      "\n",
      "Epoch:   47/60    Loss: 3.0263735632896425\n",
      "\n",
      "Epoch:   47/60    Loss: 3.0292762644290923\n",
      "\n",
      "Epoch:   48/60    Loss: 3.0849865003610435\n",
      "\n",
      "Epoch:   48/60    Loss: 3.1018317778110505\n",
      "\n",
      "Epoch:   48/60    Loss: 3.042961688041687\n",
      "\n",
      "Epoch:   48/60    Loss: 3.063106123924255\n",
      "\n",
      "Epoch:   48/60    Loss: 3.002747392654419\n",
      "\n",
      "Epoch:   48/60    Loss: 3.0731441850662233\n",
      "\n",
      "Epoch:   48/60    Loss: 3.097103804588318\n",
      "\n",
      "Epoch:   48/60    Loss: 2.9860553121566773\n",
      "\n",
      "Epoch:   48/60    Loss: 2.903356143474579\n",
      "\n",
      "Epoch:   48/60    Loss: 3.0644680700302125\n",
      "\n",
      "Epoch:   48/60    Loss: 3.0039691903591157\n",
      "\n",
      "Epoch:   48/60    Loss: 2.9913999338150026\n",
      "\n",
      "Epoch:   48/60    Loss: 2.9440281121730805\n",
      "\n",
      "Epoch:   48/60    Loss: 2.940204051017761\n",
      "\n",
      "Epoch:   48/60    Loss: 2.894203959941864\n",
      "\n",
      "Epoch:   48/60    Loss: 2.9327537639141084\n",
      "\n",
      "Epoch:   48/60    Loss: 2.953297787427902\n",
      "\n",
      "Epoch:   48/60    Loss: 2.996680649995804\n",
      "\n",
      "Epoch:   48/60    Loss: 2.9318720417022703\n",
      "\n",
      "Epoch:   48/60    Loss: 2.8591598246097565\n",
      "\n",
      "Epoch:   48/60    Loss: 2.9931799845695495\n",
      "\n",
      "Epoch:   48/60    Loss: 2.9099164085388183\n",
      "\n",
      "Epoch:   48/60    Loss: 3.0639079792499544\n",
      "\n",
      "Epoch:   48/60    Loss: 3.0140649843215943\n",
      "\n",
      "Epoch:   48/60    Loss: 3.1117189733982085\n",
      "\n",
      "Epoch:   48/60    Loss: 3.0810452206134795\n",
      "\n",
      "Epoch:   48/60    Loss: 3.010371458768845\n",
      "\n",
      "Epoch:   48/60    Loss: 3.0653964443206787\n",
      "\n",
      "Epoch:   48/60    Loss: 3.026694645166397\n",
      "\n",
      "Epoch:   48/60    Loss: 2.9693665103912354\n",
      "\n",
      "Epoch:   48/60    Loss: 2.8377054188251494\n",
      "\n",
      "Epoch:   48/60    Loss: 3.010176119327545\n",
      "\n",
      "Epoch:   48/60    Loss: 2.9801430628299714\n",
      "\n",
      "Epoch:   48/60    Loss: 2.8851949994564055\n",
      "\n",
      "Epoch:   48/60    Loss: 2.8727548274993895\n",
      "\n",
      "Epoch:   48/60    Loss: 2.9952844116687776\n",
      "\n",
      "Epoch:   48/60    Loss: 2.9247602264881136\n",
      "\n",
      "Epoch:   48/60    Loss: 2.974836740732193\n",
      "\n",
      "Epoch:   48/60    Loss: 2.9898908233642576\n",
      "\n",
      "Epoch:   48/60    Loss: 2.917654103279114\n",
      "\n",
      "Epoch:   48/60    Loss: 2.927294830560684\n",
      "\n",
      "Epoch:   48/60    Loss: 2.9491155841350554\n",
      "\n",
      "Epoch:   48/60    Loss: 3.009120227098465\n",
      "\n",
      "Epoch:   48/60    Loss: 3.0884748239517212\n",
      "\n",
      "Epoch:   48/60    Loss: 2.9949560270309448\n",
      "\n",
      "Epoch:   48/60    Loss: 3.0671943466663363\n",
      "\n",
      "Epoch:   48/60    Loss: 3.0904375865459444\n",
      "\n",
      "Epoch:   48/60    Loss: 3.005414951086044\n",
      "\n",
      "Epoch:   48/60    Loss: 3.0370432374477385\n",
      "\n",
      "Epoch:   48/60    Loss: 3.102999111413956\n",
      "\n",
      "Epoch:   48/60    Loss: 3.078783193588257\n",
      "\n",
      "Epoch:   48/60    Loss: 3.1153530972003938\n",
      "\n",
      "Epoch:   48/60    Loss: 3.115285287499428\n",
      "\n",
      "Epoch:   48/60    Loss: 3.1353337178230287\n",
      "\n",
      "Epoch:   48/60    Loss: 3.0681954922676087\n",
      "\n",
      "Epoch:   48/60    Loss: 3.1069755177497864\n",
      "\n",
      "Epoch:   48/60    Loss: 3.049838349103928\n",
      "\n",
      "Epoch:   48/60    Loss: 3.0469242560863496\n",
      "\n",
      "Epoch:   48/60    Loss: 3.026157600879669\n",
      "\n",
      "Epoch:   49/60    Loss: 3.0800397145035476\n",
      "\n",
      "Epoch:   49/60    Loss: 3.0836811571121214\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   49/60    Loss: 3.019122073173523\n",
      "\n",
      "Epoch:   49/60    Loss: 3.0437518105506896\n",
      "\n",
      "Epoch:   49/60    Loss: 2.991272403240204\n",
      "\n",
      "Epoch:   49/60    Loss: 3.088693995475769\n",
      "\n",
      "Epoch:   49/60    Loss: 3.0891170752048493\n",
      "\n",
      "Epoch:   49/60    Loss: 2.999826104640961\n",
      "\n",
      "Epoch:   49/60    Loss: 2.900358872652054\n",
      "\n",
      "Epoch:   49/60    Loss: 3.081073584318161\n",
      "\n",
      "Epoch:   49/60    Loss: 3.0098414347171785\n",
      "\n",
      "Epoch:   49/60    Loss: 2.99009863615036\n",
      "\n",
      "Epoch:   49/60    Loss: 2.9393506503105162\n",
      "\n",
      "Epoch:   49/60    Loss: 2.9425090942382814\n",
      "\n",
      "Epoch:   49/60    Loss: 2.8990601954460145\n",
      "\n",
      "Epoch:   49/60    Loss: 2.932772700548172\n",
      "\n",
      "Epoch:   49/60    Loss: 2.9487368531227114\n",
      "\n",
      "Epoch:   49/60    Loss: 3.0011843755245207\n",
      "\n",
      "Epoch:   49/60    Loss: 2.9225366299152373\n",
      "\n",
      "Epoch:   49/60    Loss: 2.8649790987968444\n",
      "\n",
      "Epoch:   49/60    Loss: 2.989877316236496\n",
      "\n",
      "Epoch:   49/60    Loss: 2.913241027832031\n",
      "\n",
      "Epoch:   49/60    Loss: 3.0553090274333954\n",
      "\n",
      "Epoch:   49/60    Loss: 3.0039348700046538\n",
      "\n",
      "Epoch:   49/60    Loss: 3.108970588207245\n",
      "\n",
      "Epoch:   49/60    Loss: 3.0879432039260863\n",
      "\n",
      "Epoch:   49/60    Loss: 3.018503621816635\n",
      "\n",
      "Epoch:   49/60    Loss: 3.071346702337265\n",
      "\n",
      "Epoch:   49/60    Loss: 3.0297627956867217\n",
      "\n",
      "Epoch:   49/60    Loss: 2.9620844252109526\n",
      "\n",
      "Epoch:   49/60    Loss: 2.8478054993152617\n",
      "\n",
      "Epoch:   49/60    Loss: 3.0155974340438845\n",
      "\n",
      "Epoch:   49/60    Loss: 2.9705784947872163\n",
      "\n",
      "Epoch:   49/60    Loss: 2.870784148931503\n",
      "\n",
      "Epoch:   49/60    Loss: 2.8496800854206086\n",
      "\n",
      "Epoch:   49/60    Loss: 2.9871755051612854\n",
      "\n",
      "Epoch:   49/60    Loss: 2.910436533689499\n",
      "\n",
      "Epoch:   49/60    Loss: 2.9649738726615906\n",
      "\n",
      "Epoch:   49/60    Loss: 2.992098108768463\n",
      "\n",
      "Epoch:   49/60    Loss: 2.902198829650879\n",
      "\n",
      "Epoch:   49/60    Loss: 2.9271729214191438\n",
      "\n",
      "Epoch:   49/60    Loss: 2.949398866891861\n",
      "\n",
      "Epoch:   49/60    Loss: 2.9971057121753693\n",
      "\n",
      "Epoch:   49/60    Loss: 3.08716539311409\n",
      "\n",
      "Epoch:   49/60    Loss: 2.9728712980747223\n",
      "\n",
      "Epoch:   49/60    Loss: 3.05896693444252\n",
      "\n",
      "Epoch:   49/60    Loss: 3.0711623201370237\n",
      "\n",
      "Epoch:   49/60    Loss: 2.993757415294647\n",
      "\n",
      "Epoch:   49/60    Loss: 3.0194747681617735\n",
      "\n",
      "Epoch:   49/60    Loss: 3.105437849283218\n",
      "\n",
      "Epoch:   49/60    Loss: 3.0554436209201814\n",
      "\n",
      "Epoch:   49/60    Loss: 3.095263400554657\n",
      "\n",
      "Epoch:   49/60    Loss: 3.0942877244949343\n",
      "\n",
      "Epoch:   49/60    Loss: 3.1009848127365114\n",
      "\n",
      "Epoch:   49/60    Loss: 3.0567599432468415\n",
      "\n",
      "Epoch:   49/60    Loss: 3.0640114924907684\n",
      "\n",
      "Epoch:   49/60    Loss: 3.0130142250061036\n",
      "\n",
      "Epoch:   49/60    Loss: 3.0064301960468294\n",
      "\n",
      "Epoch:   49/60    Loss: 2.981265371084213\n",
      "\n",
      "Epoch:   50/60    Loss: 3.0613568416270227\n",
      "\n",
      "Epoch:   50/60    Loss: 3.071657246351242\n",
      "\n",
      "Epoch:   50/60    Loss: 3.0024305205345154\n",
      "\n",
      "Epoch:   50/60    Loss: 3.0459081122875213\n",
      "\n",
      "Epoch:   50/60    Loss: 2.9822627065181733\n",
      "\n",
      "Epoch:   50/60    Loss: 3.0612265453338625\n",
      "\n",
      "Epoch:   50/60    Loss: 3.0843437352180483\n",
      "\n",
      "Epoch:   50/60    Loss: 2.975562352180481\n",
      "\n",
      "Epoch:   50/60    Loss: 2.8786121568679808\n",
      "\n",
      "Epoch:   50/60    Loss: 3.047159935474396\n",
      "\n",
      "Epoch:   50/60    Loss: 2.9935846462249756\n",
      "\n",
      "Epoch:   50/60    Loss: 2.9705122718811037\n",
      "\n",
      "Epoch:   50/60    Loss: 2.9167635247707366\n",
      "\n",
      "Epoch:   50/60    Loss: 2.925040512561798\n",
      "\n",
      "Epoch:   50/60    Loss: 2.8768383402824402\n",
      "\n",
      "Epoch:   50/60    Loss: 2.8970713448524474\n",
      "\n",
      "Epoch:   50/60    Loss: 2.910839380979538\n",
      "\n",
      "Epoch:   50/60    Loss: 2.97347486948967\n",
      "\n",
      "Epoch:   50/60    Loss: 2.8967274746894836\n",
      "\n",
      "Epoch:   50/60    Loss: 2.8394748191833497\n",
      "\n",
      "Epoch:   50/60    Loss: 2.9679217665195465\n",
      "\n",
      "Epoch:   50/60    Loss: 2.907258535861969\n",
      "\n",
      "Epoch:   50/60    Loss: 3.05255255818367\n",
      "\n",
      "Epoch:   50/60    Loss: 2.9735028088092803\n",
      "\n",
      "Epoch:   50/60    Loss: 3.0890113904476166\n",
      "\n",
      "Epoch:   50/60    Loss: 3.0722603290081025\n",
      "\n",
      "Epoch:   50/60    Loss: 3.0180531022548673\n",
      "\n",
      "Epoch:   50/60    Loss: 3.0613181090354917\n",
      "\n",
      "Epoch:   50/60    Loss: 3.0275284328460694\n",
      "\n",
      "Epoch:   50/60    Loss: 2.9364496760368346\n",
      "\n",
      "Epoch:   50/60    Loss: 2.8322240874767304\n",
      "\n",
      "Epoch:   50/60    Loss: 3.0282137265205384\n",
      "\n",
      "Epoch:   50/60    Loss: 2.974846268415451\n",
      "\n",
      "Epoch:   50/60    Loss: 2.878977446556091\n",
      "\n",
      "Epoch:   50/60    Loss: 2.8708135725259782\n",
      "\n",
      "Epoch:   50/60    Loss: 2.971199601650238\n",
      "\n",
      "Epoch:   50/60    Loss: 2.9030075426101685\n",
      "\n",
      "Epoch:   50/60    Loss: 2.9520105941295625\n",
      "\n",
      "Epoch:   50/60    Loss: 2.98646621799469\n",
      "\n",
      "Epoch:   50/60    Loss: 2.894718611717224\n",
      "\n",
      "Epoch:   50/60    Loss: 2.9284240565299986\n",
      "\n",
      "Epoch:   50/60    Loss: 2.947987493991852\n",
      "\n",
      "Epoch:   50/60    Loss: 2.9915312254428863\n",
      "\n",
      "Epoch:   50/60    Loss: 3.073798157930374\n",
      "\n",
      "Epoch:   50/60    Loss: 2.9799598290920257\n",
      "\n",
      "Epoch:   50/60    Loss: 3.0665150318145753\n",
      "\n",
      "Epoch:   50/60    Loss: 3.0567766189575196\n",
      "\n",
      "Epoch:   50/60    Loss: 2.992167160987854\n",
      "\n",
      "Epoch:   50/60    Loss: 3.0096910388469698\n",
      "\n",
      "Epoch:   50/60    Loss: 3.1275985288619994\n",
      "\n",
      "Epoch:   50/60    Loss: 3.0632794866561888\n",
      "\n",
      "Epoch:   50/60    Loss: 3.0875400490760803\n",
      "\n",
      "Epoch:   50/60    Loss: 3.089534109354019\n",
      "\n",
      "Epoch:   50/60    Loss: 3.1106541419029234\n",
      "\n",
      "Epoch:   50/60    Loss: 3.054996931552887\n",
      "\n",
      "Epoch:   50/60    Loss: 3.056796977043152\n",
      "\n",
      "Epoch:   50/60    Loss: 3.028136667013168\n",
      "\n",
      "Epoch:   50/60    Loss: 3.018318776845932\n",
      "\n",
      "Epoch:   50/60    Loss: 2.9934408338069916\n",
      "\n",
      "Epoch:   51/60    Loss: 3.054399254853311\n",
      "\n",
      "Epoch:   51/60    Loss: 3.0810298993587493\n",
      "\n",
      "Epoch:   51/60    Loss: 3.0060585012435914\n",
      "\n",
      "Epoch:   51/60    Loss: 3.022301633834839\n",
      "\n",
      "Epoch:   51/60    Loss: 2.980330480337143\n",
      "\n",
      "Epoch:   51/60    Loss: 3.057424148321152\n",
      "\n",
      "Epoch:   51/60    Loss: 3.075183735370636\n",
      "\n",
      "Epoch:   51/60    Loss: 2.9870274760723112\n",
      "\n",
      "Epoch:   51/60    Loss: 2.882827315568924\n",
      "\n",
      "Epoch:   51/60    Loss: 3.064393669128418\n",
      "\n",
      "Epoch:   51/60    Loss: 2.977226418018341\n",
      "\n",
      "Epoch:   51/60    Loss: 2.977231836795807\n",
      "\n",
      "Epoch:   51/60    Loss: 2.9177310099601748\n",
      "\n",
      "Epoch:   51/60    Loss: 2.9210846781730653\n",
      "\n",
      "Epoch:   51/60    Loss: 2.877005383491516\n",
      "\n",
      "Epoch:   51/60    Loss: 2.899774928569794\n",
      "\n",
      "Epoch:   51/60    Loss: 2.9229600133895874\n",
      "\n",
      "Epoch:   51/60    Loss: 2.9975520486831666\n",
      "\n",
      "Epoch:   51/60    Loss: 2.912836739063263\n",
      "\n",
      "Epoch:   51/60    Loss: 2.84456818652153\n",
      "\n",
      "Epoch:   51/60    Loss: 2.9639290523529054\n",
      "\n",
      "Epoch:   51/60    Loss: 2.917105629205704\n",
      "\n",
      "Epoch:   51/60    Loss: 3.114727685689926\n",
      "\n",
      "Epoch:   51/60    Loss: 2.9980156664848328\n",
      "\n",
      "Epoch:   51/60    Loss: 3.100083258628845\n",
      "\n",
      "Epoch:   51/60    Loss: 3.0737390043735506\n",
      "\n",
      "Epoch:   51/60    Loss: 3.0204210300445555\n",
      "\n",
      "Epoch:   51/60    Loss: 3.053943338394165\n",
      "\n",
      "Epoch:   51/60    Loss: 3.004842661857605\n",
      "\n",
      "Epoch:   51/60    Loss: 2.9378234446048737\n",
      "\n",
      "Epoch:   51/60    Loss: 2.8309053342342376\n",
      "\n",
      "Epoch:   51/60    Loss: 3.033059121131897\n",
      "\n",
      "Epoch:   51/60    Loss: 2.9852282521724702\n",
      "\n",
      "Epoch:   51/60    Loss: 2.8845387070178985\n",
      "\n",
      "Epoch:   51/60    Loss: 2.8797512893676758\n",
      "\n",
      "Epoch:   51/60    Loss: 2.9767066411972047\n",
      "\n",
      "Epoch:   51/60    Loss: 2.9003634164333345\n",
      "\n",
      "Epoch:   51/60    Loss: 2.961876041650772\n",
      "\n",
      "Epoch:   51/60    Loss: 3.0050615510940553\n",
      "\n",
      "Epoch:   51/60    Loss: 2.901410232067108\n",
      "\n",
      "Epoch:   51/60    Loss: 2.924691110610962\n",
      "\n",
      "Epoch:   51/60    Loss: 2.9245167343616485\n",
      "\n",
      "Epoch:   51/60    Loss: 2.9768986485004425\n",
      "\n",
      "Epoch:   51/60    Loss: 3.091092780828476\n",
      "\n",
      "Epoch:   51/60    Loss: 2.986560703754425\n",
      "\n",
      "Epoch:   51/60    Loss: 3.0738426747322083\n",
      "\n",
      "Epoch:   51/60    Loss: 3.063547237634659\n",
      "\n",
      "Epoch:   51/60    Loss: 3.0026896553039553\n",
      "\n",
      "Epoch:   51/60    Loss: 3.0040248239040377\n",
      "\n",
      "Epoch:   51/60    Loss: 3.1120832161903382\n",
      "\n",
      "Epoch:   51/60    Loss: 3.050765271663666\n",
      "\n",
      "Epoch:   51/60    Loss: 3.0752094833850863\n",
      "\n",
      "Epoch:   51/60    Loss: 3.0971774789094924\n",
      "\n",
      "Epoch:   51/60    Loss: 3.0951415543556213\n",
      "\n",
      "Epoch:   51/60    Loss: 3.039756693840027\n",
      "\n",
      "Epoch:   51/60    Loss: 3.0682893633842467\n",
      "\n",
      "Epoch:   51/60    Loss: 3.026142585992813\n",
      "\n",
      "Epoch:   51/60    Loss: 3.019805272102356\n",
      "\n",
      "Epoch:   51/60    Loss: 2.9821710691452026\n",
      "\n",
      "Epoch:   52/60    Loss: 3.0466790170125337\n",
      "\n",
      "Epoch:   52/60    Loss: 3.0770574729442597\n",
      "\n",
      "Epoch:   52/60    Loss: 3.013322429418564\n",
      "\n",
      "Epoch:   52/60    Loss: 3.0250846581459045\n",
      "\n",
      "Epoch:   52/60    Loss: 2.971890931367874\n",
      "\n",
      "Epoch:   52/60    Loss: 3.069017068862915\n",
      "\n",
      "Epoch:   52/60    Loss: 3.0653288316726686\n",
      "\n",
      "Epoch:   52/60    Loss: 2.9740147907733916\n",
      "\n",
      "Epoch:   52/60    Loss: 2.8695229897499086\n",
      "\n",
      "Epoch:   52/60    Loss: 3.0666405193805693\n",
      "\n",
      "Epoch:   52/60    Loss: 2.970627545595169\n",
      "\n",
      "Epoch:   52/60    Loss: 2.9645105142593384\n",
      "\n",
      "Epoch:   52/60    Loss: 2.9124842274188993\n",
      "\n",
      "Epoch:   52/60    Loss: 2.921178946971893\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   52/60    Loss: 2.8773056118488314\n",
      "\n",
      "Epoch:   52/60    Loss: 2.888235698699951\n",
      "\n",
      "Epoch:   52/60    Loss: 2.9229613678455353\n",
      "\n",
      "Epoch:   52/60    Loss: 2.978849330186844\n",
      "\n",
      "Epoch:   52/60    Loss: 2.9101776342391967\n",
      "\n",
      "Epoch:   52/60    Loss: 2.8345661537647246\n",
      "\n",
      "Epoch:   52/60    Loss: 2.9668083910942076\n",
      "\n",
      "Epoch:   52/60    Loss: 2.9005878484249115\n",
      "\n",
      "Epoch:   52/60    Loss: 3.09209019780159\n",
      "\n",
      "Epoch:   52/60    Loss: 2.9908509542942046\n",
      "\n",
      "Epoch:   52/60    Loss: 3.102702036619186\n",
      "\n",
      "Epoch:   52/60    Loss: 3.062076731681824\n",
      "\n",
      "Epoch:   52/60    Loss: 2.996789535045624\n",
      "\n",
      "Epoch:   52/60    Loss: 3.037564143657684\n",
      "\n",
      "Epoch:   52/60    Loss: 3.0080623025894164\n",
      "\n",
      "Epoch:   52/60    Loss: 2.94582121348381\n",
      "\n",
      "Epoch:   52/60    Loss: 2.8164009456634522\n",
      "\n",
      "Epoch:   52/60    Loss: 3.0184047169685364\n",
      "\n",
      "Epoch:   52/60    Loss: 2.989757337331772\n",
      "\n",
      "Epoch:   52/60    Loss: 2.8729828157424926\n",
      "\n",
      "Epoch:   52/60    Loss: 2.8739992871284485\n",
      "\n",
      "Epoch:   52/60    Loss: 2.9778012998104098\n",
      "\n",
      "Epoch:   52/60    Loss: 2.8842021770477295\n",
      "\n",
      "Epoch:   52/60    Loss: 2.9548330194950103\n",
      "\n",
      "Epoch:   52/60    Loss: 2.9881372945308686\n",
      "\n",
      "Epoch:   52/60    Loss: 2.8868038947582244\n",
      "\n",
      "Epoch:   52/60    Loss: 2.908275580406189\n",
      "\n",
      "Epoch:   52/60    Loss: 2.9494276208877563\n",
      "\n",
      "Epoch:   52/60    Loss: 2.9765192828178404\n",
      "\n",
      "Epoch:   52/60    Loss: 3.079454936504364\n",
      "\n",
      "Epoch:   52/60    Loss: 2.9847560076713564\n",
      "\n",
      "Epoch:   52/60    Loss: 3.0776143281459807\n",
      "\n",
      "Epoch:   52/60    Loss: 3.052996375322342\n",
      "\n",
      "Epoch:   52/60    Loss: 3.003739317417145\n",
      "\n",
      "Epoch:   52/60    Loss: 3.0046169645786285\n",
      "\n",
      "Epoch:   52/60    Loss: 3.1161595783233644\n",
      "\n",
      "Epoch:   52/60    Loss: 3.0584751942157746\n",
      "\n",
      "Epoch:   52/60    Loss: 3.0697835047245023\n",
      "\n",
      "Epoch:   52/60    Loss: 3.0866367956399916\n",
      "\n",
      "Epoch:   52/60    Loss: 3.0985342943668366\n",
      "\n",
      "Epoch:   52/60    Loss: 3.049612582206726\n",
      "\n",
      "Epoch:   52/60    Loss: 3.0630641005039214\n",
      "\n",
      "Epoch:   52/60    Loss: 3.024775385379791\n",
      "\n",
      "Epoch:   52/60    Loss: 3.015448805809021\n",
      "\n",
      "Epoch:   52/60    Loss: 2.9751757447719576\n",
      "\n",
      "Epoch:   53/60    Loss: 3.0304716548517994\n",
      "\n",
      "Epoch:   53/60    Loss: 3.0838101842403414\n",
      "\n",
      "Epoch:   53/60    Loss: 2.996749423980713\n",
      "\n",
      "Epoch:   53/60    Loss: 3.0194865529537203\n",
      "\n",
      "Epoch:   53/60    Loss: 2.9875358877182006\n",
      "\n",
      "Epoch:   53/60    Loss: 3.057285567045212\n",
      "\n",
      "Epoch:   53/60    Loss: 3.0634976997375487\n",
      "\n",
      "Epoch:   53/60    Loss: 2.994632865190506\n",
      "\n",
      "Epoch:   53/60    Loss: 2.8818737885951995\n",
      "\n",
      "Epoch:   53/60    Loss: 3.0548806331157685\n",
      "\n",
      "Epoch:   53/60    Loss: 2.9764624860286713\n",
      "\n",
      "Epoch:   53/60    Loss: 2.9736709904670717\n",
      "\n",
      "Epoch:   53/60    Loss: 2.9144565510749816\n",
      "\n",
      "Epoch:   53/60    Loss: 2.932632811784744\n",
      "\n",
      "Epoch:   53/60    Loss: 2.8803645343780517\n",
      "\n",
      "Epoch:   53/60    Loss: 2.8872793233394622\n",
      "\n",
      "Epoch:   53/60    Loss: 2.9343815660476684\n",
      "\n",
      "Epoch:   53/60    Loss: 2.9943387286663055\n",
      "\n",
      "Epoch:   53/60    Loss: 2.905864693403244\n",
      "\n",
      "Epoch:   53/60    Loss: 2.846748575925827\n",
      "\n",
      "Epoch:   53/60    Loss: 2.9678617820739746\n",
      "\n",
      "Epoch:   53/60    Loss: 2.9200097877979276\n",
      "\n",
      "Epoch:   53/60    Loss: 3.084613140583038\n",
      "\n",
      "Epoch:   53/60    Loss: 2.979613979101181\n",
      "\n",
      "Epoch:   53/60    Loss: 3.0904669885635374\n",
      "\n",
      "Epoch:   53/60    Loss: 3.0670109617710115\n",
      "\n",
      "Epoch:   53/60    Loss: 3.002507592916489\n",
      "\n",
      "Epoch:   53/60    Loss: 3.049879436969757\n",
      "\n",
      "Epoch:   53/60    Loss: 3.0116219782829283\n",
      "\n",
      "Epoch:   53/60    Loss: 2.927492927789688\n",
      "\n",
      "Epoch:   53/60    Loss: 2.805922000646591\n",
      "\n",
      "Epoch:   53/60    Loss: 3.0064674673080445\n",
      "\n",
      "Epoch:   53/60    Loss: 2.970868295669556\n",
      "\n",
      "Epoch:   53/60    Loss: 2.871236868619919\n",
      "\n",
      "Epoch:   53/60    Loss: 2.8708896642923354\n",
      "\n",
      "Epoch:   53/60    Loss: 2.976849819660187\n",
      "\n",
      "Epoch:   53/60    Loss: 2.8974650545120237\n",
      "\n",
      "Epoch:   53/60    Loss: 2.9628543343544007\n",
      "\n",
      "Epoch:   53/60    Loss: 2.9960959131717684\n",
      "\n",
      "Epoch:   53/60    Loss: 2.88539675450325\n",
      "\n",
      "Epoch:   53/60    Loss: 2.889001387834549\n",
      "\n",
      "Epoch:   53/60    Loss: 2.922188564538956\n",
      "\n",
      "Epoch:   53/60    Loss: 2.9651145327091215\n",
      "\n",
      "Epoch:   53/60    Loss: 3.0781735157966614\n",
      "\n",
      "Epoch:   53/60    Loss: 2.9838739812374113\n",
      "\n",
      "Epoch:   53/60    Loss: 3.0527908918857576\n",
      "\n",
      "Epoch:   53/60    Loss: 3.050944520711899\n",
      "\n",
      "Epoch:   53/60    Loss: 3.0003903949260713\n",
      "\n",
      "Epoch:   53/60    Loss: 2.9956551396846773\n",
      "\n",
      "Epoch:   53/60    Loss: 3.1047948648929595\n",
      "\n",
      "Epoch:   53/60    Loss: 3.0262836899757386\n",
      "\n",
      "Epoch:   53/60    Loss: 3.046745379447937\n",
      "\n",
      "Epoch:   53/60    Loss: 3.082558100819588\n",
      "\n",
      "Epoch:   53/60    Loss: 3.072143547296524\n",
      "\n",
      "Epoch:   53/60    Loss: 3.0232918243408204\n",
      "\n",
      "Epoch:   53/60    Loss: 3.0340089309215545\n",
      "\n",
      "Epoch:   53/60    Loss: 3.0025494112968443\n",
      "\n",
      "Epoch:   53/60    Loss: 2.994285982131958\n",
      "\n",
      "Epoch:   53/60    Loss: 2.9801971855163574\n",
      "\n",
      "Epoch:   54/60    Loss: 3.0398767248767875\n",
      "\n",
      "Epoch:   54/60    Loss: 3.064681040763855\n",
      "\n",
      "Epoch:   54/60    Loss: 2.9980653235912325\n",
      "\n",
      "Epoch:   54/60    Loss: 3.0131693539619446\n",
      "\n",
      "Epoch:   54/60    Loss: 2.966613899946213\n",
      "\n",
      "Epoch:   54/60    Loss: 3.0535581452846525\n",
      "\n",
      "Epoch:   54/60    Loss: 3.0733730947971343\n",
      "\n",
      "Epoch:   54/60    Loss: 2.9609646074771883\n",
      "\n",
      "Epoch:   54/60    Loss: 2.88037367773056\n",
      "\n",
      "Epoch:   54/60    Loss: 3.0580583708286286\n",
      "\n",
      "Epoch:   54/60    Loss: 2.962363934516907\n",
      "\n",
      "Epoch:   54/60    Loss: 2.9614403874874116\n",
      "\n",
      "Epoch:   54/60    Loss: 2.906262978076935\n",
      "\n",
      "Epoch:   54/60    Loss: 2.911340111732483\n",
      "\n",
      "Epoch:   54/60    Loss: 2.8607526586055756\n",
      "\n",
      "Epoch:   54/60    Loss: 2.8780839858055116\n",
      "\n",
      "Epoch:   54/60    Loss: 2.926607965707779\n",
      "\n",
      "Epoch:   54/60    Loss: 2.9758105716705323\n",
      "\n",
      "Epoch:   54/60    Loss: 2.873407564640045\n",
      "\n",
      "Epoch:   54/60    Loss: 2.8302983667850494\n",
      "\n",
      "Epoch:   54/60    Loss: 2.9484657855033873\n",
      "\n",
      "Epoch:   54/60    Loss: 2.900604434967041\n",
      "\n",
      "Epoch:   54/60    Loss: 3.0545633714199067\n",
      "\n",
      "Epoch:   54/60    Loss: 2.9834310846328735\n",
      "\n",
      "Epoch:   54/60    Loss: 3.0946285586357116\n",
      "\n",
      "Epoch:   54/60    Loss: 3.0567964668273926\n",
      "\n",
      "Epoch:   54/60    Loss: 2.9960142493247988\n",
      "\n",
      "Epoch:   54/60    Loss: 3.0313789258003236\n",
      "\n",
      "Epoch:   54/60    Loss: 3.003554049730301\n",
      "\n",
      "Epoch:   54/60    Loss: 2.9264637553691863\n",
      "\n",
      "Epoch:   54/60    Loss: 2.802824767589569\n",
      "\n",
      "Epoch:   54/60    Loss: 2.9962704904079436\n",
      "\n",
      "Epoch:   54/60    Loss: 2.969213332891464\n",
      "\n",
      "Epoch:   54/60    Loss: 2.872144943714142\n",
      "\n",
      "Epoch:   54/60    Loss: 2.8577800476551056\n",
      "\n",
      "Epoch:   54/60    Loss: 2.981569962978363\n",
      "\n",
      "Epoch:   54/60    Loss: 2.887761568784714\n",
      "\n",
      "Epoch:   54/60    Loss: 2.9609529180526732\n",
      "\n",
      "Epoch:   54/60    Loss: 2.991258065700531\n",
      "\n",
      "Epoch:   54/60    Loss: 2.88453383231163\n",
      "\n",
      "Epoch:   54/60    Loss: 2.902968658208847\n",
      "\n",
      "Epoch:   54/60    Loss: 2.9404112224578856\n",
      "\n",
      "Epoch:   54/60    Loss: 2.974745832681656\n",
      "\n",
      "Epoch:   54/60    Loss: 3.0814599976539614\n",
      "\n",
      "Epoch:   54/60    Loss: 2.973935534477234\n",
      "\n",
      "Epoch:   54/60    Loss: 3.056840943813324\n",
      "\n",
      "Epoch:   54/60    Loss: 3.047340158700943\n",
      "\n",
      "Epoch:   54/60    Loss: 2.9852964205741883\n",
      "\n",
      "Epoch:   54/60    Loss: 2.9844933116436003\n",
      "\n",
      "Epoch:   54/60    Loss: 3.0984429445266723\n",
      "\n",
      "Epoch:   54/60    Loss: 3.031358729124069\n",
      "\n",
      "Epoch:   54/60    Loss: 3.0553514609336854\n",
      "\n",
      "Epoch:   54/60    Loss: 3.0793272624015806\n",
      "\n",
      "Epoch:   54/60    Loss: 3.077792233467102\n",
      "\n",
      "Epoch:   54/60    Loss: 3.0207255215644837\n",
      "\n",
      "Epoch:   54/60    Loss: 3.032732763528824\n",
      "\n",
      "Epoch:   54/60    Loss: 3.0044342041015626\n",
      "\n",
      "Epoch:   54/60    Loss: 2.992806033849716\n",
      "\n",
      "Epoch:   54/60    Loss: 2.962880722999573\n",
      "\n",
      "Epoch:   55/60    Loss: 3.04231723535644\n",
      "\n",
      "Epoch:   55/60    Loss: 3.0642543947696685\n",
      "\n",
      "Epoch:   55/60    Loss: 2.994001963376999\n",
      "\n",
      "Epoch:   55/60    Loss: 3.018650172948837\n",
      "\n",
      "Epoch:   55/60    Loss: 2.9603012516498564\n",
      "\n",
      "Epoch:   55/60    Loss: 3.049261309146881\n",
      "\n",
      "Epoch:   55/60    Loss: 3.0798846981525423\n",
      "\n",
      "Epoch:   55/60    Loss: 2.9536896603107454\n",
      "\n",
      "Epoch:   55/60    Loss: 2.8777611451148988\n",
      "\n",
      "Epoch:   55/60    Loss: 3.0664149692058564\n",
      "\n",
      "Epoch:   55/60    Loss: 2.9675198566913603\n",
      "\n",
      "Epoch:   55/60    Loss: 2.9585204367637634\n",
      "\n",
      "Epoch:   55/60    Loss: 2.920473268985748\n",
      "\n",
      "Epoch:   55/60    Loss: 2.9192305133342744\n",
      "\n",
      "Epoch:   55/60    Loss: 2.865849867343903\n",
      "\n",
      "Epoch:   55/60    Loss: 2.880922792196274\n",
      "\n",
      "Epoch:   55/60    Loss: 2.9142291762828827\n",
      "\n",
      "Epoch:   55/60    Loss: 2.971980967760086\n",
      "\n",
      "Epoch:   55/60    Loss: 2.889021030664444\n",
      "\n",
      "Epoch:   55/60    Loss: 2.8314428832530973\n",
      "\n",
      "Epoch:   55/60    Loss: 2.9650269379615786\n",
      "\n",
      "Epoch:   55/60    Loss: 2.9031902227401734\n",
      "\n",
      "Epoch:   55/60    Loss: 3.065446618080139\n",
      "\n",
      "Epoch:   55/60    Loss: 2.9846742985248564\n",
      "\n",
      "Epoch:   55/60    Loss: 3.1062739613056185\n",
      "\n",
      "Epoch:   55/60    Loss: 3.0448401658535005\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   55/60    Loss: 2.9818870179653167\n",
      "\n",
      "Epoch:   55/60    Loss: 3.036971787929535\n",
      "\n",
      "Epoch:   55/60    Loss: 2.993278458595276\n",
      "\n",
      "Epoch:   55/60    Loss: 2.9474772527217863\n",
      "\n",
      "Epoch:   55/60    Loss: 2.815631739139557\n",
      "\n",
      "Epoch:   55/60    Loss: 2.9901257407665254\n",
      "\n",
      "Epoch:   55/60    Loss: 2.9414497957229613\n",
      "\n",
      "Epoch:   55/60    Loss: 2.8832367720603944\n",
      "\n",
      "Epoch:   55/60    Loss: 2.8809503700733186\n",
      "\n",
      "Epoch:   55/60    Loss: 2.986396545410156\n",
      "\n",
      "Epoch:   55/60    Loss: 2.9008788681030273\n",
      "\n",
      "Epoch:   55/60    Loss: 2.9637061853408815\n",
      "\n",
      "Epoch:   55/60    Loss: 2.9878115582466127\n",
      "\n",
      "Epoch:   55/60    Loss: 2.895455240726471\n",
      "\n",
      "Epoch:   55/60    Loss: 2.914346218109131\n",
      "\n",
      "Epoch:   55/60    Loss: 2.926169105529785\n",
      "\n",
      "Epoch:   55/60    Loss: 2.9722946412563322\n",
      "\n",
      "Epoch:   55/60    Loss: 3.091877036809921\n",
      "\n",
      "Epoch:   55/60    Loss: 2.978288801193237\n",
      "\n",
      "Epoch:   55/60    Loss: 3.065767784833908\n",
      "\n",
      "Epoch:   55/60    Loss: 3.0418087122440336\n",
      "\n",
      "Epoch:   55/60    Loss: 2.9924535391330718\n",
      "\n",
      "Epoch:   55/60    Loss: 2.9995793709754945\n",
      "\n",
      "Epoch:   55/60    Loss: 3.1032966153621673\n",
      "\n",
      "Epoch:   55/60    Loss: 3.0292178394794465\n",
      "\n",
      "Epoch:   55/60    Loss: 3.06530108833313\n",
      "\n",
      "Epoch:   55/60    Loss: 3.072404894709587\n",
      "\n",
      "Epoch:   55/60    Loss: 3.086179032087326\n",
      "\n",
      "Epoch:   55/60    Loss: 3.0289093651771544\n",
      "\n",
      "Epoch:   55/60    Loss: 3.0302164070606232\n",
      "\n",
      "Epoch:   55/60    Loss: 3.002160893917084\n",
      "\n",
      "Epoch:   55/60    Loss: 3.00111633849144\n",
      "\n",
      "Epoch:   55/60    Loss: 2.974642287015915\n",
      "\n",
      "Epoch:   56/60    Loss: 3.0494902922731377\n",
      "\n",
      "Epoch:   56/60    Loss: 3.073200873851776\n",
      "\n",
      "Epoch:   56/60    Loss: 2.9910693340301515\n",
      "\n",
      "Epoch:   56/60    Loss: 3.0266118621826172\n",
      "\n",
      "Epoch:   56/60    Loss: 2.9848900470733644\n",
      "\n",
      "Epoch:   56/60    Loss: 3.0435986394882204\n",
      "\n",
      "Epoch:   56/60    Loss: 3.0949651923179626\n",
      "\n",
      "Epoch:   56/60    Loss: 2.965737152814865\n",
      "\n",
      "Epoch:   56/60    Loss: 2.891989098548889\n",
      "\n",
      "Epoch:   56/60    Loss: 3.0587838122844695\n",
      "\n",
      "Epoch:   56/60    Loss: 2.970678973197937\n",
      "\n",
      "Epoch:   56/60    Loss: 2.9419221773147584\n",
      "\n",
      "Epoch:   56/60    Loss: 2.911867938041687\n",
      "\n",
      "Epoch:   56/60    Loss: 2.8984005422592163\n",
      "\n",
      "Epoch:   56/60    Loss: 2.875471059560776\n",
      "\n",
      "Epoch:   56/60    Loss: 2.8918152775764465\n",
      "\n",
      "Epoch:   56/60    Loss: 2.911176069021225\n",
      "\n",
      "Epoch:   56/60    Loss: 2.9679972920417788\n",
      "\n",
      "Epoch:   56/60    Loss: 2.9003723022937775\n",
      "\n",
      "Epoch:   56/60    Loss: 2.828194458246231\n",
      "\n",
      "Epoch:   56/60    Loss: 2.9592946574687957\n",
      "\n",
      "Epoch:   56/60    Loss: 2.904715679883957\n",
      "\n",
      "Epoch:   56/60    Loss: 3.0697643692493437\n",
      "\n",
      "Epoch:   56/60    Loss: 2.9839367063045503\n",
      "\n",
      "Epoch:   56/60    Loss: 3.0832355763912203\n",
      "\n",
      "Epoch:   56/60    Loss: 3.0537567319869994\n",
      "\n",
      "Epoch:   56/60    Loss: 2.9985463135242463\n",
      "\n",
      "Epoch:   56/60    Loss: 3.0270149180889128\n",
      "\n",
      "Epoch:   56/60    Loss: 3.0245062477588656\n",
      "\n",
      "Epoch:   56/60    Loss: 2.9305348484516145\n",
      "\n",
      "Epoch:   56/60    Loss: 2.808276775121689\n",
      "\n",
      "Epoch:   56/60    Loss: 2.9850461192131044\n",
      "\n",
      "Epoch:   56/60    Loss: 2.9456857409477233\n",
      "\n",
      "Epoch:   56/60    Loss: 2.8700095629692077\n",
      "\n",
      "Epoch:   56/60    Loss: 2.88050574028492\n",
      "\n",
      "Epoch:   56/60    Loss: 3.0097870774269104\n",
      "\n",
      "Epoch:   56/60    Loss: 2.90122624707222\n",
      "\n",
      "Epoch:   56/60    Loss: 2.9626313545703886\n",
      "\n",
      "Epoch:   56/60    Loss: 3.005253450870514\n",
      "\n",
      "Epoch:   56/60    Loss: 2.891878569126129\n",
      "\n",
      "Epoch:   56/60    Loss: 2.9299922513961794\n",
      "\n",
      "Epoch:   56/60    Loss: 2.9380088336467742\n",
      "\n",
      "Epoch:   56/60    Loss: 2.98675975561142\n",
      "\n",
      "Epoch:   56/60    Loss: 3.0873184130191804\n",
      "\n",
      "Epoch:   56/60    Loss: 2.9896799149513247\n",
      "\n",
      "Epoch:   56/60    Loss: 3.0682316143512725\n",
      "\n",
      "Epoch:   56/60    Loss: 3.066204427719116\n",
      "\n",
      "Epoch:   56/60    Loss: 2.997099313735962\n",
      "\n",
      "Epoch:   56/60    Loss: 3.002592859506607\n",
      "\n",
      "Epoch:   56/60    Loss: 3.1162855648994445\n",
      "\n",
      "Epoch:   56/60    Loss: 3.03624836564064\n",
      "\n",
      "Epoch:   56/60    Loss: 3.0597377479076386\n",
      "\n",
      "Epoch:   56/60    Loss: 3.092610401391983\n",
      "\n",
      "Epoch:   56/60    Loss: 3.072009029150009\n",
      "\n",
      "Epoch:   56/60    Loss: 3.0278348076343535\n",
      "\n",
      "Epoch:   56/60    Loss: 3.0536753487586976\n",
      "\n",
      "Epoch:   56/60    Loss: 3.010807653427124\n",
      "\n",
      "Epoch:   56/60    Loss: 3.0142667257785796\n",
      "\n",
      "Epoch:   56/60    Loss: 2.9811697454452513\n",
      "\n",
      "Epoch:   57/60    Loss: 3.0605738243978955\n",
      "\n",
      "Epoch:   57/60    Loss: 3.0842979183197023\n",
      "\n",
      "Epoch:   57/60    Loss: 2.971915983915329\n",
      "\n",
      "Epoch:   57/60    Loss: 3.0120481326580046\n",
      "\n",
      "Epoch:   57/60    Loss: 2.9850536835193635\n",
      "\n",
      "Epoch:   57/60    Loss: 3.0672122201919554\n",
      "\n",
      "Epoch:   57/60    Loss: 3.0842458810806272\n",
      "\n",
      "Epoch:   57/60    Loss: 2.957126900911331\n",
      "\n",
      "Epoch:   57/60    Loss: 2.8817261428833008\n",
      "\n",
      "Epoch:   57/60    Loss: 3.052192673206329\n",
      "\n",
      "Epoch:   57/60    Loss: 2.97237748503685\n",
      "\n",
      "Epoch:   57/60    Loss: 2.9682065107822417\n",
      "\n",
      "Epoch:   57/60    Loss: 2.912177382230759\n",
      "\n",
      "Epoch:   57/60    Loss: 2.917708056926727\n",
      "\n",
      "Epoch:   57/60    Loss: 2.8567008588314056\n",
      "\n",
      "Epoch:   57/60    Loss: 2.881456253051758\n",
      "\n",
      "Epoch:   57/60    Loss: 2.911474342107773\n",
      "\n",
      "Epoch:   57/60    Loss: 2.973313692331314\n",
      "\n",
      "Epoch:   57/60    Loss: 2.8839134829044344\n",
      "\n",
      "Epoch:   57/60    Loss: 2.8319746792316436\n",
      "\n",
      "Epoch:   57/60    Loss: 2.958038131713867\n",
      "\n",
      "Epoch:   57/60    Loss: 2.909129672288895\n",
      "\n",
      "Epoch:   57/60    Loss: 3.0589346883296966\n",
      "\n",
      "Epoch:   57/60    Loss: 3.004286259651184\n",
      "\n",
      "Epoch:   57/60    Loss: 3.110407501220703\n",
      "\n",
      "Epoch:   57/60    Loss: 3.0497521007061006\n",
      "\n",
      "Epoch:   57/60    Loss: 2.9829296462535857\n",
      "\n",
      "Epoch:   57/60    Loss: 3.0280284552574157\n",
      "\n",
      "Epoch:   57/60    Loss: 3.0002949509620667\n",
      "\n",
      "Epoch:   57/60    Loss: 2.93799049782753\n",
      "\n",
      "Epoch:   57/60    Loss: 2.8160367286205292\n",
      "\n",
      "Epoch:   57/60    Loss: 2.9780066618919374\n",
      "\n",
      "Epoch:   57/60    Loss: 2.953281651496887\n",
      "\n",
      "Epoch:   57/60    Loss: 2.847856263399124\n",
      "\n",
      "Epoch:   57/60    Loss: 2.881037012577057\n",
      "\n",
      "Epoch:   57/60    Loss: 2.9992417175769805\n",
      "\n",
      "Epoch:   57/60    Loss: 2.8962789318561555\n",
      "\n",
      "Epoch:   57/60    Loss: 2.9911974465847013\n",
      "\n",
      "Epoch:   57/60    Loss: 3.002042450428009\n",
      "\n",
      "Epoch:   57/60    Loss: 2.8984207005500795\n",
      "\n",
      "Epoch:   57/60    Loss: 2.923013423204422\n",
      "\n",
      "Epoch:   57/60    Loss: 2.921766702890396\n",
      "\n",
      "Epoch:   57/60    Loss: 2.9962456951141356\n",
      "\n",
      "Epoch:   57/60    Loss: 3.090331191778183\n",
      "\n",
      "Epoch:   57/60    Loss: 2.981841787338257\n",
      "\n",
      "Epoch:   57/60    Loss: 3.0676395733356476\n",
      "\n",
      "Epoch:   57/60    Loss: 3.0796280710697173\n",
      "\n",
      "Epoch:   57/60    Loss: 2.991514415979385\n",
      "\n",
      "Epoch:   57/60    Loss: 2.9991809656620028\n",
      "\n",
      "Epoch:   57/60    Loss: 3.1089870522022247\n",
      "\n",
      "Epoch:   57/60    Loss: 3.0180601966381073\n",
      "\n",
      "Epoch:   57/60    Loss: 3.0664596030712126\n",
      "\n",
      "Epoch:   57/60    Loss: 3.0862892487049103\n",
      "\n",
      "Epoch:   57/60    Loss: 3.072568423748016\n",
      "\n",
      "Epoch:   57/60    Loss: 3.0378028964996338\n",
      "\n",
      "Epoch:   57/60    Loss: 3.0411947100162506\n",
      "\n",
      "Epoch:   57/60    Loss: 3.003308625936508\n",
      "\n",
      "Epoch:   57/60    Loss: 3.035538523674011\n",
      "\n",
      "Epoch:   57/60    Loss: 2.970074701786041\n",
      "\n",
      "Epoch:   58/60    Loss: 3.052757196938214\n",
      "\n",
      "Epoch:   58/60    Loss: 3.053083639383316\n",
      "\n",
      "Epoch:   58/60    Loss: 2.9829904634952547\n",
      "\n",
      "Epoch:   58/60    Loss: 3.025077497959137\n",
      "\n",
      "Epoch:   58/60    Loss: 2.9662833466529848\n",
      "\n",
      "Epoch:   58/60    Loss: 3.064315193891525\n",
      "\n",
      "Epoch:   58/60    Loss: 3.0688265726566315\n",
      "\n",
      "Epoch:   58/60    Loss: 2.9762827379703523\n",
      "\n",
      "Epoch:   58/60    Loss: 2.8898939049243926\n",
      "\n",
      "Epoch:   58/60    Loss: 3.0619193625450136\n",
      "\n",
      "Epoch:   58/60    Loss: 2.96705300617218\n",
      "\n",
      "Epoch:   58/60    Loss: 2.9522287971973418\n",
      "\n",
      "Epoch:   58/60    Loss: 2.8963928134441375\n",
      "\n",
      "Epoch:   58/60    Loss: 2.9106952786445617\n",
      "\n",
      "Epoch:   58/60    Loss: 2.8632334289550783\n",
      "\n",
      "Epoch:   58/60    Loss: 2.8655536607503893\n",
      "\n",
      "Epoch:   58/60    Loss: 2.91704083609581\n",
      "\n",
      "Epoch:   58/60    Loss: 2.9767431609630584\n",
      "\n",
      "Epoch:   58/60    Loss: 2.8824785583019255\n",
      "\n",
      "Epoch:   58/60    Loss: 2.8138919236660005\n",
      "\n",
      "Epoch:   58/60    Loss: 2.951694934606552\n",
      "\n",
      "Epoch:   58/60    Loss: 2.9068608424663545\n",
      "\n",
      "Epoch:   58/60    Loss: 3.0753172800540924\n",
      "\n",
      "Epoch:   58/60    Loss: 2.9714195835590362\n",
      "\n",
      "Epoch:   58/60    Loss: 3.104715345144272\n",
      "\n",
      "Epoch:   58/60    Loss: 3.05153959941864\n",
      "\n",
      "Epoch:   58/60    Loss: 2.981308692216873\n",
      "\n",
      "Epoch:   58/60    Loss: 3.031957718372345\n",
      "\n",
      "Epoch:   58/60    Loss: 3.010605211019516\n",
      "\n",
      "Epoch:   58/60    Loss: 2.9410625541210176\n",
      "\n",
      "Epoch:   58/60    Loss: 2.820645138025284\n",
      "\n",
      "Epoch:   58/60    Loss: 2.987515372753143\n",
      "\n",
      "Epoch:   58/60    Loss: 2.961802225112915\n",
      "\n",
      "Epoch:   58/60    Loss: 2.8638599779605864\n",
      "\n",
      "Epoch:   58/60    Loss: 2.8699944515228273\n",
      "\n",
      "Epoch:   58/60    Loss: 3.0090534496307373\n",
      "\n",
      "Epoch:   58/60    Loss: 2.9073416788578035\n",
      "\n",
      "Epoch:   58/60    Loss: 2.973944884300232\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   58/60    Loss: 3.011494353055954\n",
      "\n",
      "Epoch:   58/60    Loss: 2.9144302282333374\n",
      "\n",
      "Epoch:   58/60    Loss: 2.928942413806915\n",
      "\n",
      "Epoch:   58/60    Loss: 2.9462935311794283\n",
      "\n",
      "Epoch:   58/60    Loss: 3.0154632954597473\n",
      "\n",
      "Epoch:   58/60    Loss: 3.089923846244812\n",
      "\n",
      "Epoch:   58/60    Loss: 2.9795881843566896\n",
      "\n",
      "Epoch:   58/60    Loss: 3.0965788426399232\n",
      "\n",
      "Epoch:   58/60    Loss: 3.109135447263718\n",
      "\n",
      "Epoch:   58/60    Loss: 3.0051245551109314\n",
      "\n",
      "Epoch:   58/60    Loss: 3.027168481826782\n",
      "\n",
      "Epoch:   58/60    Loss: 3.1139655599594116\n",
      "\n",
      "Epoch:   58/60    Loss: 3.046295505285263\n",
      "\n",
      "Epoch:   58/60    Loss: 3.066065661430359\n",
      "\n",
      "Epoch:   58/60    Loss: 3.1018606140613554\n",
      "\n",
      "Epoch:   58/60    Loss: 3.084925150871277\n",
      "\n",
      "Epoch:   58/60    Loss: 3.054350051879883\n",
      "\n",
      "Epoch:   58/60    Loss: 3.0427903695106506\n",
      "\n",
      "Epoch:   58/60    Loss: 3.020717315196991\n",
      "\n",
      "Epoch:   58/60    Loss: 3.0195130007267\n",
      "\n",
      "Epoch:   58/60    Loss: 2.982715908050537\n",
      "\n",
      "Epoch:   59/60    Loss: 3.0452361814677715\n",
      "\n",
      "Epoch:   59/60    Loss: 3.0575683653354644\n",
      "\n",
      "Epoch:   59/60    Loss: 2.9981422402858735\n",
      "\n",
      "Epoch:   59/60    Loss: 3.034874997138977\n",
      "\n",
      "Epoch:   59/60    Loss: 3.002537048339844\n",
      "\n",
      "Epoch:   59/60    Loss: 3.0873897314071654\n",
      "\n",
      "Epoch:   59/60    Loss: 3.083726209163666\n",
      "\n",
      "Epoch:   59/60    Loss: 2.973847106695175\n",
      "\n",
      "Epoch:   59/60    Loss: 2.889144278049469\n",
      "\n",
      "Epoch:   59/60    Loss: 3.0603441479206084\n",
      "\n",
      "Epoch:   59/60    Loss: 2.9837223472595213\n",
      "\n",
      "Epoch:   59/60    Loss: 2.953134929418564\n",
      "\n",
      "Epoch:   59/60    Loss: 2.9117457249164582\n",
      "\n",
      "Epoch:   59/60    Loss: 2.913226757764816\n",
      "\n",
      "Epoch:   59/60    Loss: 2.865428701877594\n",
      "\n",
      "Epoch:   59/60    Loss: 2.884046220779419\n",
      "\n",
      "Epoch:   59/60    Loss: 2.9047068340778353\n",
      "\n",
      "Epoch:   59/60    Loss: 2.9894070482254027\n",
      "\n",
      "Epoch:   59/60    Loss: 2.8986696090698243\n",
      "\n",
      "Epoch:   59/60    Loss: 2.832121235847473\n",
      "\n",
      "Epoch:   59/60    Loss: 2.9518259100914\n",
      "\n",
      "Epoch:   59/60    Loss: 2.901452662706375\n",
      "\n",
      "Epoch:   59/60    Loss: 3.078658596754074\n",
      "\n",
      "Epoch:   59/60    Loss: 2.9790510535240173\n",
      "\n",
      "Epoch:   59/60    Loss: 3.109859281539917\n",
      "\n",
      "Epoch:   59/60    Loss: 3.05625715303421\n",
      "\n",
      "Epoch:   59/60    Loss: 2.979164356470108\n",
      "\n",
      "Epoch:   59/60    Loss: 3.026801521062851\n",
      "\n",
      "Epoch:   59/60    Loss: 3.0009855554103853\n",
      "\n",
      "Epoch:   59/60    Loss: 2.931206425666809\n",
      "\n",
      "Epoch:   59/60    Loss: 2.8180688881874083\n",
      "\n",
      "Epoch:   59/60    Loss: 2.9913138756752016\n",
      "\n",
      "Epoch:   59/60    Loss: 2.9856986222267152\n",
      "\n",
      "Epoch:   59/60    Loss: 2.8688534355163573\n",
      "\n",
      "Epoch:   59/60    Loss: 2.8798106508255006\n",
      "\n",
      "Epoch:   59/60    Loss: 3.014713763475418\n",
      "\n",
      "Epoch:   59/60    Loss: 2.898033784389496\n",
      "\n",
      "Epoch:   59/60    Loss: 2.9615472691059113\n",
      "\n",
      "Epoch:   59/60    Loss: 3.029514420032501\n",
      "\n",
      "Epoch:   59/60    Loss: 2.919979352235794\n",
      "\n",
      "Epoch:   59/60    Loss: 2.922021285533905\n",
      "\n",
      "Epoch:   59/60    Loss: 2.924693707227707\n",
      "\n",
      "Epoch:   59/60    Loss: 2.9876632397174836\n",
      "\n",
      "Epoch:   59/60    Loss: 3.0887418694496156\n",
      "\n",
      "Epoch:   59/60    Loss: 3.001750155210495\n",
      "\n",
      "Epoch:   59/60    Loss: 3.0833980689048768\n",
      "\n",
      "Epoch:   59/60    Loss: 3.08768013381958\n",
      "\n",
      "Epoch:   59/60    Loss: 3.00435680103302\n",
      "\n",
      "Epoch:   59/60    Loss: 3.0044203991889953\n",
      "\n",
      "Epoch:   59/60    Loss: 3.1102002601623537\n",
      "\n",
      "Epoch:   59/60    Loss: 3.030851905107498\n",
      "\n",
      "Epoch:   59/60    Loss: 3.0481544024944305\n",
      "\n",
      "Epoch:   59/60    Loss: 3.0877297670841215\n",
      "\n",
      "Epoch:   59/60    Loss: 3.081446855306625\n",
      "\n",
      "Epoch:   59/60    Loss: 3.0322229998111725\n",
      "\n",
      "Epoch:   59/60    Loss: 3.031746115207672\n",
      "\n",
      "Epoch:   59/60    Loss: 3.0102510447502135\n",
      "\n",
      "Epoch:   59/60    Loss: 3.00330578827858\n",
      "\n",
      "Epoch:   59/60    Loss: 2.960490219116211\n",
      "\n",
      "Epoch:   60/60    Loss: 3.042100684960251\n",
      "\n",
      "Epoch:   60/60    Loss: 3.0646385209560396\n",
      "\n",
      "Epoch:   60/60    Loss: 2.983560513973236\n",
      "\n",
      "Epoch:   60/60    Loss: 3.009678641319275\n",
      "\n",
      "Epoch:   60/60    Loss: 2.980162822008133\n",
      "\n",
      "Epoch:   60/60    Loss: 3.0548507344722746\n",
      "\n",
      "Epoch:   60/60    Loss: 3.0761190176010134\n",
      "\n",
      "Epoch:   60/60    Loss: 2.9789613435268403\n",
      "\n",
      "Epoch:   60/60    Loss: 2.884741348028183\n",
      "\n",
      "Epoch:   60/60    Loss: 3.049336690187454\n",
      "\n",
      "Epoch:   60/60    Loss: 2.9745236086845397\n",
      "\n",
      "Epoch:   60/60    Loss: 2.9452423231601714\n",
      "\n",
      "Epoch:   60/60    Loss: 2.8977202763557433\n",
      "\n",
      "Epoch:   60/60    Loss: 2.908296685218811\n",
      "\n",
      "Epoch:   60/60    Loss: 2.8658897778987886\n",
      "\n",
      "Epoch:   60/60    Loss: 2.877387917518616\n",
      "\n",
      "Epoch:   60/60    Loss: 2.913098311185837\n",
      "\n",
      "Epoch:   60/60    Loss: 2.9796364178657533\n",
      "\n",
      "Epoch:   60/60    Loss: 2.8940574946403506\n",
      "\n",
      "Epoch:   60/60    Loss: 2.821116201400757\n",
      "\n",
      "Epoch:   60/60    Loss: 2.963512318611145\n",
      "\n",
      "Epoch:   60/60    Loss: 2.898242568016052\n",
      "\n",
      "Epoch:   60/60    Loss: 3.0628935446739196\n",
      "\n",
      "Epoch:   60/60    Loss: 3.0021293087005616\n",
      "\n",
      "Epoch:   60/60    Loss: 3.101706418991089\n",
      "\n",
      "Epoch:   60/60    Loss: 3.058830629110336\n",
      "\n",
      "Epoch:   60/60    Loss: 2.9968287605047226\n",
      "\n",
      "Epoch:   60/60    Loss: 3.0220017557144163\n",
      "\n",
      "Epoch:   60/60    Loss: 2.9825271937847138\n",
      "\n",
      "Epoch:   60/60    Loss: 2.931373210430145\n",
      "\n",
      "Epoch:   60/60    Loss: 2.817794398546219\n",
      "\n",
      "Epoch:   60/60    Loss: 2.9982976648807527\n",
      "\n",
      "Epoch:   60/60    Loss: 2.9652942707538603\n",
      "\n",
      "Epoch:   60/60    Loss: 2.8756358847618104\n",
      "\n",
      "Epoch:   60/60    Loss: 2.882172851085663\n",
      "\n",
      "Epoch:   60/60    Loss: 3.0220310349464414\n",
      "\n",
      "Epoch:   60/60    Loss: 2.897277935028076\n",
      "\n",
      "Epoch:   60/60    Loss: 2.961400050163269\n",
      "\n",
      "Epoch:   60/60    Loss: 3.0024780814647674\n",
      "\n",
      "Epoch:   60/60    Loss: 2.898976637840271\n",
      "\n",
      "Epoch:   60/60    Loss: 2.9109009709358213\n",
      "\n",
      "Epoch:   60/60    Loss: 2.9405596842765807\n",
      "\n",
      "Epoch:   60/60    Loss: 2.978248086452484\n",
      "\n",
      "Epoch:   60/60    Loss: 3.0936934700012206\n",
      "\n",
      "Epoch:   60/60    Loss: 2.96538426733017\n",
      "\n",
      "Epoch:   60/60    Loss: 3.0583674821853637\n",
      "\n",
      "Epoch:   60/60    Loss: 3.065163011789322\n",
      "\n",
      "Epoch:   60/60    Loss: 2.9900614993572234\n",
      "\n",
      "Epoch:   60/60    Loss: 3.0007856607437136\n",
      "\n",
      "Epoch:   60/60    Loss: 3.069423420906067\n",
      "\n",
      "Epoch:   60/60    Loss: 3.0162329878807066\n",
      "\n",
      "Epoch:   60/60    Loss: 3.0377836785316465\n",
      "\n",
      "Epoch:   60/60    Loss: 3.078305502772331\n",
      "\n",
      "Epoch:   60/60    Loss: 3.0720870769023896\n",
      "\n",
      "Epoch:   60/60    Loss: 3.008007902383804\n",
      "\n",
      "Epoch:   60/60    Loss: 3.005903123378754\n",
      "\n",
      "Epoch:   60/60    Loss: 2.9781039476394655\n",
      "\n",
      "Epoch:   60/60    Loss: 2.975994692325592\n",
      "\n",
      "Epoch:   60/60    Loss: 2.9531306116580964\n",
      "\n",
      "Model Trained and Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "\n",
    "# create model and move to gpu if available\n",
    "rnn = RNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5)\n",
    "if train_on_gpu:\n",
    "    rnn.cuda()\n",
    "\n",
    "# defining loss and optimization functions for training\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# training the model\n",
    "trained_rnn = train_rnn(rnn, batch_size, optimizer, criterion, num_epochs, show_every_n_batches)\n",
    "\n",
    "# saving the trained model\n",
    "helper.save_model('./save/trained_rnn', trained_rnn)\n",
    "print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: How did you decide on your model hyperparameters? \n",
    "For example, did you try different sequence_lengths and find that one size made the model converge faster? What about your hidden_dim and n_layers; how did you decide on those?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "The biggest change happend when I removed the dropout that I originally had. This changed my model to never go below a loss of 4.0 to beeing able to converge. The reasoning for not doing dropout is that we are not afraid of overfitting, we are actually trying to recreate seinfeld scripts as good as possible.\n",
    "\n",
    "Suddenly the model was able to converge, and I just left the other parameters as they were at that moment.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Checkpoint\n",
    "\n",
    "After running the above training cell, your model will be saved by name, `trained_rnn`, and if you save your notebook progress, **you can pause here and come back to this code at another time**. You can resume your progress by running the next cell, which will load in our word:id dictionaries _and_ load in your saved model by name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import torch\n",
    "import helper\n",
    "import problem_unittests as tests\n",
    "\n",
    "_, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()\n",
    "trained_rnn = helper.load_model('./save/trained_rnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate TV Script\n",
    "With the network trained and saved, you'll use it to generate a new, \"fake\" Seinfeld TV script in this section.\n",
    "\n",
    "### Generate Text\n",
    "To generate the text, the network needs to start with a single word and repeat its predictions until it reaches a set length. You'll be using the `generate` function to do this. It takes a word id to start with, `prime_id`, and generates a set length of text, `predict_len`. Also note that it uses topk sampling to introduce some randomness in choosing the most likely next word, given an output set of word scores!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def generate(rnn, prime_id, int_to_vocab, token_dict, pad_value, predict_len=100):\n",
    "    \"\"\"\n",
    "    Generate text using the neural network\n",
    "    :param decoder: The PyTorch Module that holds the trained neural network\n",
    "    :param prime_id: The word id to start the first prediction\n",
    "    :param int_to_vocab: Dict of word id keys to word values\n",
    "    :param token_dict: Dict of puncuation tokens keys to puncuation values\n",
    "    :param pad_value: The value used to pad a sequence\n",
    "    :param predict_len: The length of text to generate\n",
    "    :return: The generated text\n",
    "    \"\"\"\n",
    "    rnn.eval()\n",
    "    \n",
    "    # create a sequence (batch_size=1) with the prime_id\n",
    "    current_seq = np.full((1, sequence_length), pad_value)\n",
    "    current_seq[-1][-1] = prime_id\n",
    "    predicted = [int_to_vocab[prime_id]]\n",
    "    \n",
    "    for _ in range(predict_len):\n",
    "        if train_on_gpu:\n",
    "            current_seq = torch.LongTensor(current_seq).cuda()\n",
    "        else:\n",
    "            current_seq = torch.LongTensor(current_seq)\n",
    "        \n",
    "        # initialize the hidden state\n",
    "        hidden = rnn.init_hidden(current_seq.size(0))\n",
    "        \n",
    "        # get the output of the rnn\n",
    "        output, _ = rnn(current_seq, hidden)\n",
    "        \n",
    "        # get the next word probabilities\n",
    "        p = F.softmax(output, dim=1).data\n",
    "        if(train_on_gpu):\n",
    "            p = p.cpu() # move to cpu\n",
    "         \n",
    "        # use top_k sampling to get the index of the next word\n",
    "        top_k = 5\n",
    "        p, top_i = p.topk(top_k)\n",
    "        top_i = top_i.numpy().squeeze()\n",
    "        \n",
    "        # select the likely next word index with some element of randomness\n",
    "        p = p.numpy().squeeze()\n",
    "        word_i = np.random.choice(top_i, p=p/p.sum())\n",
    "        \n",
    "        # retrieve that word from the dictionary\n",
    "        word = int_to_vocab[word_i]\n",
    "        predicted.append(word)     \n",
    "        \n",
    "        # the generated word becomes the next \"current sequence\" and the cycle can continue\n",
    "        current_seq = np.roll(current_seq, -1, 1)\n",
    "        current_seq[-1][-1] = word_i\n",
    "    \n",
    "    gen_sentences = ' '.join(predicted)\n",
    "    \n",
    "    # Replace punctuation tokens\n",
    "    for key, token in token_dict.items():\n",
    "        ending = ' ' if key in ['\\n', '(', '\"'] else ''\n",
    "        gen_sentences = gen_sentences.replace(' ' + token.lower(), key)\n",
    "    gen_sentences = gen_sentences.replace('\\n ', '\\n')\n",
    "    gen_sentences = gen_sentences.replace('( ', '(')\n",
    "    \n",
    "    # return all the sentences\n",
    "    return gen_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a New Script\n",
    "It's time to generate the text. Set `gen_length` to the length of TV script you want to generate and set `prime_word` to one of the following to start the prediction:\n",
    "- \"jerry\"\n",
    "- \"elaine\"\n",
    "- \"george\"\n",
    "- \"kramer\"\n",
    "\n",
    "You can set the prime word to _any word_ in our dictionary, but it's best to start with a name for generating a TV script. (You can also start with any other names you find in the original text file!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:37: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jerry: brandes cooling footnote:. writer's knowwork footnote: kroft) pitched\n",
      "\n",
      "jerry: hello?\n",
      "\n",
      "kramer: hey, you gotta get the cash, you want to be honest with that man, you got.\n",
      "\n",
      "morty: what do you mean?\n",
      "\n",
      "helen: it's not that guy.\n",
      "\n",
      "george: oh, i got it.\n",
      "\n",
      "jerry: i don't know how you can do that.\n",
      "\n",
      "morty: i don't know, i'm so sorry.\n",
      "\n",
      "chiles: help me!\n",
      "\n",
      "kramer: hey, i got a lot of static. poor i was there.\n",
      "\n",
      "elaine: so, i got it.\n",
      "\n",
      "george: i can't believe i was in the position with the way to talk about.\n",
      "\n",
      "jerry: what?\n",
      "\n",
      "elaine: well, i don't know.\n",
      "\n",
      "jerry: why did you not?\n",
      "\n",
      "helen: the sticks. they don't want to hear soup and she said that would have to be. i have been in this court, you're a cosmo he was in front of a restaurant tribe- the moors. we just want to get ready, but i would.\n",
      "\n",
      "helen: george, i am, i'm gonna be.\n",
      "\n",
      "george: jerry, i am so grateful for you to get the pound. i was with the of the.\n",
      "\n",
      "george: i love this contest...\n",
      "\n",
      "elaine: i think i have a pee party and they are.\n",
      "\n",
      "kramer: you know, i can't find this stuff, you know, i was in my car with the soup. i can't have to be closing in front of the 26th packed to my mother and i had a rubber suicide thing.\n",
      "\n",
      "elaine: i have a pee party.\n",
      "\n",
      "elaine: well, it's a performance. i know what i do.\n",
      "\n",
      "susan: did you see it.\n",
      "\n",
      "george: i think it's not good for you, and he says that the time we have a good bye yeah? what did they do about this?\n",
      "\n",
      "george: i don't know. i don't know where the is as good.\n",
      "\n",
      "sidra:\n"
     ]
    }
   ],
   "source": [
    "# run the cell multiple times to get different results!\n",
    "gen_length = 400 # modify the length to your preference\n",
    "prime_word = 'jerry' # name for starting the script\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "pad_word = helper.SPECIAL_WORDS['PADDING']\n",
    "generated_script = generate(trained_rnn, vocab_to_int[prime_word + ':'], int_to_vocab, token_dict, vocab_to_int[pad_word], gen_length)\n",
    "print(generated_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save your favorite scripts\n",
    "\n",
    "Once you have a script that you like (or find interesting), save it to a text file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save script to a text file\n",
    "f =  open(\"generated_script_1.txt\",\"w\")\n",
    "f.write(generated_script)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The TV Script is Not Perfect\n",
    "It's ok if the TV script doesn't make perfect sense. It should look like alternating lines of dialogue, here is one such example of a few generated lines.\n",
    "\n",
    "### Example generated script\n",
    "\n",
    ">jerry: what about me?\n",
    ">\n",
    ">jerry: i don't have to wait.\n",
    ">\n",
    ">kramer:(to the sales table)\n",
    ">\n",
    ">elaine:(to jerry) hey, look at this, i'm a good doctor.\n",
    ">\n",
    ">newman:(to elaine) you think i have no idea of this...\n",
    ">\n",
    ">elaine: oh, you better take the phone, and he was a little nervous.\n",
    ">\n",
    ">kramer:(to the phone) hey, hey, jerry, i don't want to be a little bit.(to kramer and jerry) you can't.\n",
    ">\n",
    ">jerry: oh, yeah. i don't even know, i know.\n",
    ">\n",
    ">jerry:(to the phone) oh, i know.\n",
    ">\n",
    ">kramer:(laughing) you know...(to jerry) you don't know.\n",
    "\n",
    "You can see that there are multiple characters that say (somewhat) complete sentences, but it doesn't have to be perfect! It takes quite a while to get good results, and often, you'll have to use a smaller vocabulary (and discard uncommon words), or get more data.  The Seinfeld dataset is about 3.4 MB, which is big enough for our purposes; for script generation you'll want more than 1 MB of text, generally. \n",
    "\n",
    "# Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as \"dlnd_tv_script_generation.ipynb\" and save another copy as an HTML file by clicking \"File\" -> \"Download as..\"->\"html\". Include the \"helper.py\" and \"problem_unittests.py\" files in your submission. Once you download these files, compress them into one zip file for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
